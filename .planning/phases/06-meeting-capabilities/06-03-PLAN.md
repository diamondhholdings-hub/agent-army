---
phase: 06-meeting-capabilities
plan: 03
type: execute
wave: 2
depends_on: ["06-01"]
files_modified:
  - src/app/meetings/bot/__init__.py
  - src/app/meetings/bot/recall_client.py
  - src/app/meetings/bot/manager.py
  - src/app/meetings/realtime/__init__.py
  - src/app/meetings/realtime/stt.py
  - src/app/meetings/realtime/tts.py
  - src/app/meetings/realtime/avatar.py
  - tests/test_bot_services.py
autonomous: true

must_haves:
  truths:
    - "RecallClient can create, monitor, and manage Recall.ai meeting bots with Output Media configuration"
    - "BotManager handles full bot lifecycle: create with avatar webpage, track status, send audio, retrieve transcript/recording"
    - "BotManager sends verbal entrance greeting immediately upon successful meeting join (per CONTEXT.md: no silent joining)"
    - "DeepgramSTT provides streaming speech-to-text with endpointing for turn detection"
    - "ElevenLabsTTS provides streaming text-to-speech with Flash v2.5 for minimum latency"
    - "HeyGenAvatar manages avatar sessions with lip-sync via streaming.task API"
  artifacts:
    - path: "src/app/meetings/bot/recall_client.py"
      provides: "Async HTTP client wrapper for Recall.ai REST API"
      exports: ["RecallClient"]
      min_lines: 80
    - path: "src/app/meetings/bot/manager.py"
      provides: "BotManager for meeting bot lifecycle management"
      exports: ["BotManager"]
      min_lines: 100
    - path: "src/app/meetings/realtime/stt.py"
      provides: "Deepgram streaming STT with endpointing and VAD"
      exports: ["DeepgramSTT"]
      min_lines: 60
    - path: "src/app/meetings/realtime/tts.py"
      provides: "ElevenLabs streaming TTS with Flash v2.5"
      exports: ["ElevenLabsTTS"]
      min_lines: 50
    - path: "src/app/meetings/realtime/avatar.py"
      provides: "HeyGen avatar session management via REST API"
      exports: ["HeyGenAvatar"]
      min_lines: 80
  key_links:
    - from: "src/app/meetings/bot/manager.py"
      to: "src/app/meetings/bot/recall_client.py"
      via: "RecallClient for API calls"
      pattern: "RecallClient"
    - from: "src/app/meetings/bot/manager.py"
      to: "src/app/meetings/repository.py"
      via: "MeetingRepository for persisting bot state"
      pattern: "MeetingRepository"
    - from: "src/app/meetings/realtime/stt.py"
      to: "deepgram"
      via: "Deepgram SDK WebSocket streaming"
      pattern: "DeepgramClient"
    - from: "src/app/meetings/realtime/tts.py"
      to: "elevenlabs"
      via: "ElevenLabs async client"
      pattern: "AsyncElevenLabs"
    - from: "src/app/meetings/bot/manager.py"
      to: "src/app/meetings/realtime/tts.py"
      via: "ElevenLabsTTS for entrance greeting audio synthesis"
      pattern: "synthesize_full"
---

<objective>
Build the Recall.ai bot management layer and real-time service wrappers for STT, TTS, and Avatar -- the external API integration clients that the real-time pipeline will orchestrate.

Purpose: This plan creates the service wrappers for all external APIs that the meeting bot needs. RecallClient and BotManager handle the Recall.ai bot lifecycle. DeepgramSTT, ElevenLabsTTS, and HeyGenAvatar are thin async wrappers around their respective APIs. These are the building blocks that Plan 06-04 (RealtimePipeline) will orchestrate.

Output: Bot management layer + three real-time service wrappers + unit tests.
</objective>

<execution_context>
@/Users/RAZER/.claude/get-shit-done/workflows/execute-plan.md
@/Users/RAZER/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/06-meeting-capabilities/06-CONTEXT.md
@.planning/phases/06-meeting-capabilities/06-RESEARCH.md
@.planning/phases/06-meeting-capabilities/06-01-SUMMARY.md

@src/app/meetings/schemas.py
@src/app/meetings/repository.py
@src/app/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: RecallClient and BotManager</name>
  <files>
    src/app/meetings/bot/__init__.py
    src/app/meetings/bot/recall_client.py
    src/app/meetings/bot/manager.py
  </files>
  <action>
    1. Create `src/app/meetings/bot/__init__.py` (empty module marker).

    2. Create `src/app/meetings/bot/recall_client.py` with `RecallClient`:
       - Constructor takes: `api_key: str`, `region: str = "us-west-2"`
       - Base URL: `https://{region}.recall.ai/api/v1`
       - Headers: `{"Authorization": f"Token {api_key}"}`
       - Uses httpx.AsyncClient with tenacity retry (3 attempts, exponential backoff 1-10s) matching existing patterns (05-03)

       Methods (all async):
       - `create_bot(config: dict) -> dict` -- POST /bot/
       - `get_bot(bot_id: str) -> dict` -- GET /bot/{bot_id}/
       - `get_bot_status(bot_id: str) -> str` -- GET /bot/{bot_id}/ -> extracts status_changes[-1].code
       - `send_audio(bot_id: str, mp3_b64: str) -> None` -- POST /bot/{bot_id}/output_audio/
       - `get_transcript(bot_id: str) -> list[dict]` -- GET /bot/{bot_id}/transcript/
       - `get_recording(bot_id: str) -> dict` -- GET /bot/{bot_id}/recording/
       - `delete_bot(bot_id: str) -> None` -- DELETE /bot/{bot_id}/
       - All methods log with structlog (bot_id, operation, status)
       - Timeout: 30s for create/delete, 10s for get/status

    3. Create `src/app/meetings/bot/manager.py` with `BotManager`:
       - Constructor takes: `recall_client: RecallClient`, `repository: MeetingRepository`, `settings` (for webapp URL, bot name), `tts_client: ElevenLabsTTS | None = None` (optional, for entrance greeting; if None, greeting is skipped with log warning)

       - `async create_meeting_bot(meeting: Meeting, tenant_id: str) -> str`:
         - Build bot config with Output Media (camera: webpage kind, config.url = MEETING_BOT_WEBAPP_URL with query params for meeting_id, tenant_id, and api keys as encrypted tokens)
         - Configure automatic_audio_output with silent MP3 placeholder
         - Configure real_time_endpoints webhook for transcript events
         - Configure automatic_leave: everyone_left_timeout 30s, exclude_bot True (per CONTEXT.md: agent stays until all external participants leave)
         - Call recall_client.create_bot(config)
         - Update meeting record with bot_id via repository
         - Return bot_id

       - `async join_meeting_early(meeting: Meeting, tenant_id: str) -> str`:
         - Calculate early join time (meeting start - EARLY_JOIN_MINUTES)
         - If current time is within early join window: create bot immediately
         - Otherwise: schedule bot creation (return scheduled time for caller to manage)
         - Per CONTEXT.md: 2-3 minutes early, professional standard

       - `async get_bot_status(bot_id: str) -> str`:
         - Returns current bot status from Recall.ai

       - `async handle_bot_event(bot_id: str, event_type: str, event_data: dict) -> None`:
         - Process webhook events from Recall.ai (status changes, transcript data)
         - Update meeting status in repository based on bot lifecycle:
           BOT_JOINING when bot starts, IN_PROGRESS when bot joins meeting, ENDED when bot leaves
         - **On IN_PROGRESS (bot successfully joined meeting):** trigger entrance greeting via _send_entrance_greeting()
           Per CONTEXT.md LOCKED decision: "Verbal greeting immediately upon join. No silent joining -- transparency is critical."

       - `async _send_entrance_greeting(bot_id: str, meeting: Meeting, tenant_id: str) -> None`:
         - Build greeting text: "Hi, this is {agent_name} joining from {company_name}."
           - agent_name: from meeting.agent_config or tenant settings
           - company_name: from tenant settings
         - Synthesize greeting audio via ElevenLabsTTS.synthesize_full(greeting_text)
         - Send greeting audio to meeting via recall_client.send_audio(bot_id, mp3_b64=base64_encoded_audio)
         - Log: structlog "bot.entrance_greeting_sent" with bot_id, meeting_id
         - Error handling: if TTS or send_audio fails, log warning but do NOT block meeting participation (greeting is best-effort)

       - `async retrieve_meeting_artifacts(bot_id: str, meeting_id: UUID, tenant_id: str) -> dict`:
         - After meeting ends, fetch transcript and recording URL from Recall.ai
         - Save transcript to repository
         - Update meeting with recording_url
         - Return dict with transcript and recording_url

       - `_build_output_media_url(meeting_id: UUID, tenant_id: str) -> str`:
         - Constructs the Output Media webapp URL with query parameters
         - Parameters: meeting_id, tenant_id (webapp uses these to connect to correct backend WS)
  </action>
  <verify>
    Run: `cd "/Users/RAZER/Documents/projects/sales army" && python -c "from src.app.meetings.bot.recall_client import RecallClient; from src.app.meetings.bot.manager import BotManager; print('Bot management OK')"`
  </verify>
  <done>
    RecallClient provides async Recall.ai REST API wrapper with retry logic. BotManager handles full bot lifecycle: creation with Output Media config, early joining, status tracking, webhook event processing, post-meeting artifact retrieval, and verbal entrance greeting on join (per CONTEXT.md: no silent joining).
  </done>
</task>

<task type="auto">
  <name>Task 2: DeepgramSTT, ElevenLabsTTS, HeyGenAvatar service wrappers and tests</name>
  <files>
    src/app/meetings/realtime/__init__.py
    src/app/meetings/realtime/stt.py
    src/app/meetings/realtime/tts.py
    src/app/meetings/realtime/avatar.py
    tests/test_bot_services.py
  </files>
  <action>
    1. Create `src/app/meetings/realtime/__init__.py` (empty module marker).

    2. Create `src/app/meetings/realtime/stt.py` with `DeepgramSTT`:
       - Constructor takes: `api_key: str`
       - Uses `deepgram.DeepgramClient` for WebSocket streaming

       - `async connect(on_transcript: Callable, on_utterance_end: Callable) -> None`:
         - Establishes WebSocket connection with LiveOptions:
           model="nova-3", language="en-US", smart_format=True, interim_results=True,
           endpointing=300, utterance_end_ms="1000", vad_events=True, diarize=True,
           encoding="linear16", channels=1, sample_rate=16000
         - Registers event handlers for Transcript and UtteranceEnd events
         - Per RESEARCH.md: 300ms endpointing for fast-paced, 1s utterance_end

       - `send_audio(audio_bytes: bytes) -> None`:
         - Sends raw audio bytes to Deepgram WebSocket

       - `_handle_transcript(result, **kwargs) -> None`:
         - Extracts transcript text and is_final flag
         - Calls on_transcript callback with (transcript, is_final, speaker_id from diarization)

       - `_handle_utterance_end(result, **kwargs) -> None`:
         - Calls on_utterance_end callback

       - `async close() -> None`:
         - Gracefully closes WebSocket connection

    3. Create `src/app/meetings/realtime/tts.py` with `ElevenLabsTTS`:
       - Constructor takes: `api_key: str`, `voice_id: str`
       - Uses `elevenlabs.client.AsyncElevenLabs`
       - Model: `eleven_flash_v2_5` (~75ms TTFB per RESEARCH.md)

       - `async synthesize_stream(text: str) -> AsyncIterator[bytes]`:
         - Calls text_to_speech.convert with streaming
         - output_format="mp3_22050_32" (MP3 for Recall.ai output_audio compatibility)
         - optimize_streaming_latency=4 (maximum optimization per ElevenLabs docs)
         - Yields audio chunks as they arrive

       - `async synthesize_full(text: str) -> bytes`:
         - Convenience method that collects all chunks into a single bytes buffer
         - Used for short utterances (greetings, confirmations)

    4. Create `src/app/meetings/realtime/avatar.py` with `HeyGenAvatar`:
       - Constructor takes: `api_key: str`, `avatar_id: str`, `voice_id: str | None = None`
       - Uses httpx.AsyncClient for HeyGen REST API calls
       - Base URL: `https://api.heygen.com/v1`

       - `async start_session() -> dict`:
         - POST streaming.new with version="v2", avatar_name=avatar_id, quality="high"
         - Returns session data including session_id, LiveKit url, and access_token
         - Stores session_id internally

       - `async start_streaming() -> None`:
         - POST streaming.start with session_id
         - Marks session as active

       - `async speak(text: str) -> None`:
         - POST streaming.task with session_id, text=text, task_type="repeat"
         - "repeat" mode: avatar speaks exact text with lip-sync (we handle LLM ourselves)
         - Per CONTEXT.md: fully animated with natural movements, lip-sync critical

       - `async send_idle_reaction(reaction: str) -> None`:
         - POST streaming.task with task_type="talk" for context-aware idle behavior
         - Reaction types: "nod", "interested", "thinking" (mapped to avatar behaviors)
         - Per CONTEXT.md: context-aware reactions even when not speaking

       - `async stop_session() -> None`:
         - POST streaming.stop with session_id
         - Cleans up session resources

       - `get_session_info() -> dict | None`:
         - Returns current session info (session_id, LiveKit url, access_token)
         - Used by Output Media webapp to connect to LiveKit room

       - Session rotation support: `async rotate_session() -> dict`:
         - Creates new session, returns new session info
         - Per RESEARCH Pitfall 4: handle session duration limits

    5. Create `tests/test_bot_services.py` with unit tests:
       - Test RecallClient.create_bot builds correct HTTP request (mock httpx)
       - Test RecallClient retry logic on transient failures
       - Test BotManager.create_meeting_bot includes Output Media config
       - Test BotManager.handle_bot_event updates meeting status correctly
       - Test BotManager._build_output_media_url includes meeting_id and tenant_id
       - Test DeepgramSTT connects with correct LiveOptions (mock DeepgramClient)
       - Test ElevenLabsTTS uses Flash v2.5 model and correct output_format
       - Test HeyGenAvatar.start_session, speak, stop_session lifecycle (mock httpx)
       - Test HeyGenAvatar.rotate_session creates new session
       - Test BotManager._send_entrance_greeting synthesizes and sends audio on join
       - Test BotManager.handle_bot_event triggers greeting on IN_PROGRESS status
       - Test BotManager._send_entrance_greeting handles TTS failure gracefully (logs warning, continues)
       - Minimum 14 tests covering all service wrappers
  </action>
  <verify>
    Run: `cd "/Users/RAZER/Documents/projects/sales army" && python -m pytest tests/test_bot_services.py -v`
    All tests pass.
  </verify>
  <done>
    DeepgramSTT provides streaming STT with Nova-3 model and endpointing. ElevenLabsTTS provides streaming TTS with Flash v2.5. HeyGenAvatar manages avatar sessions with lip-sync and idle reactions. All service wrappers have unit tests with mocked external APIs.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from src.app.meetings.bot.recall_client import RecallClient; from src.app.meetings.bot.manager import BotManager; from src.app.meetings.realtime.stt import DeepgramSTT; from src.app.meetings.realtime.tts import ElevenLabsTTS; from src.app.meetings.realtime.avatar import HeyGenAvatar; print('All bot/realtime services OK')"` succeeds
2. `python -m pytest tests/test_bot_services.py -v` -- all tests pass
3. RecallClient uses tenacity retry matching existing patterns
4. BotManager creates bots with Output Media webpage config
5. DeepgramSTT uses Nova-3 with 300ms endpointing
6. ElevenLabsTTS uses Flash v2.5 with streaming optimization
7. HeyGenAvatar supports session lifecycle + rotation
</verification>

<success_criteria>
All external API service wrappers are built and tested -- RecallClient/BotManager for meeting bot lifecycle (including verbal entrance greeting on join), DeepgramSTT for streaming transcription, ElevenLabsTTS for streaming voice synthesis, HeyGenAvatar for animated avatar with lip-sync. These are ready for orchestration in Plan 06-04.
</success_criteria>

<output>
After completion, create `.planning/phases/06-meeting-capabilities/06-03-SUMMARY.md`
</output>
