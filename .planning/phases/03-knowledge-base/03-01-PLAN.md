---
phase: 03-knowledge-base
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - pyproject.toml
  - src/__init__.py
  - src/knowledge/__init__.py
  - src/knowledge/config.py
  - src/knowledge/embeddings.py
  - src/knowledge/qdrant_client.py
  - src/knowledge/models.py
  - .env.example
  - tests/__init__.py
  - tests/knowledge/__init__.py
  - tests/knowledge/test_qdrant_client.py
autonomous: true

must_haves:
  truths:
    - "Qdrant local instance initializes and accepts connections"
    - "Embedding service generates vectors from text input"
    - "Collections are created with payload-based multitenancy (tenant_id with is_tenant=true, per-tenant HNSW indexes)"
    - "Hybrid search (dense + sparse) is configured on collections"
  artifacts:
    - path: "pyproject.toml"
      provides: "Project dependencies and configuration"
      contains: "qdrant-client"
    - path: "src/knowledge/qdrant_client.py"
      provides: "Qdrant client wrapper with tenant-scoped operations"
      exports: ["QdrantKnowledgeStore"]
    - path: "src/knowledge/embeddings.py"
      provides: "Embedding service for dense and sparse vectors"
      exports: ["EmbeddingService"]
    - path: "src/knowledge/models.py"
      provides: "Pydantic models for knowledge chunks, metadata, tenants"
      exports: ["KnowledgeChunk", "ChunkMetadata", "TenantConfig"]
  key_links:
    - from: "src/knowledge/qdrant_client.py"
      to: "qdrant_client"
      via: "QdrantClient initialization"
      pattern: "QdrantClient"
    - from: "src/knowledge/qdrant_client.py"
      to: "src/knowledge/embeddings.py"
      via: "embed text before upsert/search"
      pattern: "EmbeddingService"
    - from: "src/knowledge/qdrant_client.py"
      to: "src/knowledge/models.py"
      via: "uses KnowledgeChunk for typed operations"
      pattern: "KnowledgeChunk"
---

<objective>
Set up the Qdrant vector database foundation with payload-based multi-tenant isolation (per-tenant HNSW indexes via is_tenant=true), embedding service, and shared type system for the entire knowledge base.

Purpose: Every other knowledge base plan depends on this foundation -- vector storage, embedding generation, and tenant isolation are prerequisites for product knowledge, methodology, conversation history, and RAG.

Output: Working Qdrant local instance with tenant-scoped collections, an embedding service generating dense+sparse vectors, and Pydantic models defining the knowledge chunk schema.
</objective>

<execution_context>
@/Users/RAZER/.claude/get-shit-done/workflows/execute-plan.md
@/Users/RAZER/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
Phase 3 builds the tenant-scoped knowledge foundation. This is Plan 01 -- the vector DB and embedding foundation.

Key research findings to honor:
- Qdrant v1.16+ with payload-based multitenancy (tenant_id field with `is_tenant=true` index). NOTE: This implements the "multi-tenant with per-tenant namespaces" requirement using Qdrant's recommended payload-based isolation pattern -- NOT Qdrant's deprecated "namespace" concept. Each tenant gets logically isolated data via mandatory tenant_id filtering with per-tenant HNSW indexes (payload_m=16, m=0), which is functionally equivalent to namespace isolation but more scalable.
- Qdrant local mode for development (no Docker needed): `QdrantClient(path="./qdrant_data")`
- Two separate collections: `knowledge_base` (products, methodology, regional) and `conversations`
- Hybrid search: dense vectors (OpenAI text-embedding-3-small, 1536 dims) + BM25 sparse vectors
- Server-side sparse encoding via Qdrant FastEmbed or client-side via fastembed library
- RRF (Reciprocal Rank Fusion) for combining dense + sparse results
- Payload indexes on: tenant_id (keyword, is_tenant), product_category, buyer_persona, sales_stage, region, is_current, version

Locked decisions from user:
- Metadata tagging: product_category, buyer_persona, sales_stage, region
- Product categories: Monetization, Charging, Billing (actual ESW products -- NOT fictional names)
- Hybrid search (semantic + keyword)
- Per-product organization (each ESW product is a separate knowledge unit)
- Feature-level chunks (each capability/feature self-contained)
- Versioning: track knowledge versions over time
- Cross-references: explicit links between related content
</context>

<tasks>

<task type="auto">
  <name>Task 1: Initialize Python project with dependencies and base structure</name>
  <files>
    pyproject.toml
    src/__init__.py
    src/knowledge/__init__.py
    src/knowledge/config.py
    src/knowledge/models.py
    .env.example
    tests/__init__.py
    tests/knowledge/__init__.py
  </files>
  <action>
    Create the Python project structure using pyproject.toml (not setup.py).

    pyproject.toml dependencies:
    - qdrant-client >= 1.12.0 (supports local mode, payload multitenancy)
    - openai >= 1.0.0 (for text-embedding-3-small)
    - fastembed >= 0.4.0 (for BM25 sparse vectors client-side)
    - langchain >= 0.3.0
    - langchain-openai >= 0.2.0
    - langchain-qdrant >= 0.2.0
    - langgraph >= 0.2.0
    - pydantic >= 2.0.0
    - python-dotenv >= 1.0.0
    - unstructured[all-docs] >= 0.16.0 (PDF, Word, etc. parsing)
    - pytest >= 8.0.0 (dev dependency)
    - pytest-asyncio >= 0.24.0 (dev dependency)

    src/knowledge/config.py:
    - KnowledgeBaseConfig Pydantic settings model
    - Fields: qdrant_path (default "./qdrant_data"), qdrant_url (optional, for production), qdrant_api_key (optional), openai_api_key, embedding_model (default "text-embedding-3-small"), embedding_dimensions (default 1536), collection_knowledge (default "knowledge_base"), collection_conversations (default "conversations"), default_top_k (default 7), chunk_size (default 512), chunk_overlap_pct (default 0.15)
    - Load from environment variables with KNOWLEDGE_ prefix

    src/knowledge/models.py:
    - ChunkMetadata(BaseModel): product_category (Literal["monetization", "charging", "billing"] -- matches actual ESW product portfolio), buyer_persona (list[str] -- values: "technical", "business", "executive", "operations"), sales_stage (list[str] -- values: "discovery", "demo", "evaluation", "negotiation", "implementation"), region (list[str] -- values: "apac", "emea", "americas", "global"), content_type (Literal["product", "methodology", "regional", "positioning", "pricing"]), source_document (str), version (int, default 1), valid_from (datetime), valid_until (datetime | None), is_current (bool, default True), cross_references (list[str], default [])
    - KnowledgeChunk(BaseModel): id (str, uuid4), tenant_id (str), content (str), metadata (ChunkMetadata), embedding_dense (list[float] | None), embedding_sparse (dict | None), created_at (datetime), updated_at (datetime)
    - TenantConfig(BaseModel): tenant_id (str), name (str), products (list[str]), regions (list[str]), active (bool, default True)
    - ConversationMessage(BaseModel): id (str, uuid4), tenant_id (str), session_id (str), channel (str), role (Literal["user", "assistant", "system"]), content (str), timestamp (datetime), metadata (dict)

    .env.example with all required env vars (OPENAI_API_KEY, KNOWLEDGE_QDRANT_PATH, etc.)

    All __init__.py files with appropriate re-exports.
  </action>
  <verify>
    cd to project root and run:
    - `pip install -e ".[dev]"` completes without errors
    - `python -c "from src.knowledge.models import KnowledgeChunk, ChunkMetadata, TenantConfig; print('Models OK')"` succeeds
    - `python -c "from src.knowledge.config import KnowledgeBaseConfig; print('Config OK')"` succeeds
  </verify>
  <done>
    Project installs cleanly. All Pydantic models validate. Config loads from environment. Package structure importable.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement Qdrant client wrapper and embedding service</name>
  <files>
    src/knowledge/embeddings.py
    src/knowledge/qdrant_client.py
    tests/knowledge/test_qdrant_client.py
  </files>
  <action>
    src/knowledge/embeddings.py - EmbeddingService class:
    - __init__(config: KnowledgeBaseConfig): Initialize OpenAI client for dense embeddings, fastembed for BM25 sparse
    - async embed_text(text: str) -> tuple[list[float], dict]: Returns (dense_vector, sparse_vector). Dense via OpenAI text-embedding-3-small. Sparse via fastembed BM25.
    - async embed_batch(texts: list[str]) -> list[tuple[list[float], dict]]: Batch embedding for efficiency
    - Handle rate limits with exponential backoff on OpenAI calls
    - Sparse vector format: {"indices": [...], "values": [...]} matching Qdrant SparseVector

    src/knowledge/qdrant_client.py - QdrantKnowledgeStore class:
    - __init__(config: KnowledgeBaseConfig): Initialize QdrantClient. Use local mode (path=config.qdrant_path) if no qdrant_url provided, otherwise connect to server.
    - async initialize_collections(): Create both collections if not exist:
      * knowledge_base collection: dense vectors (1536 dims, Cosine), named sparse vector "bm25", payload indexes on tenant_id (keyword, is_tenant=True), product_category (keyword), buyer_persona (keyword), sales_stage (keyword), region (keyword), content_type (keyword), is_current (bool), version (integer)
      * conversations collection: dense vectors (1536 dims, Cosine), payload indexes on tenant_id (keyword, is_tenant=True), session_id (keyword), channel (keyword), timestamp (integer for range queries)
    - async upsert_chunks(chunks: list[KnowledgeChunk], tenant_id: str): Upsert with tenant_id in payload. Use PointStruct with id, vector (named vectors: "dense" and "bm25"), payload (flatten metadata + tenant_id).
    - async hybrid_search(query_text: str, tenant_id: str, filters: dict | None, top_k: int) -> list[KnowledgeChunk]:
      * Embed query (dense + sparse)
      * Use Qdrant prefetch with both dense and sparse queries
      * Apply tenant_id filter (must match) + optional metadata filters
      * RRF fusion to combine results
      * Return top_k results as KnowledgeChunk objects
    - async delete_chunks(chunk_ids: list[str], tenant_id: str): Delete by IDs with tenant guard
    - async get_chunk(chunk_id: str, tenant_id: str) -> KnowledgeChunk | None: Get single chunk with tenant guard

    tests/knowledge/test_qdrant_client.py:
    - Test collection initialization (uses temporary directory for Qdrant local)
    - Test upsert + search round-trip (mock embeddings to avoid OpenAI calls)
    - Test tenant isolation (chunk from tenant A not returned for tenant B query)
    - Test metadata filtering (filter by product_category, sales_stage)
    - Use pytest fixtures with tmp_path for isolated Qdrant instances
    - Mock EmbeddingService to return deterministic vectors for testing
  </action>
  <verify>
    Run: `pytest tests/knowledge/test_qdrant_client.py -v`
    All tests pass. Specifically verify:
    - Collection creation succeeds
    - Upsert + retrieve returns correct data
    - Tenant isolation test confirms cross-tenant queries return empty
    - Metadata filter test confirms filtered results match expected
  </verify>
  <done>
    QdrantKnowledgeStore creates tenant-scoped collections with hybrid search. EmbeddingService generates dense+sparse vectors. Tenant isolation verified by tests. Foundation ready for knowledge ingestion.
  </done>
</task>

</tasks>

<verification>
- `pip install -e ".[dev]"` succeeds
- `pytest tests/knowledge/ -v` all tests pass
- Qdrant local data directory created at ./qdrant_data (or tmp_path during tests)
- Python imports work: `from src.knowledge import QdrantKnowledgeStore, EmbeddingService, KnowledgeChunk`
</verification>

<success_criteria>
- Qdrant initializes in local mode with two collections (knowledge_base, conversations)
- Embedding service generates both dense (1536-dim) and sparse (BM25) vectors
- Hybrid search combines dense + sparse with RRF fusion
- Tenant isolation verified: tenant A data invisible to tenant B queries
- Metadata filtering works on product_category, buyer_persona, sales_stage, region
- All Pydantic models validate correctly
- Tests pass without requiring external services (mocked OpenAI, local Qdrant)
</success_criteria>

<output>
After completion, create `.planning/phases/03-knowledge-base/03-01-SUMMARY.md`
</output>
