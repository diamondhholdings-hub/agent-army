---
phase: 03-knowledge-base
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - src/knowledge/ingestion/__init__.py
  - src/knowledge/ingestion/loaders.py
  - src/knowledge/ingestion/chunker.py
  - src/knowledge/ingestion/metadata_extractor.py
  - tests/knowledge/test_ingestion.py
  - tests/knowledge/fixtures/sample_product.md
  - tests/knowledge/fixtures/sample_pricing.json
autonomous: true

must_haves:
  truths:
    - "PDF, Word, Markdown, JSON, and CSV files are parsed into raw text"
    - "Raw text is split into feature-level chunks with configurable size and overlap"
    - "Metadata (product_category, buyer_persona, sales_stage, region) is extracted from document structure and frontmatter"
    - "Cross-references between related chunks are identified and stored"
  artifacts:
    - path: "src/knowledge/ingestion/loaders.py"
      provides: "Document loaders for all supported input formats"
      exports: ["DocumentLoader", "load_document"]
    - path: "src/knowledge/ingestion/chunker.py"
      provides: "Feature-level text chunking with overlap"
      exports: ["KnowledgeChunker"]
    - path: "src/knowledge/ingestion/metadata_extractor.py"
      provides: "Metadata extraction from document structure"
      exports: ["MetadataExtractor"]
  key_links:
    - from: "src/knowledge/ingestion/chunker.py"
      to: "src/knowledge/models.py"
      via: "produces KnowledgeChunk objects"
      pattern: "KnowledgeChunk"
    - from: "src/knowledge/ingestion/metadata_extractor.py"
      to: "src/knowledge/models.py"
      via: "produces ChunkMetadata objects"
      pattern: "ChunkMetadata"
---

<objective>
Build the document ingestion pipeline that parses multiple file formats, splits text into feature-level chunks, and extracts structured metadata -- everything needed before vector storage.

Purpose: The ingestion pipeline is the entry point for all knowledge content. Without it, product docs, methodology frameworks, and regional data cannot be processed into searchable chunks. This plan covers parsing and chunking; Plan 03 wires it to Qdrant for storage.

Output: Working ingestion pipeline that accepts PDF, Word, Markdown, JSON, CSV files and produces structured KnowledgeChunk objects with rich metadata.
</objective>

<execution_context>
@/Users/RAZER/.claude/get-shit-done/workflows/execute-plan.md
@/Users/RAZER/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/03-knowledge-base/03-01-SUMMARY.md

Phase 3 builds the tenant-scoped knowledge foundation. This is Plan 02 -- the document ingestion pipeline (parsing + chunking layer).

Depends on Plan 01 for: KnowledgeChunk, ChunkMetadata, and TenantConfig Pydantic models (src/knowledge/models.py), pyproject.toml (project dependencies and package structure).

Key research findings to honor:
- LangChain document loaders for file parsing (UnstructuredFileLoader, MarkdownLoader, JSONLoader, CSVLoader)
- RecursiveCharacterTextSplitter with 512 tokens, 15% overlap
- Feature-level chunking: each capability/feature should be self-contained
- Markdown headers as natural chunk boundaries (## Product Name, ### Feature)
- Metadata from frontmatter (YAML headers in markdown) and document structure
- unstructured[all-docs] library for PDF and Word parsing

Locked decisions from user:
- Input formats: Accept all (PDF, Word, Markdown, JSON, CSV, URLs, APIs)
- Granularity: Feature-level chunks (each capability/feature self-contained)
- Metadata tagging: product_category, buyer_persona, sales_stage, region
- Product categories: Monetization, Charging, Billing (actual ESW products)
- Cross-references: Explicit links between related content
- Per-product organization (each ESW product is a separate knowledge unit)
- Versioning: Track knowledge versions over time
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement document loaders and feature-level chunker</name>
  <files>
    src/knowledge/ingestion/__init__.py
    src/knowledge/ingestion/loaders.py
    src/knowledge/ingestion/chunker.py
  </files>
  <action>
    src/knowledge/ingestion/loaders.py:
    - DocumentLoader class with factory pattern based on file extension
    - Supported formats:
      * .md / .markdown: LangChain MarkdownTextSplitter or custom parser that preserves header hierarchy
      * .pdf: UnstructuredFileLoader from unstructured library
      * .docx: UnstructuredFileLoader (handles Word)
      * .json: Custom JSON loader that flattens nested structures into text sections. For product JSON, extract each top-level key as a section. For pricing JSON, preserve table structure.
      * .csv: CSVLoader from LangChain, each row becomes a section with column headers as context
      * .txt: Plain text loader
    - load_document(file_path: str | Path, content_type: str | None) -> list[RawSection]: Returns list of raw text sections with source info
    - RawSection(BaseModel): content (str), source (str), section_title (str | None), hierarchy (list[str] -- e.g., ["Monetization Platform", "Features", "Subscription Management"]), page_number (int | None)
    - Handle encoding detection (UTF-8 default, fallback to chardet)
    - Raise clear errors for unsupported formats with guidance

    src/knowledge/ingestion/chunker.py:
    - KnowledgeChunker class:
    - __init__(chunk_size: int = 512, overlap_pct: float = 0.15): Configure chunking params. chunk_size in tokens (not chars). overlap_pct as fraction.
    - chunk_sections(sections: list[RawSection], tenant_id: str, document_source: str) -> list[KnowledgeChunk]:
      * Use RecursiveCharacterTextSplitter from LangChain with separators ["\n\n", "\n", ". ", " "]
      * Respect section boundaries: prefer splitting at section breaks over mid-paragraph
      * Preserve hierarchy in chunk metadata (from RawSection.hierarchy)
      * Each chunk gets a UUID, tenant_id, and partial metadata (content_type from document, source info)
      * Track chunk position/index within document for ordering
    - Feature-level strategy: If a section (identified by header) fits within chunk_size, keep it as one chunk. Only split sections that exceed chunk_size.
    - Cross-reference detection: When chunk content mentions another product/feature by name, add to cross_references list in metadata. Use simple string matching against known product names from tenant config.
    - Version assignment: New chunks get version=1, is_current=True, valid_from=now()

    src/knowledge/ingestion/__init__.py:
    - Re-export DocumentLoader, load_document, KnowledgeChunker, MetadataExtractor
  </action>
  <verify>
    Run: `python -c "from src.knowledge.ingestion import DocumentLoader, KnowledgeChunker; print('Imports OK')"`
    Verify no import errors.
  </verify>
  <done>
    DocumentLoader handles all specified formats. KnowledgeChunker produces feature-level chunks with proper metadata stubs. Cross-reference detection works for known product names.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement metadata extractor and test with fixtures</name>
  <files>
    src/knowledge/ingestion/metadata_extractor.py
    tests/knowledge/test_ingestion.py
    tests/knowledge/fixtures/sample_product.md
    tests/knowledge/fixtures/sample_pricing.json
  </files>
  <action>
    src/knowledge/ingestion/metadata_extractor.py - MetadataExtractor class:
    - __init__(default_region: str = "global"): Configure defaults
    - extract_metadata(raw_section: RawSection, overrides: dict | None) -> ChunkMetadata:
      * From markdown frontmatter (if present): parse YAML header for product_category, buyer_persona, sales_stage, region
      * From document structure: infer content_type from hierarchy (e.g., "Pricing" header -> content_type="pricing", "Features" -> content_type="product")
      * From filename conventions: e.g., "monetization-platform-battlecard-vs-competitor.md" -> content_type="positioning"
      * buyer_persona inference: If content mentions "CTO", "VP Engineering" etc., tag accordingly. Use keyword matching against a persona dictionary: {"technical": ["CTO", "VP Engineering", "architect"], "business": ["CFO", "VP Sales", "CEO"], "operations": ["COO", "IT Manager", "DevOps"]}
      * sales_stage inference: Map content keywords to stages. Discovery content -> "discovery", pricing -> "negotiation", ROI/value -> "evaluation", competitive -> "evaluation"
      * Allow overrides dict to force any metadata field (for manual tagging)
    - enrich_chunks(chunks: list[KnowledgeChunk]) -> list[KnowledgeChunk]:
      * Apply metadata extraction to each chunk
      * Fill in any missing metadata fields with defaults
      * Return enriched chunks ready for embedding and storage

    tests/knowledge/fixtures/sample_product.md:
    - Create a realistic ESW product document (e.g., Monetization Platform) with:
      * YAML frontmatter (product_category: "monetization", region: ["global"])
      * Multiple features as ## headers (e.g., Subscription Management, Usage-Based Pricing)
      * Pricing section
      * Competitive positioning section
      * Cross-references to other ESW products (Charging, Billing)
      * ~2000 words to test chunking behavior

    tests/knowledge/fixtures/sample_pricing.json:
    - JSON pricing structure with:
      * Product tiers (Starter, Professional, Enterprise)
      * Per-tier pricing, features included, limits
      * Regional pricing variations

    tests/knowledge/test_ingestion.py:
    - test_markdown_loading: Load sample_product.md, verify sections extracted with correct hierarchy
    - test_json_loading: Load sample_pricing.json, verify structured data converted to searchable sections
    - test_chunking_respects_feature_boundaries: Verify features that fit in chunk_size stay as single chunks
    - test_chunking_splits_large_sections: Verify oversized sections split with overlap
    - test_metadata_extraction_from_frontmatter: Verify YAML frontmatter parsed correctly
    - test_metadata_inference_from_content: Verify buyer_persona and sales_stage inferred from content keywords
    - test_cross_reference_detection: Verify cross-references found when chunk mentions another product
    - test_version_assignment: Verify new chunks get version=1, is_current=True
    - test_full_pipeline: Load -> chunk -> extract metadata -> verify complete KnowledgeChunk objects
  </action>
  <verify>
    Run: `pytest tests/knowledge/test_ingestion.py -v`
    All tests pass. Specifically verify:
    - Markdown loading produces sections matching header structure
    - JSON pricing data is parseable and produces meaningful text chunks
    - Feature-level chunks are self-contained (not split across features)
    - Metadata fields are populated from frontmatter and content inference
  </verify>
  <done>
    MetadataExtractor enriches chunks with product_category, buyer_persona, sales_stage, region from multiple sources (frontmatter, content inference, filename). Full ingestion pipeline (load -> chunk -> enrich) produces complete KnowledgeChunk objects. All tests pass with realistic ESW product fixtures. product_category values use correct ESW categories: monetization, charging, billing.
  </done>
</task>

</tasks>

<verification>
- `pytest tests/knowledge/test_ingestion.py -v` all tests pass
- Sample product markdown is loaded and chunked into feature-level chunks
- Sample pricing JSON is parsed into structured searchable sections
- Metadata extraction produces valid ChunkMetadata objects
- Python imports work: `from src.knowledge.ingestion import DocumentLoader, KnowledgeChunker, MetadataExtractor`
</verification>

<success_criteria>
- All supported file formats (MD, JSON, PDF, Word, CSV, TXT) have working loaders
- Feature-level chunking keeps small sections intact and splits large ones with overlap
- Metadata extraction populates all four tag types from document structure
- Cross-references detected between related content
- Version tracking assigns version=1 with is_current=True to new chunks
- Pipeline is testable without external services (no embedding or Qdrant needed)
</success_criteria>

<output>
After completion, create `.planning/phases/03-knowledge-base/03-02-SUMMARY.md`
</output>
