---
phase: 13-technical-account-manager-agent
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/app/agents/technical_account_manager/__init__.py
  - src/app/agents/technical_account_manager/schemas.py
  - src/app/agents/technical_account_manager/prompts.py
  - src/app/handoffs/validators.py
autonomous: true

must_haves:
  truths:
    - "TAM schemas define all domain models including health score, relationship profile, ticket, and communication types"
    - "TAM handoff types health_report and escalation_alert are registered in StrictnessConfig"
    - "Prompt builders embed JSON schema in user message for structured LLM output"
    - "HealthScoreResult includes both numeric score (0-100) and RAG status"
    - "Five communication types are represented as Literal values in TAMTask"
  artifacts:
    - path: "src/app/agents/technical_account_manager/schemas.py"
      provides: "All TAM domain models, handoff payloads, and task/result types"
      exports: ["TAMTask", "TAMResult", "HealthScoreResult", "TicketSummary", "StakeholderProfile", "IntegrationStatus", "FeatureAdoption", "RelationshipProfile", "CommunicationRecord", "CoDevOpportunity", "TAMHandoffRequest", "TAMHandoffResponse", "EscalationNotificationResult"]
    - path: "src/app/agents/technical_account_manager/prompts.py"
      provides: "System prompt + 5 communication prompt builders"
      exports: ["TAM_SYSTEM_PROMPT", "build_escalation_outreach_prompt", "build_release_notes_prompt", "build_roadmap_preview_prompt", "build_health_checkin_prompt", "build_customer_success_review_prompt"]
    - path: "src/app/agents/technical_account_manager/__init__.py"
      provides: "Package init (minimal, expanded in plan 02)"
    - path: "src/app/handoffs/validators.py"
      provides: "health_report STRICT and escalation_alert STRICT handoff types registered"
      contains: "health_report"
  key_links:
    - from: "src/app/agents/technical_account_manager/prompts.py"
      to: "src/app/agents/technical_account_manager/schemas.py"
      via: "model_json_schema() embedded in prompts"
      pattern: "model_json_schema|json_schema"
    - from: "src/app/handoffs/validators.py"
      to: "StrictnessConfig._rules"
      via: "health_report -> STRICT and escalation_alert -> STRICT mapping"
      pattern: "health_report.*STRICT"
---

<objective>
Create the TAM agent's foundational Pydantic schemas and LLM prompt templates, plus register TAM handoff types in the handoff validator.

Purpose: Schemas and prompts are the foundation that every other TAM plan depends on. Getting these right first means handlers, Notion adapter, health scorer, and tests all have stable types to import.
Output: schemas.py (all domain models), prompts.py (system prompt + 5 communication builders), __init__.py (minimal package), validators.py update (health_report + escalation_alert STRICT)
</objective>

<execution_context>
@/Users/RAZER/.claude/get-shit-done/workflows/execute-plan.md
@/Users/RAZER/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-technical-account-manager-agent/13-CONTEXT.md
@.planning/phases/13-technical-account-manager-agent/13-RESEARCH.md

# Pattern references -- clone these structures
@src/app/agents/business_analyst/schemas.py
@src/app/agents/business_analyst/prompts.py
@src/app/agents/project_manager/schemas.py
@src/app/handoffs/validators.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create TAM Pydantic schemas and handoff payloads</name>
  <files>
    src/app/agents/technical_account_manager/__init__.py
    src/app/agents/technical_account_manager/schemas.py
    src/app/handoffs/validators.py
  </files>
  <action>
Create `src/app/agents/technical_account_manager/` directory and files.

**schemas.py** -- Follow the BA schemas.py pattern exactly. Define these models:

1. `TicketSummary(BaseModel)`:
   - `ticket_id: str`
   - `account_id: str`
   - `priority: Literal["P1", "P2", "P3", "P4"]`
   - `status: Literal["open", "pending", "resolved", "closed"]`
   - `created_at: datetime`
   - `age_days: float = Field(ge=0.0)`
   - `subject: str`

2. `HealthScoreResult(BaseModel)`:
   - `account_id: str`
   - `score: int = Field(ge=0, le=100)` (0-100, higher = healthier)
   - `rag_status: Literal["Green", "Amber", "Red"]`
   - `previous_score: int | None = None`
   - `previous_rag: str | None = None`
   - `p1_p2_ticket_count: int = 0`
   - `oldest_p1_p2_age_days: float = 0.0`
   - `total_open_tickets: int = 0`
   - `hours_since_heartbeat: float | None = None`
   - `should_escalate: bool = False` (computed by model_validator)
   - `scan_timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))`
   Use a `model_validator(mode="after")` to auto-set `should_escalate` when:
   - `score < 40` (Red threshold), OR
   - `previous_rag is not None and previous_rag != "Red" and rag_status == "Red"` (worsened to Red), OR
   - `previous_rag == "Green" and rag_status == "Amber"` (early warning Green->Amber)

3. `StakeholderProfile(BaseModel)`:
   - `name: str`
   - `role: str`
   - `technical_maturity: Literal["low", "medium", "high"]`
   - `notes: str = ""`

4. `IntegrationStatus(BaseModel)`:
   - `integration_name: str`
   - `is_active: bool = True`
   - `since: str = ""` (date string or "unknown")

5. `FeatureAdoption(BaseModel)`:
   - `feature_name: str`
   - `adopted: bool = False`
   - `source: Literal["heartbeat", "ticket", "manual"] = "manual"`

6. `CommunicationRecord(BaseModel)`:
   - `date: str`
   - `communication_type: Literal["escalation_outreach", "release_notes", "roadmap_preview", "health_checkin", "customer_success_review"]`
   - `subject: str`
   - `outcome: str = ""` (rep-noted outcome)

7. `CoDevOpportunity(BaseModel)`:
   - `opportunity_name: str`
   - `description: str`
   - `status: Literal["surfaced", "discussed", "in_progress", "closed"] = "surfaced"`
   - `dispatched_to_sales: bool = False`

8. `RelationshipProfile(BaseModel)`:
   - `account_id: str`
   - `account_name: str = ""`
   - `stakeholders: list[StakeholderProfile] = Field(default_factory=list)`
   - `integrations: list[IntegrationStatus] = Field(default_factory=list)`
   - `feature_adoption: list[FeatureAdoption] = Field(default_factory=list)`
   - `customer_environment: list[str] = Field(default_factory=list)` (known apps/systems)
   - `communication_history: list[CommunicationRecord] = Field(default_factory=list)`
   - `co_dev_opportunities: list[CoDevOpportunity] = Field(default_factory=list)`
   - `health_score: int | None = None`
   - `health_rag: str | None = None`
   - `last_health_scan: datetime | None = None`
   - `profile_page_id: str | None = None` (Notion sub-page ID)

9. `EscalationNotificationResult(BaseModel)`:
   - `account_id: str`
   - `channels: dict[str, bool] = Field(default_factory=dict)` (e.g. {"notion": True, "event_bus": True, "email": False, "chat": True})
   - `draft_id: str | None = None` (Gmail draft ID for outreach communication)
   - `alerts_sent: int = 0`

10. `TAMTask(BaseModel)`:
    - `task_type: Literal["health_scan", "escalation_outreach", "release_notes", "roadmap_preview", "health_checkin", "customer_success_review", "update_relationship_profile"]`
    - `account_id: str | None = None` (None for batch operations like daily scan)
    - `tenant_id: str`
    - `deal_id: str | None = None`
    - `release_info: dict[str, Any] = Field(default_factory=dict)` (for release_notes type)
    - `profile_updates: dict[str, Any] = Field(default_factory=dict)` (for update_relationship_profile)
    - `metadata: dict[str, Any] = Field(default_factory=dict)`

11. `TAMResult(BaseModel)`:
    - `task_type: str`
    - `health_scores: list[HealthScoreResult] = Field(default_factory=list)` (for batch scan)
    - `health_score: HealthScoreResult | None = None` (for single account)
    - `escalation_result: EscalationNotificationResult | None = None`
    - `communication_content: str | None = None` (generated communication text)
    - `communication_type: str | None = None`
    - `draft_id: str | None = None` (Gmail draft ID)
    - `relationship_profile: RelationshipProfile | None = None`
    - `error: str | None = None`
    - `confidence: Literal["high", "medium", "low"] = "medium"`
    - `partial: bool = False`

12. `TAMHandoffRequest(BaseModel)`:
    - `handoff_type: Literal["health_report", "escalation_alert"] = "health_report"`
    - `account_id: str`
    - `tenant_id: str`
    - `deal_id: str | None = None`
    - `request_type: Literal["health_scan", "escalation_outreach", "release_notes", "roadmap_preview", "health_checkin", "customer_success_review"] = "health_scan"`

13. `TAMHandoffResponse(BaseModel)`:
    - `handoff_type: Literal["health_report", "escalation_alert"] = "health_report"`
    - `health_score: HealthScoreResult | None = None`
    - `escalation_result: EscalationNotificationResult | None = None`
    - `communication_content: str | None = None`
    - `recommended_next_action: str = ""`
    - `confidence: float = Field(default=0.7, ge=0.0, le=1.0)`

Include `__all__` listing all exported models.

Use `from __future__ import annotations` at top. Import `Any` from typing, `datetime` and `timezone` from datetime, `Literal` from typing.

**__init__.py** -- Create minimal package init that imports schemas (expanded in plan 02):
```python
"""Technical Account Manager Agent for health monitoring and escalation prediction."""
from src.app.agents.technical_account_manager.schemas import (
    TAMHandoffRequest,
    TAMHandoffResponse,
    TAMResult,
    TAMTask,
    TicketSummary,
    HealthScoreResult,
    StakeholderProfile,
    IntegrationStatus,
    FeatureAdoption,
    RelationshipProfile,
    CommunicationRecord,
    CoDevOpportunity,
    EscalationNotificationResult,
)
```

**validators.py** -- Add TAM handoff types to `StrictnessConfig.__init__._rules` dict. Add after the BA agent handoff types block:
```python
# TAM agent handoff types
"health_report": ValidationStrictness.STRICT,
"escalation_alert": ValidationStrictness.STRICT,
```
  </action>
  <verify>
Run: `cd "/Users/RAZER/Documents/projects/sales army" && python -c "from src.app.agents.technical_account_manager.schemas import TAMTask, TAMResult, HealthScoreResult, TicketSummary, RelationshipProfile, TAMHandoffRequest, TAMHandoffResponse, EscalationNotificationResult; print('All TAM schemas import OK')"` -- must succeed.

Run: `cd "/Users/RAZER/Documents/projects/sales army" && python -c "
from src.app.agents.technical_account_manager.schemas import HealthScoreResult
# Test auto-escalation: score below 40
h1 = HealthScoreResult(account_id='acc-1', score=35, rag_status='Red')
assert h1.should_escalate == True, 'Should escalate when score < 40'
# Test auto-escalation: Green -> Amber
h2 = HealthScoreResult(account_id='acc-2', score=60, rag_status='Amber', previous_rag='Green')
assert h2.should_escalate == True, 'Should escalate on Green->Amber'
# Test no escalation: healthy
h3 = HealthScoreResult(account_id='acc-3', score=85, rag_status='Green')
assert h3.should_escalate == False, 'Should not escalate when healthy'
print('HealthScoreResult escalation logic OK')
"` -- must succeed.

Run: `cd "/Users/RAZER/Documents/projects/sales army" && python -c "from src.app.handoffs.validators import StrictnessConfig, ValidationStrictness; c = StrictnessConfig(); assert c.get_strictness('health_report') == ValidationStrictness.STRICT; assert c.get_strictness('escalation_alert') == ValidationStrictness.STRICT; print('TAM handoff registration OK')"` -- must succeed.
  </verify>
  <done>
All 13 TAM Pydantic models import and validate correctly. HealthScoreResult auto-computes should_escalate from score thresholds and RAG status changes. health_report and escalation_alert handoff types registered as STRICT in StrictnessConfig.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create TAM prompt templates with JSON schema embedding</name>
  <files>src/app/agents/technical_account_manager/prompts.py</files>
  <action>
Create `prompts.py` following the BA prompts.py pattern. Each prompt builder calls `Model.model_json_schema()` and embeds the JSON schema in the user message for parseable LLM output.

Define:

1. `TAM_SYSTEM_PROMPT` -- System prompt establishing the TAM agent's role:
   "You are a Technical Account Manager agent specializing in customer technical health monitoring and relationship management. You generate empathetic, technically accurate communications tailored to each account's specific context -- their integrations, stakeholder maturity levels, known environment, and communication history. Always return valid JSON matching the provided schema. Be proactive and customer-focused -- anticipate issues before they escalate."

2. `build_escalation_outreach_prompt(health_score: dict, relationship_profile: dict, tickets: list[dict]) -> str`:
   - Embed JSON schema for output: `{"subject": str, "body_html": str, "tone": str, "key_issues": list[str]}`
   - Provide full health score context (score, RAG, signals that triggered escalation)
   - Provide relationship profile (stakeholder names, maturity, known integrations) for personalization
   - Provide current open tickets as specific issues to address
   - Instruct: empathetic tone, address specific issues, reference stakeholder names, offer concrete next steps
   - Note: "This email will be created as a DRAFT for rep review before sending. Reference the specific issues causing the health score drop."

3. `build_release_notes_prompt(release_info: dict, relationship_profile: dict) -> str`:
   - Embed JSON schema for output: `{"subject": str, "body_html": str, "highlighted_features": list[str], "relevance_notes": list[str]}`
   - Provide release details (version, features, fixes)
   - Provide relationship profile for relevance matching (which integrations active, which features adopted)
   - Instruct: highlight only features relevant to THIS account's known use cases, explain impact in their context

4. `build_roadmap_preview_prompt(roadmap_items: list[dict], relationship_profile: dict) -> str`:
   - Embed JSON schema for output: `{"subject": str, "body_html": str, "aligned_items": list[str], "co_dev_opportunities": list[str]}`
   - Provide upcoming roadmap items and relationship profile
   - Instruct: identify items aligned with customer's technical roadmap, surface co-dev/integration opportunities, frame for QBR or strategic call preparation

5. `build_health_checkin_prompt(health_score: dict, relationship_profile: dict, recent_communications: list[dict]) -> str`:
   - Embed JSON schema for output: `{"subject": str, "body_html": str, "health_summary": str, "recommendations": list[str]}`
   - Provide current health score, profile, and recent communication history
   - Instruct: periodic health check-in even when all is well, summarize current health, provide recommendations for improving or maintaining health, reference past communications for continuity

6. `build_customer_success_review_prompt(health_score: dict, relationship_profile: dict, tickets: list[dict]) -> str`:
   - Embed JSON schema for output: `{"subject": str, "body_html": str, "health_overview": str, "integration_summary": str, "open_items": list[str], "recommendations": list[str]}`
   - Provide comprehensive data: health score, full profile, tickets
   - Instruct: structured Customer Success Review covering technical health, integration status, open items, and actionable recommendations

All builders return `str`. Use `json.dumps(schema, indent=2)` for schema embedding. Import json at top of file.
  </action>
  <verify>
Run: `cd "/Users/RAZER/Documents/projects/sales army" && python -c "
from src.app.agents.technical_account_manager.prompts import (
    TAM_SYSTEM_PROMPT,
    build_escalation_outreach_prompt,
    build_release_notes_prompt,
    build_roadmap_preview_prompt,
    build_health_checkin_prompt,
    build_customer_success_review_prompt,
)
p1 = build_escalation_outreach_prompt({'score': 30, 'rag_status': 'Red'}, {'account_name': 'Acme'}, [{'subject': 'API down'}])
assert 'subject' in p1, 'Schema not embedded in escalation prompt'
p2 = build_release_notes_prompt({'version': '2.0', 'features': []}, {'account_name': 'Acme'})
assert 'highlighted_features' in p2, 'Schema not embedded in release notes prompt'
p3 = build_roadmap_preview_prompt([{'item': 'SSO'}], {'account_name': 'Acme'})
assert 'co_dev_opportunities' in p3, 'Schema not embedded in roadmap prompt'
p4 = build_health_checkin_prompt({'score': 85}, {'account_name': 'Acme'}, [])
assert 'recommendations' in p4, 'Schema not embedded in health checkin prompt'
p5 = build_customer_success_review_prompt({'score': 75}, {'account_name': 'Acme'}, [])
assert 'integration_summary' in p5, 'Schema not embedded in CSR prompt'
print('All 5 TAM prompts build OK with embedded schemas')
"` -- must succeed.
  </verify>
  <done>
All 5 communication prompt builders produce prompts with embedded JSON schemas. TAM_SYSTEM_PROMPT defined. Each builder follows the established pattern of embedding output schema in user message text. Prompts include personalization context from relationship profile.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from src.app.agents.technical_account_manager import TAMTask, TAMResult, HealthScoreResult"` -- imports succeed
2. `python -c "from src.app.agents.technical_account_manager.prompts import TAM_SYSTEM_PROMPT"` -- imports succeed
3. `python -c "from src.app.handoffs.validators import StrictnessConfig; c = StrictnessConfig(); print(c.get_strictness('health_report'))"` -- prints "strict"
4. Existing tests still pass: `cd "/Users/RAZER/Documents/projects/sales army" && python -m pytest tests/ -x -q --timeout=30 2>&1 | tail -5`
</verification>

<success_criteria>
- All 13 TAM Pydantic schemas defined with proper validation (HealthScoreResult auto-computes should_escalate)
- 5 communication prompt builders + system prompt, all embedding JSON schemas in prompts
- health_report and escalation_alert handoff types registered as STRICT
- Existing test suite unbroken
</success_criteria>

<output>
After completion, create `.planning/phases/13-technical-account-manager-agent/13-01-SUMMARY.md`
</output>
