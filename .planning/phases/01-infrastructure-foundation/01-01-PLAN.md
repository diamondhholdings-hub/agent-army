---
phase: 01-infrastructure-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - pyproject.toml
  - src/app/__init__.py
  - src/app/main.py
  - src/app/config.py
  - src/app/core/__init__.py
  - src/app/core/tenant.py
  - src/app/core/database.py
  - src/app/core/redis.py
  - src/app/models/__init__.py
  - src/app/models/shared.py
  - src/app/models/tenant.py
  - src/app/services/__init__.py
  - src/app/services/tenant_provisioning.py
  - src/app/api/__init__.py
  - src/app/api/deps.py
  - alembic.ini
  - alembic/env.py
  - alembic/script.py.mako
  - alembic/tenant.py
  - alembic/versions/.gitkeep
  - docker-compose.yml
  - tests/__init__.py
  - tests/conftest.py
  - tests/test_tenant_isolation.py
autonomous: true

user_setup:
  - service: postgresql
    why: "Local PostgreSQL for development (docker-compose handles this)"
    env_vars: []
    dashboard_config: []
  - service: redis
    why: "Local Redis for development (docker-compose handles this)"
    env_vars: []
    dashboard_config: []

must_haves:
  truths:
    - "A new tenant can be provisioned via a Python function and gets an isolated PostgreSQL schema"
    - "Tenant context propagates via contextvars -- any function can call get_current_tenant() to get the active tenant"
    - "Database queries are automatically routed to the correct tenant schema via schema_translate_map"
    - "RLS policies prevent a tenant from reading or writing another tenant's data even if schema_translate_map is bypassed"
    - "Redis keys are automatically prefixed with tenant ID -- no cross-tenant cache leakage possible"
    - "Connection pool checkout resets tenant context to prevent stale session variable leaks"
  artifacts:
    - path: "src/app/core/tenant.py"
      provides: "TenantContext dataclass, contextvar, get_current_tenant(), TenantMiddleware"
      contains: "contextvars.ContextVar"
    - path: "src/app/core/database.py"
      provides: "Async SQLAlchemy engine, tenant-scoped session factory, pool checkout reset"
      contains: "schema_translate_map"
    - path: "src/app/core/redis.py"
      provides: "TenantRedis wrapper with automatic key prefixing"
      contains: "t:{tenant_id}"
    - path: "src/app/models/shared.py"
      provides: "Shared schema models (Tenant table in public/shared schema)"
      contains: "class Tenant"
    - path: "src/app/models/tenant.py"
      provides: "Per-tenant schema models with placeholder schema='tenant'"
      contains: "MetaData(schema=\"tenant\")"
    - path: "src/app/services/tenant_provisioning.py"
      provides: "provision_tenant() that creates schema, runs migrations, registers tenant"
      contains: "CREATE SCHEMA"
    - path: "alembic/env.py"
      provides: "Multi-tenant migration environment supporting schema_translate_map"
      contains: "schema_translate_map"
    - path: "docker-compose.yml"
      provides: "Local PostgreSQL 16 and Redis 7 for development"
      contains: "postgres:16"
    - path: "tests/test_tenant_isolation.py"
      provides: "Tests proving tenant data isolation at DB and Redis levels"
      contains: "test_cross_tenant"
  key_links:
    - from: "src/app/core/tenant.py"
      to: "src/app/core/database.py"
      via: "get_current_tenant() used in get_tenant_session() to set schema_translate_map"
      pattern: "get_current_tenant.*schema_translate_map"
    - from: "src/app/core/tenant.py"
      to: "src/app/core/redis.py"
      via: "get_current_tenant() used in TenantRedis._key() for prefix"
      pattern: "get_current_tenant.*tenant_id"
    - from: "src/app/services/tenant_provisioning.py"
      to: "src/app/models/shared.py"
      via: "Inserts into shared.tenants table during provisioning"
      pattern: "INSERT INTO.*tenants"
    - from: "src/app/core/database.py"
      to: "sqlalchemy pool events"
      via: "checkout event resets tenant context to prevent leaks"
      pattern: "event.listens_for.*checkout"
---

<objective>
Build the multi-tenant database foundation: PostgreSQL with schema-per-tenant isolation and RLS defense-in-depth, Redis with tenant key prefixing, tenant context propagation via Python contextvars, and a tenant provisioning service that creates fully isolated tenant environments.

Purpose: This is the bedrock layer -- every subsequent component (API gateway, LLM calls, agent orchestration) depends on tenant context being available and data being isolated. Multi-tenancy cannot be retrofitted; it must be built from the first line of code.

Output: Working multi-tenant data layer with PostgreSQL schemas, RLS policies, Redis isolation, and automated tenant provisioning. Local dev environment via docker-compose. Tests proving cross-tenant isolation.
</objective>

<execution_context>
@/Users/RAZER/.claude/get-shit-done/workflows/execute-plan.md
@/Users/RAZER/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-infrastructure-foundation/01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Project scaffold, database engine, and tenant context propagation</name>
  <files>
    pyproject.toml
    docker-compose.yml
    src/app/__init__.py
    src/app/main.py
    src/app/config.py
    src/app/core/__init__.py
    src/app/core/tenant.py
    src/app/core/database.py
    src/app/core/redis.py
    src/app/models/__init__.py
    src/app/models/shared.py
    src/app/models/tenant.py
    src/app/api/__init__.py
    src/app/api/deps.py
    src/app/services/__init__.py
  </files>
  <action>
    **1. Create pyproject.toml** with project name `agent-army`, Python 3.12+, and these dependencies:
    - Core: fastapi, uvicorn[standard], sqlalchemy[asyncio], asyncpg, alembic, redis[hiredis], pydantic, pydantic-settings
    - Auth (for next plan): python-jose[cryptography], passlib[bcrypt]
    - LLM (for next plan): litellm
    - Google (for next plan): google-auth, google-api-python-client
    - HTTP: httpx, tenacity
    - Logging: structlog
    - Monitoring (for plan 03): prometheus-client, sentry-sdk[fastapi]
    - Dev: pytest, pytest-asyncio, pytest-cov, ruff, mypy
    Use uv as the package manager. Include a [tool.ruff] section with line-length=120 and target python 3.12.

    **2. Create docker-compose.yml** with:
    - PostgreSQL 16 service: port 5432, user `agent_army`, password `agent_army_dev`, database `agent_army`, volume for persistence. Add healthcheck: `pg_isready -U agent_army`.
    - Redis 7 service: port 6379, volume for persistence. Add healthcheck: `redis-cli ping`.
    - No application container (runs locally via uvicorn during dev).

    **3. Create src/app/config.py** using Pydantic BaseSettings:
    - `DATABASE_URL`: default `postgresql+asyncpg://agent_army:agent_army_dev@localhost:5432/agent_army`
    - `REDIS_URL`: default `redis://localhost:6379/0`
    - `ENVIRONMENT`: default `development` (enum: development, staging, production)
    - `LOG_LEVEL`: default `INFO`
    - `SHARED_SCHEMA`: default `shared`
    - Load from `.env` file via `model_config = SettingsConfigDict(env_file=".env")`.
    - Create a singleton `get_settings()` function with `@lru_cache`.

    **4. Create src/app/core/tenant.py** -- Tenant context propagation:
    - `TenantContext` dataclass with fields: `tenant_id: str`, `tenant_slug: str`, `schema_name: str` (e.g., `tenant_skyvera`).
    - `_tenant_context: contextvars.ContextVar[TenantContext]` -- the contextvar.
    - `get_current_tenant() -> TenantContext` -- returns current tenant or raises `RuntimeError("No tenant context")`.
    - `set_tenant_context(ctx: TenantContext) -> contextvars.Token` -- sets the contextvar, returns token.
    - `TenantMiddleware(BaseHTTPMiddleware)` -- extracts `X-Tenant-ID` header, looks up tenant (from a simple in-memory cache backed by Redis), sets contextvar via token, resets in `finally` block. Skips tenant resolution for paths starting with `/health`, `/docs`, `/openapi.json`, `/api/v1/tenants` (provisioning endpoint).

    **5. Create src/app/core/database.py** -- Async SQLAlchemy engine with tenant isolation:
    - Create async engine from `settings.DATABASE_URL` with pool_size=20, max_overflow=10.
    - **Critical: Add pool checkout event** that executes `RESET ALL` on every connection checkout to prevent stale tenant context from previous request. Use `@event.listens_for(engine.sync_engine, "checkout")`.
    - `SharedBase(DeclarativeBase)` with `metadata = MetaData(schema="shared")` for shared tables.
    - `TenantBase(DeclarativeBase)` with `metadata = MetaData(schema="tenant")` for per-tenant tables (placeholder schema).
    - `get_shared_session()` async generator -- yields an AsyncSession bound to the engine (no schema translation).
    - `get_tenant_session()` async generator -- gets current tenant via `get_current_tenant()`, creates connection with `execution_options(schema_translate_map={"tenant": tenant.schema_name})`, sets RLS context via `SET app.current_tenant_id = '{tenant.tenant_id}'`, yields AsyncSession, closes in finally.
    - `init_db()` async function that creates the shared schema (`CREATE SCHEMA IF NOT EXISTS shared`) and the shared tables.

    **6. Create src/app/core/redis.py** -- Tenant-aware Redis wrapper:
    - `get_redis_pool()` function creating an async Redis connection pool from `settings.REDIS_URL`.
    - `TenantRedis` class wrapping `redis.asyncio.Redis`:
      - `_key(self, key: str) -> str` -- returns `t:{tenant_id}:{key}` using `get_current_tenant()`.
      - Async methods: `get`, `set` (with optional `ex` TTL), `delete`, `exists`, `expire`, `keys` (prefixed pattern).
      - `publish(channel, message)` -- publishes to tenant-prefixed channel.
      - `hset`, `hget`, `hgetall` -- hash operations with tenant prefix.
    - `get_tenant_redis()` dependency that returns a `TenantRedis` instance.

    **7. Create src/app/models/shared.py** -- Shared schema models:
    - `Tenant(SharedBase)`: `__tablename__ = "tenants"`, columns: `id` (UUID, PK, server_default=gen_random_uuid()), `slug` (String, unique, not null), `name` (String, not null), `schema_name` (String, unique, not null), `is_active` (Boolean, default True), `config` (JSON, nullable -- for future tenant-specific config), `created_at` (DateTime with timezone, server_default=now()), `updated_at` (DateTime with timezone, onupdate=now()).

    **8. Create src/app/models/tenant.py** -- Per-tenant schema models (initial set):
    - `User(TenantBase)`: `__tablename__ = "users"`, columns: `id` (UUID PK), `tenant_id` (UUID, not null), `email` (String, not null), `name` (String), `role` (String, default "member"), `is_active` (Boolean, default True), `created_at`, `updated_at`.
    - Note: unique constraint on `(tenant_id, email)` NOT just `email` -- prevents cross-tenant data leakage via constraint violations.

    **9. Create src/app/api/deps.py** -- FastAPI dependency injection:
    - `get_tenant()` -- calls `get_current_tenant()` (relies on middleware having set it).
    - `get_db()` -- wraps `get_tenant_session()` for use as FastAPI dependency.
    - `get_shared_db()` -- wraps `get_shared_session()` for admin endpoints.
    - `get_redis()` -- wraps `get_tenant_redis()`.

    **10. Create src/app/main.py** -- FastAPI app factory:
    - `create_app() -> FastAPI` function.
    - Add `TenantMiddleware`.
    - Add lifespan that calls `init_db()` on startup and closes engine on shutdown.
    - Include a basic `/health` endpoint returning `{"status": "ok", "environment": settings.ENVIRONMENT}`.
    - Set title="Agent Army API", version="0.1.0".

    Create all `__init__.py` files as empty or with appropriate `__all__` exports.
  </action>
  <verify>
    1. `cd "/Users/RAZER/Documents/projects/sales training" && uv sync` installs all dependencies without errors.
    2. `docker compose up -d` starts PostgreSQL and Redis; `docker compose ps` shows both healthy.
    3. `python -c "from src.app.main import create_app; app = create_app(); print(app.title)"` prints "Agent Army API".
    4. `python -c "from src.app.core.tenant import TenantContext, get_current_tenant; print('tenant module OK')"` imports without errors.
    5. `python -c "from src.app.core.database import TenantBase, SharedBase; print('database module OK')"` imports without errors.
  </verify>
  <done>
    Project scaffold exists with all core modules importable. Docker services (PostgreSQL 16, Redis 7) running. TenantContext propagation via contextvars implemented. Database engine with schema_translate_map and pool checkout reset implemented. TenantRedis with automatic key prefixing implemented. Shared and tenant model bases defined.
  </done>
</task>

<task type="auto">
  <name>Task 2: Tenant provisioning, Alembic migrations, RLS policies, and isolation tests</name>
  <files>
    alembic.ini
    alembic/env.py
    alembic/script.py.mako
    alembic/tenant.py
    alembic/versions/.gitkeep
    src/app/services/tenant_provisioning.py
    src/app/api/v1/__init__.py
    src/app/api/v1/router.py
    src/app/api/v1/tenants.py
    src/app/api/v1/health.py
    src/app/schemas/__init__.py
    src/app/schemas/tenant.py
    tests/__init__.py
    tests/conftest.py
    tests/test_tenant_isolation.py
  </files>
  <action>
    **1. Set up Alembic for multi-tenant migrations:**

    Create `alembic.ini` with:
    - `sqlalchemy.url` pointing to the DATABASE_URL (will be overridden in env.py).
    - `script_location = alembic`.

    Create `alembic/env.py` with:
    - Import SharedBase and TenantBase metadata.
    - Two migration modes controlled by `-x` argument:
      - `alembic -x schema=shared upgrade head` -- migrates shared schema only.
      - `alembic -x schema=tenant_skyvera upgrade head` -- migrates a specific tenant schema.
    - In `run_migrations_online()`, read the schema from context `x` args. Set `target_metadata` to SharedBase.metadata or TenantBase.metadata accordingly. Apply `schema_translate_map` when running tenant migrations (map `"tenant"` -> actual schema name).
    - Include `version_table_schema` parameter so each schema has its own `alembic_version` table.

    Create `alembic/tenant.py` helper with:
    - `migrate_all_tenants(direction="upgrade", revision="head")` -- queries the shared.tenants table, iterates over all active tenant schemas, and runs Alembic migration for each. Uses `alembic.command.upgrade()` programmatically.
    - `migrate_tenant(schema_name: str, direction="upgrade", revision="head")` -- migrates a single tenant schema.

    Create initial migration by defining the migration inline (do NOT run `alembic revision --autogenerate` as DB may not be ready):
    Create `alembic/versions/001_initial_shared.py`:
    - Creates `shared` schema.
    - Creates `shared.tenants` table with all columns from the Tenant model.
    - Includes `downgrade()` that drops table and schema.

    Create `alembic/versions/002_initial_tenant.py`:
    - Creates `users` table in the `tenant` placeholder schema (Alembic will translate via schema_translate_map).
    - Enables RLS on `users` table: `ALTER TABLE {schema}.users ENABLE ROW LEVEL SECURITY` and `ALTER TABLE {schema}.users FORCE ROW LEVEL SECURITY`.
    - Creates RLS policy: `CREATE POLICY tenant_isolation ON {schema}.users FOR ALL TO app_user USING (tenant_id::text = current_setting('app.current_tenant_id', true)) WITH CHECK (tenant_id::text = current_setting('app.current_tenant_id', true))`.
    - Creates performance index: `CREATE INDEX idx_users_tenant ON {schema}.users(tenant_id)`.
    - Creates unique constraint: `CREATE UNIQUE INDEX idx_users_email_tenant ON {schema}.users(tenant_id, lower(email))`.
    - Grants permissions: `GRANT USAGE ON SCHEMA {schema} TO app_user; GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA {schema} TO app_user`.
    - Note: The `{schema}` will be the actual schema name at migration time.

    **IMPORTANT about RLS and roles:** For local development, the asyncpg connection uses the `agent_army` user which is also the table owner. RLS policies only apply to non-owner roles. For dev, we use `FORCE ROW LEVEL SECURITY` which makes RLS apply even to the table owner. In production, create a separate `app_user` role. For now, use the existing `agent_army` role with FORCE RLS.

    **2. Create tenant provisioning service** (`src/app/services/tenant_provisioning.py`):

    `async def provision_tenant(slug: str, name: str) -> dict`:
    - Validate slug (lowercase alphanumeric + hyphens only, 3-50 chars).
    - Compute `schema_name = f"tenant_{slug.replace('-', '_')}"`.
    - Using a shared session:
      1. Check if tenant with this slug already exists. Raise HTTPException(409) if so.
      2. Create the PostgreSQL schema: `CREATE SCHEMA IF NOT EXISTS "{schema_name}"`.
      3. Run tenant migrations for the new schema (call Alembic programmatically or execute the DDL directly -- for reliability, execute the DDL directly with raw SQL matching the migration).
      4. Enable RLS on all tenant tables (users table initially).
      5. Insert tenant record into `shared.tenants`.
      6. Initialize Redis namespace: set `t:{tenant_id}:initialized` = "true" with no expiry.
      7. Commit and return `{"tenant_id": str(tenant.id), "slug": slug, "schema_name": schema_name}`.

    `async def list_tenants() -> list[dict]`:
    - Query `shared.tenants` and return list of active tenants.

    `async def get_tenant_by_slug(slug: str) -> Tenant | None`:
    - Look up by slug. Cache result in Redis (global key, not tenant-prefixed) for 5 minutes.

    **3. Create API endpoints:**

    `src/app/api/v1/tenants.py`:
    - `POST /api/v1/tenants` -- accepts `{"slug": "skyvera", "name": "Skyvera"}`, calls `provision_tenant()`, returns 201 with tenant data.
    - `GET /api/v1/tenants` -- lists all tenants.
    - These endpoints skip tenant middleware (no X-Tenant-ID needed -- they're admin endpoints).

    `src/app/api/v1/health.py`:
    - `GET /health` -- basic health check (already exists, move here).
    - `GET /health/ready` -- readiness check: verifies DB connection (SELECT 1) and Redis connection (PING). Returns 200 if both pass, 503 if either fails.

    `src/app/api/v1/router.py` -- aggregates all v1 routers.

    `src/app/schemas/tenant.py` -- Pydantic models:
    - `TenantCreate(BaseModel)`: slug (str, min_length=3, max_length=50, pattern=r'^[a-z0-9-]+$'), name (str, min_length=1, max_length=200).
    - `TenantResponse(BaseModel)`: id (str), slug (str), name (str), schema_name (str), is_active (bool), created_at (datetime). Use `model_config = ConfigDict(from_attributes=True)`.

    Update `src/app/main.py` to include the v1 router.

    **4. Create isolation tests** (`tests/test_tenant_isolation.py`):

    `tests/conftest.py`:
    - Fixture that starts the app, provisions two test tenants ("test-alpha" and "test-beta").
    - Fixture that provides async client (httpx.AsyncClient) against the test app.
    - Fixture that provides raw async database sessions for each tenant.
    - Uses `@pytest.fixture(scope="session")` for DB setup.
    - After all tests, cleans up test tenant schemas.

    `tests/test_tenant_isolation.py`:
    - `test_provision_tenant`: POST to create a tenant, verify 201 response, verify schema exists in PostgreSQL.
    - `test_duplicate_tenant_rejected`: Provision same slug twice, verify 409.
    - `test_tenant_context_propagation`: Set tenant context, verify `get_current_tenant()` returns correct tenant.
    - `test_schema_translate_map_isolation`: Insert a user in tenant Alpha's schema. Query from tenant Beta's context. Verify zero results.
    - `test_redis_key_isolation`: Set a key in tenant Alpha's Redis namespace. Try to read it from tenant Beta's namespace. Verify None.
    - `test_rls_prevents_cross_tenant_read`: Using raw SQL, set tenant context to Alpha, insert a row. Set tenant context to Beta, SELECT from same table. Verify zero rows returned (RLS blocks it).
    - `test_rls_prevents_cross_tenant_write`: Set tenant context to Alpha, try to INSERT a row with Beta's tenant_id. Verify the RLS WITH CHECK blocks it.
    - `test_connection_pool_reset`: Verify that after returning a connection to the pool and checking out a new one, the `app.current_tenant_id` setting is reset (not carrying over from previous request).
    - `test_health_endpoints`: Verify `/health` returns 200, `/health/ready` returns 200 when DB and Redis are up.
  </action>
  <verify>
    1. `docker compose up -d` and services are healthy.
    2. `cd "/Users/RAZER/Documents/projects/sales training" && uv run pytest tests/test_tenant_isolation.py -v` -- all tests pass.
    3. `curl -X POST http://localhost:8000/api/v1/tenants -H "Content-Type: application/json" -d '{"slug": "skyvera", "name": "Skyvera"}'` returns 201.
    4. `curl -X POST http://localhost:8000/api/v1/tenants -H "Content-Type: application/json" -d '{"slug": "jigtree", "name": "Jigtree"}'` returns 201.
    5. `curl http://localhost:8000/health/ready` returns 200.
    6. Verify in PostgreSQL that schemas `tenant_skyvera` and `tenant_jigtree` exist with `users` table and RLS enabled: `docker compose exec postgres psql -U agent_army -c "SELECT schemaname, tablename FROM pg_tables WHERE schemaname LIKE 'tenant_%';"`.
    7. RLS test: manually verify cross-tenant query returns 0 rows.
  </verify>
  <done>
    Tenant provisioning creates isolated PostgreSQL schemas with RLS policies. Alembic supports multi-tenant migrations. Three tenants (Skyvera, Jigtree, Totogi) can be provisioned. All isolation tests pass: schema isolation, Redis key isolation, RLS read/write prevention, and connection pool context reset. API endpoints for tenant management are functional. Health check endpoints verify database and Redis connectivity.
  </done>
</task>

</tasks>

<verification>
1. **PLT-01 (Multi-tenant architecture with schema-per-tenant isolation):** Verified by provisioning Skyvera, Jigtree, and Totogi as separate tenants, each with their own PostgreSQL schema. `test_schema_translate_map_isolation` proves data separation.
2. **PLT-02 (Tenant context propagation):** Verified by `test_tenant_context_propagation` showing contextvars work across the call stack, and `test_schema_translate_map_isolation` showing database queries are automatically routed.
3. **INF-02 (PostgreSQL with RLS):** Verified by `test_rls_prevents_cross_tenant_read` and `test_rls_prevents_cross_tenant_write`. RLS uses both ENABLE and FORCE. Policies include both USING and WITH CHECK.
4. **INF-03 (Redis for caching):** Verified by `test_redis_key_isolation` showing tenant-prefixed keys prevent cross-tenant cache access. TenantRedis wrapper auto-prefixes all operations.
5. **Connection pool safety:** Verified by `test_connection_pool_reset` showing RESET ALL on checkout prevents stale tenant context.
</verification>

<success_criteria>
- `uv run pytest tests/ -v` passes all isolation tests
- Three tenants can be provisioned via API
- Each tenant has its own PostgreSQL schema with RLS enabled and forced
- Redis keys are tenant-prefixed with zero cross-tenant leakage
- Connection pool checkout resets session variables
- docker-compose provides working local dev environment
</success_criteria>

<output>
After completion, create `.planning/phases/01-infrastructure-foundation/01-01-SUMMARY.md`
</output>
