---
phase: 10-solution-architect-agent
plan: 04
type: execute
wave: 3
depends_on: ["10-02", "10-03"]
files_modified:
  - src/app/main.py
  - tests/test_solution_architect.py
autonomous: true

must_haves:
  truths:
    - "SA agent is registered in the AgentRegistry during app startup"
    - "SA agent is instantiated with LLM service and RAG pipeline from app state"
    - "Tests verify SA agent instantiation, execute routing, and fail-open behavior"
    - "An end-to-end test demonstrates map_requirements input producing TechnicalRequirementsDoc output through the full agent chain"
    - "Sales Agent can construct a handoff payload targeting solution_architect"
  artifacts:
    - path: "src/app/main.py"
      provides: "SA agent initialization and registry registration in lifespan"
      contains: "solution_architect"
    - path: "tests/test_solution_architect.py"
      provides: "Integration tests for SA agent"
      contains: "test_sa_"
  key_links:
    - from: "src/app/main.py"
      to: "src/app/agents/solution_architect/__init__.py"
      via: "import SolutionArchitectAgent, create_sa_registration"
      pattern: "from src.app.agents.solution_architect import"
    - from: "src/app/main.py"
      to: "src/app/agents/registry.py"
      via: "agent_registry.register(sa_registration)"
      pattern: "agent_registry.register"
    - from: "tests/test_solution_architect.py"
      to: "src/app/agents/solution_architect/agent.py"
      via: "test imports and invocations"
      pattern: "from src.app.agents.solution_architect"
---

<objective>
Wire the Solution Architect agent into the application: register it in main.py lifespan and create integration tests that verify all 5 capabilities work end-to-end (with mocked LLM), including a full map_requirements -> TechnicalRequirementsDoc round-trip test.

Purpose: This is the final integration step that makes the SA agent discoverable and invocable within the running application. Without this wiring, the agent exists but cannot be reached. Tests validate the entire chain: task input -> handler routing -> LLM call -> response parsing -> typed output. Note: The HybridRouter is not yet wired in main.py (it lives inside SupervisorOrchestrator which is also not initialized in main.py). Registration in AgentRegistry is sufficient -- it enables LLM-fallback routing when the Supervisor is eventually wired. Deterministic router.add_rule() calls will be added when the Supervisor is initialized in a future phase.
Output: Updated main.py with SA initialization block, comprehensive test file.
</objective>

<execution_context>
@/Users/RAZER/.claude/get-shit-done/workflows/execute-plan.md
@/Users/RAZER/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/10-solution-architect-agent/10-RESEARCH.md
@.planning/phases/10-solution-architect-agent/10-02-SUMMARY.md

# Key files for this plan
@src/app/main.py
@src/app/agents/solution_architect/__init__.py
@src/app/agents/solution_architect/agent.py
@src/app/agents/solution_architect/schemas.py
@src/app/agents/base.py
@src/app/agents/registry.py
@src/app/handoffs/validators.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Register SA agent in main.py lifespan</name>
  <files>src/app/main.py</files>
  <action>
    Add a new SA initialization block in `src/app/main.py` inside the lifespan function, AFTER the Phase 4 Sales Agent block (after `log.info("phase4.sales_agent_initialized", ...)`). Follow the exact same pattern as the Sales Agent init block (Phase 4 section).

    Add this block with its own try/except:

    ```python
    # ── Phase 10: Solution Architect Agent ────────────────────────────
    # Follows the Sales Agent pattern: instantiate with shared services,
    # register in AgentRegistry. Fail-tolerant -- SA unavailability
    # does not prevent app startup.

    try:
        from src.app.agents.solution_architect import (
            SolutionArchitectAgent,
            create_sa_registration,
        )

        sa_registration = create_sa_registration()

        sa_agent = SolutionArchitectAgent(
            registration=sa_registration,
            llm_service=llm_service,
            rag_pipeline=rag_pipeline,
        )

        # Register in agent registry
        agent_registry = getattr(app.state, "agent_registry", None)
        if agent_registry is not None:
            agent_registry.register(sa_registration)
            sa_registration._agent_instance = sa_agent
        app.state.solution_architect = sa_agent
        log.info("phase10.solution_architect_initialized")
    except Exception as exc:
        log.warning("phase10.solution_architect_init_failed", error=str(exc))
    ```

    IMPORTANT: The `llm_service`, `rag_pipeline`, and `agent_registry` variables are already in scope from the earlier Sales Agent init block. Reuse them -- do NOT re-import or re-create them.

    IMPORTANT: Place this block AFTER the Phase 4.2 QBS block but BEFORE any API router registration. Find the right location by searching for the pattern after `log.info("phase4.sales_agent_initialized"` -- there may be Phase 4.1 and 4.2 blocks in between. Place the SA block after ALL Phase 4.x blocks.

    Also add the SA agent to the handoff strictness config if it is initialized in main.py. Search for any existing `StrictnessConfig` usage. If none found in main.py, skip this -- the default StrictnessConfig already includes the rules from plan 01.

    NOTE on routing: The HybridRouter is NOT currently initialized in main.py -- it lives inside SupervisorOrchestrator (which is also not wired in main.py yet). Do NOT attempt to add router.add_rule() calls. Registration in AgentRegistry is sufficient for now and enables LLM-fallback routing when the Supervisor is wired in a future phase.

    Do NOT modify any other section of main.py. This is a pure additive change.
  </action>
  <verify>
    Run: `python -c "from src.app.main import create_app; app = create_app(); print('App creates without error')"` (may show warnings for missing services -- that is OK)
    Run: `grep -n 'solution_architect' src/app/main.py` -- should show the new init block
  </verify>
  <done>
    main.py contains a Phase 10 init block that instantiates SolutionArchitectAgent and registers it in the AgentRegistry. The block follows the fail-tolerant pattern (try/except with warning log). App startup does not crash when SA init fails (e.g., missing LLM service in dev).
  </done>
</task>

<task type="auto">
  <name>Task 2: Create integration tests for SA agent</name>
  <files>tests/test_solution_architect.py</files>
  <action>
    Create `tests/test_solution_architect.py` following the existing test patterns in the project (pytest, async tests with `@pytest.mark.asyncio`, mock LLM service).

    **Test fixtures:**

    `mock_llm_service`: A simple mock that returns pre-built JSON responses. Create a class or use `unittest.mock.AsyncMock` that has a `.completion()` async method returning `{"content": json_string}`.

    `sa_agent`: Instantiate `SolutionArchitectAgent` with mock_llm_service and rag_pipeline=None.

    **Test cases:**

    1. `test_sa_execute_routes_map_requirements`:
    - Call `agent.execute({"type": "map_requirements", "transcript": "We need REST API integration with 99.9% uptime"}, {"tenant_id": "test"})`
    - Mock LLM returns valid TechnicalRequirementsDoc JSON
    - Assert result has "requirements" key, "summary" key, "confidence" key

    2. `test_sa_execute_routes_generate_architecture`:
    - Call with `{"type": "generate_architecture", "tech_stack": "AWS, PostgreSQL, Node.js"}`
    - Mock LLM returns valid ArchitectureNarrative JSON
    - Assert result has "overview", "integration_points" keys

    3. `test_sa_execute_routes_scope_poc`:
    - Call with `{"type": "scope_poc", "requirements": [], "deal_stage": "evaluation"}`
    - Mock LLM returns valid POCPlan JSON
    - Assert result has "deliverables", "timeline_weeks", "resource_estimate" keys

    4. `test_sa_execute_routes_respond_objection`:
    - Call with `{"type": "respond_objection", "objection": "Your API latency is too high"}`
    - Mock LLM returns valid ObjectionResponse JSON
    - Assert result has "response", "evidence" keys

    5. `test_sa_execute_routes_technical_handoff`:
    - Call with `{"type": "technical_handoff", "question": "How does Skyvera handle webhook retries?"}`
    - Mock LLM returns valid TechnicalAnswerPayload JSON
    - Assert result has "answer", "evidence" keys

    6. `test_sa_execute_unknown_type_raises_valueerror`:
    - Call with `{"type": "not_a_real_type"}`
    - Assert `ValueError` is raised
    - Assert error message contains "map_requirements" (lists supported types)

    7. `test_sa_execute_fail_open_on_llm_error`:
    - Mock LLM raises `Exception("LLM unavailable")`
    - Call with `{"type": "map_requirements", "transcript": "test"}`
    - Assert result is NOT an exception (fail-open)
    - Assert result contains "error" or "partial" key indicating degraded response

    8. `test_sa_registration_has_correct_capabilities`:
    - Call `create_sa_registration()`
    - Assert agent_id == "solution_architect"
    - Assert len(capabilities) == 5
    - Assert capability names match: map_requirements, generate_architecture, scope_poc, respond_objection, technical_handoff

    9. `test_sa_handoff_payload_construction`:
    - Create a `HandoffPayload` with source_agent_id="sales_agent", target_agent_id="solution_architect", handoff_type="technical_question"
    - Assert it validates without error
    - Assert call_chain includes source but not target

    10. `test_sa_content_types_valid`:
    - Create `ChunkMetadata` with each new content_type: "competitor_analysis", "architecture_template", "poc_template"
    - Assert all 3 validate without error

    11. `test_sa_map_requirements_end_to_end`:
    - This is the key end-to-end test that proves the full chain works.
    - Create an SA agent with mocked LLM that returns a full, realistic TechnicalRequirementsDoc JSON (with 3 requirements covering integration, security, and performance categories).
    - Call `agent.execute({"type": "map_requirements", "transcript": "We need REST API integration with OAuth2 auth, 99.9% uptime SLA, and SOC2 compliance. Our stack is AWS with PostgreSQL."}, {"tenant_id": "test_tenant"})`
    - Assert result is a dict (not an exception)
    - Assert result["requirements"] is a list with 3 items
    - Assert each requirement has "category", "description", "priority" keys
    - Assert result["summary"] is a non-empty string
    - Assert result["confidence"] is a float between 0.0 and 1.0
    - This proves: task input -> handler routing -> prompt building -> LLM call -> JSON parsing -> Pydantic validation -> dict output

    Each test should be independent and not require external services (no Qdrant, no real LLM, no Redis). Use mocks for everything.

    Add proper module docstring.
  </action>
  <verify>
    Run: `python -m pytest tests/test_solution_architect.py -v --timeout=30`
    All 11 tests should pass.
  </verify>
  <done>
    11 tests pass covering: all 5 task type handlers, unknown type error, fail-open behavior, registration correctness, handoff payload construction, content type validation, and a full end-to-end map_requirements -> TechnicalRequirementsDoc round-trip. All tests are self-contained with mocked dependencies.
  </done>
</task>

</tasks>

<verification>
1. `python -m pytest tests/test_solution_architect.py -v --timeout=30` -- all 11 tests pass
2. `python -m pytest tests/ -x -q --timeout=60` -- full test suite passes (no regressions)
3. `grep 'solution_architect' src/app/main.py` -- SA init block present
4. `python -c "from src.app.agents.registry import get_agent_registry; r = get_agent_registry(); print(r.list_agent_ids())"` -- may show empty list (agents are registered at app startup, not import time), but no import error
</verification>

<success_criteria>
- main.py contains Phase 10 init block following the Sales Agent pattern
- SA agent registers in AgentRegistry at app startup
- 11 integration tests pass covering all 5 capabilities + error handling + registration + end-to-end map_requirements
- Full test suite passes with no regressions
- SA agent is accessible via `app.state.solution_architect` at runtime
</success_criteria>

<output>
After completion, create `.planning/phases/10-solution-architect-agent/10-04-SUMMARY.md`
</output>
