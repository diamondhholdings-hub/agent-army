---
phase: 10-solution-architect-agent
plan: 05
type: execute
wave: 3
depends_on: ["10-02", "10-04"]
files_modified:
  - src/app/agents/sales/agent.py
  - tests/test_sales_sa_handoff.py
autonomous: true

must_haves:
  truths:
    - "Sales Agent can detect a technical question in a conversation and dispatch it to the Solution Architect"
    - "Sales Agent publishes a technical_question task targeting solution_architect via its execute() routing"
    - "Sales Agent can receive a TechnicalAnswerPayload response and incorporate it into its reply"
    - "An end-to-end test demonstrates the full round-trip: Sales Agent detects technical question -> constructs SA task -> SA returns structured answer -> Sales Agent uses answer"
  artifacts:
    - path: "src/app/agents/sales/agent.py"
      provides: "handle_technical_question handler and _detect_technical_question helper"
      contains: "handle_technical_question"
    - path: "tests/test_sales_sa_handoff.py"
      provides: "Integration tests for Sales Agent -> SA handoff round-trip"
      contains: "test_sales_agent_technical_handoff"
  key_links:
    - from: "src/app/agents/sales/agent.py"
      to: "src/app/agents/solution_architect/schemas.py"
      via: "import TechnicalQuestionPayload, TechnicalAnswerPayload for typed handoff"
      pattern: "from src.app.agents.solution_architect.schemas import"
    - from: "src/app/agents/sales/agent.py"
      to: "src/app/agents/solution_architect/agent.py"
      via: "constructs task dict with type=technical_handoff for SA consumption"
      pattern: "technical_handoff"
    - from: "tests/test_sales_sa_handoff.py"
      to: "src/app/agents/sales/agent.py"
      via: "tests the dispatch_technical_question handler"
      pattern: "dispatch_technical_question"
---

<objective>
Add technical question detection and dispatch to the Sales Agent so it can hand off technical questions to the Solution Architect and receive structured answers back. This completes the SA-05 inter-agent handoff requirement by wiring the sending side (Sales Agent) to the already-built receiving side (SA agent's technical_handoff handler).

Purpose: The SA agent has a `technical_handoff` handler (built in Plan 02), but the Sales Agent currently has no way to detect technical questions, construct a handoff task, or use the response. This plan adds that dispatch mechanism. The round-trip is: Sales Agent detects technical question -> constructs task for SA -> SA processes and returns TechnicalAnswerPayload -> Sales Agent uses the answer. For now this is a Supervisor-mediated handoff (Sales Agent returns a task recommendation; Supervisor routes to SA). Direct event-bus publishing will be added when the Supervisor is fully wired.

Output: Updated SalesAgent with `dispatch_technical_question` handler, integration test file proving the round-trip.
</objective>

<execution_context>
@/Users/RAZER/.claude/get-shit-done/workflows/execute-plan.md
@/Users/RAZER/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/10-solution-architect-agent/10-RESEARCH.md
@.planning/phases/10-solution-architect-agent/10-02-SUMMARY.md
@.planning/phases/10-solution-architect-agent/10-04-SUMMARY.md

# Key files for this plan
@src/app/agents/sales/agent.py
@src/app/agents/solution_architect/agent.py
@src/app/agents/solution_architect/schemas.py
@src/app/handoffs/validators.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add technical question dispatch to Sales Agent</name>
  <files>src/app/agents/sales/agent.py</files>
  <action>
    Add a new task type `dispatch_technical_question` to the Sales Agent's `execute()` handler routing dict. This handler enables the Sales Agent to detect technical questions and construct a handoff task targeting the Solution Architect.

    **Step 1: Add import at the top of the file (inside the existing imports section):**
    ```python
    from src.app.agents.solution_architect.schemas import (
        TechnicalQuestionPayload,
        TechnicalAnswerPayload,
    )
    ```

    **Step 2: Add the handler to the `handlers` dict in `execute()`:**
    ```python
    handlers = {
        "send_email": self._handle_send_email,
        "send_chat": self._handle_send_chat,
        "process_reply": self._handle_process_reply,
        "qualify": self._handle_qualification,
        "recommend_action": self._handle_recommend_action,
        "dispatch_technical_question": self._handle_dispatch_technical_question,
    }
    ```

    **Step 3: Add the handler method after the existing `_handle_recommend_action` method:**

    ```python
    async def _handle_dispatch_technical_question(
        self, task: dict[str, Any], context: dict[str, Any]
    ) -> dict[str, Any]:
        """Detect and dispatch a technical question to the Solution Architect.

        When the Sales Agent encounters a question beyond its sales domain
        expertise (e.g., integration architecture, API specifications, security
        requirements, scalability concerns), it constructs a structured handoff
        task for the Solution Architect agent.

        The return value contains:
        - handoff_task: A task dict ready to be routed to the SA agent
          (type="technical_handoff" matching SA's execute() routing)
        - question_payload: The validated TechnicalQuestionPayload
        - status: "dispatched" on success, "failed" on error

        The caller (typically the Supervisor or a test) is responsible for
        actually routing the handoff_task to the SA agent and returning
        the TechnicalAnswerPayload response.

        Args:
            task: Must contain "question" (str). Optional: "deal_id",
                "prospect_tech_stack", "context_chunks", "account_id",
                "contact_id".
            context: Must contain "tenant_id".

        Returns:
            Dict with handoff_task, question_payload, and status.
        """
        tenant_id = context.get("tenant_id", "")
        question = task.get("question", "")

        if not question:
            return {
                "status": "failed",
                "error": "No question provided in task",
                "handoff_task": None,
            }

        # Build the typed payload
        try:
            payload = TechnicalQuestionPayload(
                question=question,
                deal_id=task.get("deal_id", ""),
                prospect_tech_stack=task.get("prospect_tech_stack"),
                context_chunks=task.get("context_chunks", []),
            )
        except Exception as exc:
            logger.warning(
                "technical_question_payload_invalid",
                error=str(exc),
                question=question[:100],
            )
            return {
                "status": "failed",
                "error": f"Invalid payload: {exc}",
                "handoff_task": None,
            }

        # Construct the handoff task for the SA agent
        # This task dict matches SA's execute() handler routing:
        # SA expects type="technical_handoff" with question, deal_id, etc.
        handoff_task = {
            "type": "technical_handoff",
            "question": payload.question,
            "deal_id": payload.deal_id,
            "prospect_tech_stack": payload.prospect_tech_stack,
            "context_chunks": payload.context_chunks,
        }

        logger.info(
            "technical_question_dispatched",
            deal_id=payload.deal_id,
            question_length=len(payload.question),
            tenant_id=tenant_id,
        )

        return {
            "status": "dispatched",
            "handoff_task": handoff_task,
            "question_payload": payload.model_dump(),
            "target_agent_id": "solution_architect",
        }
    ```

    **Step 4: Add a helper method for detecting technical questions (optional but useful):**

    Add this static method in the `# -- Helpers` section:

    ```python
    @staticmethod
    def _is_technical_question(text: str) -> bool:
        """Heuristic check whether text contains a technical question.

        Uses keyword matching as a fast pre-filter. For production use,
        the Supervisor's LLM routing will make the final decision.
        This heuristic helps the Sales Agent proactively flag questions
        that should be routed to the Solution Architect.

        Args:
            text: The message or question text to check.

        Returns:
            True if text likely contains a technical question.
        """
        technical_keywords = {
            "api", "integration", "webhook", "architecture", "scalability",
            "latency", "throughput", "uptime", "sla", "sdk", "endpoint",
            "authentication", "oauth", "ssl", "tls", "encryption",
            "database", "migration", "schema", "deployment", "kubernetes",
            "docker", "microservices", "rest", "graphql", "grpc",
            "compliance", "soc2", "gdpr", "hipaa", "iso27001",
            "load balancing", "rate limit", "retry", "timeout",
            "data flow", "etl", "cdc", "sync",
        }
        text_lower = text.lower()
        matches = sum(1 for kw in technical_keywords if kw in text_lower)
        # Require at least 2 technical keyword matches to reduce false positives
        return matches >= 2
    ```

    IMPORTANT: Do NOT modify any existing handler or method. This is purely additive -- one new handler in the routing dict and one new helper method. The existing 5 task types continue to work unchanged.

    IMPORTANT: Use a lazy import pattern if the solution_architect schemas import causes circular dependency issues. In that case, move the import inside the handler method:
    ```python
    async def _handle_dispatch_technical_question(self, task, context):
        from src.app.agents.solution_architect.schemas import (
            TechnicalQuestionPayload,
            TechnicalAnswerPayload,
        )
        # ... rest of handler
    ```
  </action>
  <verify>
    Run: `python -c "from src.app.agents.sales.agent import SalesAgent; print('SalesAgent imports OK')"`
    Run: `grep -n 'dispatch_technical_question' src/app/agents/sales/agent.py` -- should show handler in routing dict and method definition
    Run: `grep -n '_is_technical_question' src/app/agents/sales/agent.py` -- should show helper method
  </verify>
  <done>
    SalesAgent.execute() routes "dispatch_technical_question" to the new handler. The handler constructs a validated TechnicalQuestionPayload, builds a handoff_task dict matching the SA's "technical_handoff" task type, and returns it with status="dispatched" and target_agent_id="solution_architect". The _is_technical_question() helper provides keyword-based detection. No existing handlers are modified.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create round-trip integration test for Sales Agent -> SA handoff</name>
  <files>tests/test_sales_sa_handoff.py</files>
  <action>
    Create `tests/test_sales_sa_handoff.py` that proves the full inter-agent handoff round-trip between the Sales Agent and Solution Architect. This is the critical test that satisfies the phase success criterion: "The Sales Agent can hand off a technical question to the Solution Architect and receive a structured answer back."

    **Test fixtures:**

    `mock_llm_service`: AsyncMock with `.completion()` method.

    `sa_agent`: SolutionArchitectAgent with mock_llm_service and rag_pipeline=None.

    `sales_agent`: SalesAgent with mock_llm_service and all other services as mocks/None. Use minimal mocks for gmail_service, chat_service, rag_pipeline, conversation_store, session_manager, state_repository, qualification_extractor, action_engine, escalation_manager. The handler under test (dispatch_technical_question) does NOT use any of these services, so simple MagicMock/AsyncMock stubs suffice.

    **Test cases:**

    1. `test_sales_agent_dispatches_technical_question`:
    - Call `sales_agent.execute({"type": "dispatch_technical_question", "question": "How does Skyvera handle webhook retries and failure recovery?", "deal_id": "deal-123", "prospect_tech_stack": "AWS, Node.js"}, {"tenant_id": "test"})`
    - Assert result["status"] == "dispatched"
    - Assert result["handoff_task"]["type"] == "technical_handoff"
    - Assert result["handoff_task"]["question"] contains "webhook retries"
    - Assert result["target_agent_id"] == "solution_architect"

    2. `test_sales_agent_dispatch_empty_question_fails`:
    - Call with `{"type": "dispatch_technical_question", "question": ""}`
    - Assert result["status"] == "failed"
    - Assert result["error"] contains "No question"
    - Assert result["handoff_task"] is None

    3. `test_sa_agent_receives_handoff_task`:
    - Get the handoff_task from test 1's result
    - Construct a realistic handoff_task dict: `{"type": "technical_handoff", "question": "How does Skyvera handle webhook retries?", "deal_id": "deal-123"}`
    - Mock SA agent's LLM to return a valid TechnicalAnswerPayload JSON
    - Call `sa_agent.execute(handoff_task, {"tenant_id": "test"})`
    - Assert result has "answer" key with non-empty string
    - Assert result has "evidence" key (list)
    - Assert result has "confidence" key (float)

    4. `test_full_round_trip_sales_to_sa_and_back`:
    This is the key end-to-end test. It simulates the full Supervisor-mediated handoff:
    - Step 1: Sales Agent dispatches technical question
      ```python
      dispatch_result = await sales_agent.execute(
          {"type": "dispatch_technical_question",
           "question": "What authentication protocols does Skyvera support for enterprise SSO integration?",
           "deal_id": "deal-456",
           "prospect_tech_stack": "Azure AD, SAML 2.0"},
          {"tenant_id": "test_tenant"},
      )
      assert dispatch_result["status"] == "dispatched"
      handoff_task = dispatch_result["handoff_task"]
      ```
    - Step 2: Route handoff_task to SA agent (simulating Supervisor routing)
      ```python
      # Mock SA LLM to return structured technical answer
      sa_llm_mock.completion.return_value = {"content": json.dumps({
          "answer": "Skyvera supports SAML 2.0, OAuth 2.0, and OIDC for enterprise SSO...",
          "evidence": ["SSO integration guide section 3.2", "Security whitepaper p.12"],
          "confidence": 0.92,
          "related_docs": ["docs/sso-integration.md"],
      })}
      sa_result = await sa_agent.execute(handoff_task, {"tenant_id": "test_tenant"})
      ```
    - Step 3: Verify the SA response is a valid TechnicalAnswerPayload shape
      ```python
      assert "answer" in sa_result
      assert isinstance(sa_result["answer"], str)
      assert len(sa_result["answer"]) > 0
      assert "evidence" in sa_result
      assert isinstance(sa_result["evidence"], list)
      assert sa_result["confidence"] >= 0.0
      ```
    - Step 4: Verify the round-trip is type-safe by parsing through TechnicalAnswerPayload
      ```python
      from src.app.agents.solution_architect.schemas import TechnicalAnswerPayload
      answer_payload = TechnicalAnswerPayload(**sa_result)
      assert answer_payload.answer  # non-empty
      assert answer_payload.confidence > 0.5
      ```

    5. `test_is_technical_question_detection`:
    - Test the _is_technical_question helper:
    - "How does your API handle rate limiting and OAuth2?" -> True (multiple technical keywords)
    - "What's your pricing for 100 users?" -> False (no technical keywords)
    - "Can you integrate with our Kubernetes deployment and handle webhook retries?" -> True
    - "When can we schedule a follow-up meeting?" -> False

    6. `test_dispatch_preserves_context_chunks`:
    - Call dispatch with context_chunks=["chunk1", "chunk2"]
    - Assert handoff_task["context_chunks"] == ["chunk1", "chunk2"]

    Each test should be independent and not require external services. Use mocks for everything.

    Add proper module docstring explaining this tests the SA-05 inter-agent handoff requirement.
  </action>
  <verify>
    Run: `python -m pytest tests/test_sales_sa_handoff.py -v --timeout=30`
    All 6 tests should pass.
    Run: `python -m pytest tests/ -x -q --timeout=60` -- full test suite passes (no regressions)
  </verify>
  <done>
    6 tests pass proving: Sales Agent dispatches technical questions with correct payload, handles empty questions gracefully, SA agent receives and processes the handoff task, full round-trip (Sales -> SA -> validated response) works end-to-end, technical question detection heuristic works, and context is preserved through the handoff. The SA-05 success criterion "Sales Agent can hand off a technical question to the Solution Architect and receive a structured answer back" is demonstrated by test 4.
  </done>
</task>

</tasks>

<verification>
1. `python -m pytest tests/test_sales_sa_handoff.py -v --timeout=30` -- all 6 tests pass
2. `python -m pytest tests/ -x -q --timeout=60` -- full test suite passes (no regressions)
3. `grep 'dispatch_technical_question' src/app/agents/sales/agent.py` -- handler exists
4. `grep '_is_technical_question' src/app/agents/sales/agent.py` -- detection helper exists
</verification>

<success_criteria>
- Sales Agent routes "dispatch_technical_question" task type to its new handler
- Handler constructs validated TechnicalQuestionPayload and builds a handoff_task dict
- handoff_task dict has type="technical_handoff" matching SA agent's execute() routing
- Full round-trip test passes: Sales Agent dispatch -> SA execute -> validated TechnicalAnswerPayload
- _is_technical_question() heuristic correctly identifies technical vs non-technical questions
- No existing Sales Agent handlers or tests are broken
</success_criteria>

<output>
After completion, create `.planning/phases/10-solution-architect-agent/10-05-SUMMARY.md`
</output>
