---
phase: 07-intelligence-autonomy
plan: 05
type: execute
wave: 3
depends_on: ["07-01", "07-03", "07-04"]
files_modified:
  - src/app/intelligence/autonomy/guardrails.py
  - src/app/intelligence/autonomy/goals.py
  - src/app/intelligence/autonomy/engine.py
  - src/app/intelligence/autonomy/scheduler.py
  - tests/test_autonomy.py
autonomous: true

must_haves:
  truths:
    - "GuardrailChecker correctly classifies all action types into autonomous, approval_required, or hard_stop"
    - "Hard stops NEVER proceed autonomously (pricing, contracts, strategy, executive relationships)"
    - "Unknown action types default to approval_required (fail-safe per RESEARCH.md Pitfall 3)"
    - "GoalTracker tracks pipeline, activity, quality, and revenue metrics"
    - "AutonomyEngine proposes actions and routes through guardrails before execution"
    - "ProactiveScheduler runs background tasks for pattern scanning and outreach triggering"
  artifacts:
    - path: "src/app/intelligence/autonomy/guardrails.py"
      provides: "GuardrailChecker with three-tier action classification"
      contains: "class GuardrailChecker"
    - path: "src/app/intelligence/autonomy/goals.py"
      provides: "GoalTracker for self-directed revenue target pursuit"
      contains: "class GoalTracker"
    - path: "src/app/intelligence/autonomy/engine.py"
      provides: "AutonomyEngine for guardrail-gated action planning"
      contains: "class AutonomyEngine"
    - path: "src/app/intelligence/autonomy/scheduler.py"
      provides: "ProactiveScheduler extending Phase 4.1 asyncio pattern"
      contains: "setup_intelligence_scheduler"
  key_links:
    - from: "src/app/intelligence/autonomy/engine.py"
      to: "src/app/intelligence/autonomy/guardrails.py"
      via: "GuardrailChecker composition"
      pattern: "guardrail_checker"
    - from: "src/app/intelligence/autonomy/engine.py"
      to: "src/app/intelligence/patterns/engine.py"
      via: "PatternRecognitionEngine for insight-driven actions"
      pattern: "pattern_engine"
    - from: "src/app/intelligence/autonomy/scheduler.py"
      to: "src/app/learning/scheduler.py"
      via: "Same asyncio background loop pattern"
      pattern: "start_scheduler_background|TASK_INTERVALS"
---

<objective>
Build the autonomy system -- GuardrailChecker for action classification with three tiers (autonomous/approval/hard-stop), GoalTracker for self-directed revenue target pursuit, AutonomyEngine for guardrail-gated action planning, and ProactiveScheduler for background task scheduling.

Purpose: This is the "autonomy" in Intelligence & Autonomy. The agent transitions from reactive to proactive -- pursuing goals, initiating outreach, and making decisions within clearly defined guardrails.

Output: Four service classes in `src/app/intelligence/autonomy/` with comprehensive tests.
</objective>

<execution_context>
@/Users/RAZER/.claude/get-shit-done/workflows/execute-plan.md
@/Users/RAZER/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-intelligence-autonomy/07-CONTEXT.md
@.planning/phases/07-intelligence-autonomy/07-RESEARCH.md
@.planning/phases/07-intelligence-autonomy/07-01-SUMMARY.md
@src/app/learning/scheduler.py
@src/app/intelligence/autonomy/schemas.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: GuardrailChecker and GoalTracker</name>
  <files>
    src/app/intelligence/autonomy/guardrails.py
    src/app/intelligence/autonomy/goals.py
  </files>
  <action>
    **guardrails.py:** Create `GuardrailChecker` -- the CRITICAL safety mechanism for all autonomous actions.

    Per CONTEXT.md locked decisions, three tiers:

    Class-level constants (sets of action type strings):
    ```python
    AUTONOMOUS_ACTIONS = {
        "send_follow_up_email",
        "send_routine_response",
        "send_chat_message",
        "schedule_meeting",
        "qualify_conversation",
        "progress_early_stage",      # discovery, qualification only
        "update_account_context",
        "create_briefing",
        "log_interaction",
    }
    APPROVAL_REQUIRED = {
        "send_proposal",
        "discuss_pricing",
        "negotiate_terms",
        "progress_past_evaluation",  # negotiation, closing require human
        "contact_c_suite",
        "share_minutes_externally",
        "modify_account_plan",
        "escalate_to_management",
    }
    HARD_STOPS = {
        "commit_pricing",
        "modify_contract",
        "approve_discount",
        "strategic_decision",
        "initiate_executive_relationship",
        "legal_commitment",
        "market_positioning_change",
    }
    ```

    - `check(action: AutonomyAction) -> GuardrailResult`:
      1. If action_type in HARD_STOPS: return GuardrailResult(allowed=False, reason="hard_stop", requires_human=True, action=action)
      2. If action_type in APPROVAL_REQUIRED: return GuardrailResult(allowed=False, reason="approval_required", requires_human=True, action=action)
      3. If action_type in AUTONOMOUS_ACTIONS:
         - Additional stage gate: if action.deal_stage in ("negotiation", "evaluation", "closed_won", "closed_lost"), return blocked with reason="stage_gate"
         - Otherwise: return GuardrailResult(allowed=True, reason="autonomous", requires_human=False, action=action)
      4. UNKNOWN action types: return GuardrailResult(allowed=False, reason="unknown_action_type", requires_human=True, action=action) -- FAIL-SAFE per RESEARCH.md Pitfall 3

    - `classify_action(action_type: str) -> ActionCategory`: Returns the category (autonomous/approval_required/hard_stop) without full check. Used for UI display.
    - `get_allowed_actions() -> set[str]`: Returns AUTONOMOUS_ACTIONS set.
    - `get_restricted_actions() -> dict[str, str]`: Returns {action: reason} for all non-autonomous actions.

    **goals.py:** Create `GoalTracker` for self-directed revenue target pursuit.

    - Constructor takes `repository` (IntelligenceRepository or compatible).
    - `async create_goal(tenant_id: str, goal_type: GoalType, target_value: float, period_start: datetime, period_end: datetime, clone_id: str | None = None) -> Goal`: Creates a new goal. Validates target_value > 0 and period_end > period_start.
    - `async update_progress(tenant_id: str, goal_id: str, current_value: float) -> Goal`: Updates current_value. Checks if goal is now completed (current_value >= target_value) or missed (period_end passed and current_value < target_value). Updates status accordingly.
    - `async get_active_goals(tenant_id: str, clone_id: str | None = None) -> list[Goal]`: Returns active goals for tenant/clone.
    - `async compute_metrics(tenant_id: str, clone_id: str | None = None) -> PerformanceMetrics`: Computes current performance metrics by querying repository. Uses deal data (pipeline, revenue), conversation data (activity counts), and outcome data (quality metrics). Fields that cannot be computed return 0.0 or None.
    - `async check_goal_status(tenant_id: str) -> list[dict]`: Evaluates all active goals. Returns list of {"goal": Goal, "progress_pct": float, "on_track": bool, "days_remaining": int}. On-track heuristic: current_value / target_value >= days_elapsed / total_days.
    - `async suggest_actions(tenant_id: str, goal: Goal) -> list[str]`: Based on goal type and progress, suggest actions. Revenue goal behind -> "Prioritize closing advanced-stage opportunities". Pipeline goal behind -> "Increase outreach cadence to new accounts". Activity goal behind -> "Schedule follow-up meetings with engaged contacts". Returns list of suggestion strings.
    - `_compute_progress_pct(goal: Goal) -> float`: current_value / target_value * 100, capped at 100.0.

    Both classes: structlog logging, `from __future__ import annotations`, standard error handling.
  </action>
  <verify>Run `python -c "from src.app.intelligence.autonomy.guardrails import GuardrailChecker; from src.app.intelligence.autonomy.goals import GoalTracker; print('OK')"` -- imports succeed.</verify>
  <done>GuardrailChecker classifies all actions with fail-safe defaults. GoalTracker tracks revenue targets and suggests corrective actions.</done>
</task>

<task type="auto">
  <name>Task 2: AutonomyEngine, ProactiveScheduler, and comprehensive tests</name>
  <files>
    src/app/intelligence/autonomy/engine.py
    src/app/intelligence/autonomy/scheduler.py
    tests/test_autonomy.py
  </files>
  <action>
    **engine.py:** Create `AutonomyEngine` -- the central autonomous decision-making service.

    - Constructor takes:
      - `guardrail_checker: GuardrailChecker`
      - `goal_tracker: GoalTracker`
      - `pattern_engine: PatternRecognitionEngine` (or compatible)
      - `repository` (IntelligenceRepository or compatible)
      - Optional `llm_service` for action planning

    - `async propose_action(tenant_id: str, action: AutonomyAction) -> GuardrailResult`:
      1. Run guardrail check.
      2. Log the action via `repository.log_autonomous_action()` with guardrail result.
      3. If allowed: return result (caller executes the action).
      4. If approval_required: create ApprovalRequest, store in repository, publish to event bus for notification.
      5. If hard_stop: log and return blocked result.
      6. Return GuardrailResult.

    - `async plan_proactive_actions(tenant_id: str, customer_view: UnifiedCustomerView, clone_id: str | None = None) -> list[AutonomyAction]`:
      1. Check active goals for this tenant/clone.
      2. Detect patterns in customer view.
      3. Based on patterns and goals, generate candidate actions:
         - Buying signal detected -> propose follow-up email (autonomous)
         - Risk indicator -> propose outreach or escalation (may require approval)
         - Goal behind target -> propose increased activity
      4. If llm_service available, use model='fast' with instructor to generate refined action proposals. Response model: list[AutonomyAction].
      5. If llm_service None, use rule-based mapping from patterns to actions.
      6. Return list of proposed actions (NOT yet guardrail-checked -- caller uses propose_action for each).

    - `async execute_approved_action(tenant_id: str, action_id: str) -> dict`:
      1. Load action from repository.
      2. Verify approval_status == "approved".
      3. Execute the action (placeholder -- actual execution delegated to SalesAgent methods).
      4. Update execution_result in repository.
      5. Track outcome via existing OutcomeTracker if available.
      6. Return execution result dict.

    - `async get_pending_approvals(tenant_id: str) -> list[ApprovalRequest]`: List actions awaiting human approval.
    - `async resolve_approval(tenant_id: str, action_id: str, approved: bool, resolved_by: str) -> bool`: Approve or reject a pending action.

    **scheduler.py:** Create `setup_intelligence_scheduler` extending the Phase 4.1 asyncio background loop pattern.

    Task intervals:
    ```python
    INTELLIGENCE_TASK_INTERVALS = {
        "pattern_scan": 6 * 60 * 60,            # Every 6 hours
        "proactive_outreach_check": 60 * 60,     # Every hour
        "goal_progress_update": 24 * 60 * 60,    # Daily
        "daily_digest_generation": 24 * 60 * 60, # Daily
        "context_summarization": 24 * 60 * 60,   # Daily
    }
    ```

    - `async setup_intelligence_scheduler(pattern_engine, autonomy_engine, goal_tracker, insight_generator, customer_view_service) -> dict`:
      Returns dict of task name -> async callable. Each task:
      - Wraps in try/except (individual failures don't crash scheduler)
      - Logs via structlog
      - Pattern scan: scans accounts with recent activity (last 7 days) per RESEARCH.md
      - Proactive outreach: evaluates triggered outreach through guardrails
      - Goal progress: updates goal current_value from latest metrics
      - Daily digest: generates and (if email available) sends daily insight digest
      - Context summarization: runs progressive summarization on stale customer views

    - Reuse `start_scheduler_background` from `src/app/learning/scheduler.py` for actually starting the tasks. The intelligence scheduler returns tasks in the same format (dict of name -> callable) so it plugs directly into the existing start function, but with its own INTELLIGENCE_TASK_INTERVALS. Create a `start_intelligence_scheduler_background(tasks, app_state)` function that mirrors the Phase 4.1 version but stores references as `app.state.intelligence_scheduler_tasks`.

    **tests/test_autonomy.py:** Comprehensive tests:

    1. GuardrailChecker tests (8+):
       - `test_autonomous_action_allowed` -- "send_follow_up_email" allowed
       - `test_approval_required` -- "send_proposal" needs approval
       - `test_hard_stop_blocked` -- "commit_pricing" always blocked
       - `test_hard_stop_requires_human` -- requires_human=True
       - `test_unknown_action_fails_safe` -- "some_random_action" -> approval_required (fail-safe)
       - `test_stage_gate_negotiation` -- autonomous action blocked in negotiation stage
       - `test_stage_gate_discovery` -- autonomous action allowed in discovery stage
       - `test_classify_action` -- returns correct ActionCategory

    2. GoalTracker tests (5+):
       - `test_create_goal` -- valid goal created
       - `test_create_goal_invalid_target` -- ValueError for target <= 0
       - `test_update_progress_completed` -- status changes to completed when target met
       - `test_check_goal_on_track` -- on_track=True when progress matches elapsed time
       - `test_suggest_actions_revenue_behind` -- suggests closing activities

    3. AutonomyEngine tests (4+):
       - `test_propose_autonomous_action` -- allowed action returns allowed=True
       - `test_propose_hard_stop` -- hard stop logged and blocked
       - `test_plan_proactive_actions_buying_signal` -- buying signal -> follow-up action
       - `test_plan_proactive_actions_no_patterns` -- no patterns -> empty list

    4. Scheduler tests (2+):
       - `test_setup_intelligence_scheduler_returns_all_tasks` -- 5 tasks returned
       - `test_task_intervals_defined` -- all 5 intervals have values

    Use in-memory test doubles for repository and pattern engine. No database dependency.
  </action>
  <verify>Run `python -m pytest tests/test_autonomy.py -v` -- all tests pass.</verify>
  <done>AutonomyEngine routes all actions through guardrails. GoalTracker tracks revenue targets. ProactiveScheduler runs 5 background tasks. 19+ tests pass.</done>
</task>

</tasks>

<verification>
- `python -m pytest tests/test_autonomy.py -v` -- all tests pass
- GuardrailChecker: hard_stop actions NEVER allowed (verify all 7 hard_stop types)
- Unknown actions default to approval_required (fail-safe)
- Stage gates block autonomous actions in negotiation/evaluation/closed stages
- GoalTracker computes progress and suggests corrective actions
- ProactiveScheduler defines 5 background tasks with correct intervals
</verification>

<success_criteria>
- GuardrailChecker implements exact three-tier classification from CONTEXT.md
- Unknown actions fail safe to approval_required (NEVER autonomous)
- GoalTracker tracks all 4 metric types (pipeline, activity, quality, revenue)
- AutonomyEngine gates every action through guardrails before execution
- ProactiveScheduler extends Phase 4.1 asyncio pattern with 5 intelligence tasks
- 19+ tests pass with no database dependency
</success_criteria>

<output>
After completion, create `.planning/phases/07-intelligence-autonomy/07-05-SUMMARY.md`
</output>
