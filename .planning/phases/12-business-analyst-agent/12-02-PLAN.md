---
phase: 12-business-analyst-agent
plan: 02
type: execute
wave: 2
depends_on: ["12-01"]
files_modified:
  - src/app/agents/business_analyst/agent.py
  - src/app/agents/business_analyst/capabilities.py
  - src/app/agents/business_analyst/__init__.py
autonomous: true

must_haves:
  truths:
    - "BA agent routes tasks to 4 specialized handlers by task_type"
    - "Each handler follows fail-open pattern returning error dict on failure"
    - "Gap analysis handler includes contradiction detection in same output"
    - "Requirements extraction uses single LLM call for all requirements"
    - "Gap analysis escalates to SA agent when requires_sa_escalation is True"
  artifacts:
    - path: "src/app/agents/business_analyst/agent.py"
      provides: "BusinessAnalystAgent(BaseAgent) with 4 capability handlers"
      exports: ["BusinessAnalystAgent"]
      min_lines: 150
    - path: "src/app/agents/business_analyst/capabilities.py"
      provides: "BA_CAPABILITIES list + create_ba_registration factory"
      exports: ["BA_CAPABILITIES", "create_ba_registration"]
    - path: "src/app/agents/business_analyst/__init__.py"
      provides: "Full package exports including agent + capabilities"
      exports: ["BusinessAnalystAgent", "BA_CAPABILITIES", "create_ba_registration"]
  key_links:
    - from: "src/app/agents/business_analyst/agent.py"
      to: "src/app/agents/business_analyst/prompts.py"
      via: "import and call prompt builders"
      pattern: "build_requirements_extraction_prompt|build_gap_analysis_prompt"
    - from: "src/app/agents/business_analyst/agent.py"
      to: "src/app/agents/business_analyst/schemas.py"
      via: "parse LLM output into Pydantic models"
      pattern: "ExtractedRequirement|GapAnalysisResult|UserStory|ProcessDocumentation"
    - from: "src/app/agents/business_analyst/agent.py"
      to: "src/app/agents/base"
      via: "BaseAgent subclass"
      pattern: "class BusinessAnalystAgent\\(BaseAgent\\)"
    - from: "src/app/agents/business_analyst/agent.py"
      to: "src/app/agents/solution_architect"
      via: "lazy import SA dispatch in _handle_gap_analysis for escalation"
      pattern: "dispatch_technical_question|sa_escalation"
---

<objective>
Implement the BusinessAnalystAgent core: 4 capability handlers (requirements_extraction, gap_analysis, user_story_generation, process_documentation), the capabilities declaration, and full package init.

Purpose: This is the agent brain -- the handlers that turn conversation text into structured requirements, gap analysis, user stories, and process docs via LLM calls.
Output: agent.py (BusinessAnalystAgent with 4 handlers), capabilities.py (4 capabilities + registration factory), __init__.py (full exports)
</objective>

<execution_context>
@/Users/RAZER/.claude/get-shit-done/workflows/execute-plan.md
@/Users/RAZER/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12-business-analyst-agent/12-CONTEXT.md
@.planning/phases/12-business-analyst-agent/12-RESEARCH.md

# Pattern references -- clone these structures exactly
@src/app/agents/solution_architect/agent.py
@src/app/agents/solution_architect/capabilities.py
@src/app/agents/solution_architect/__init__.py
@src/app/agents/base.py

# Dependencies from plan 01
@src/app/agents/business_analyst/schemas.py
@src/app/agents/business_analyst/prompts.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement BusinessAnalystAgent with 4 capability handlers</name>
  <files>src/app/agents/business_analyst/agent.py</files>
  <action>
Create `agent.py` following the SolutionArchitectAgent pattern exactly.

**Class: BusinessAnalystAgent(BaseAgent)**

Constructor takes:
- `registration: AgentRegistration`
- `llm_service: object` (LLMService or compatible)
- `rag_pipeline: object | None = None` (for Qdrant KB queries in gap analysis)
Call `super().__init__(registration)`. Store `_llm_service`, `_rag_pipeline`, and create `_log` bound logger with agent_id and agent_name.

**Task Router -- `async def execute(self, task: dict[str, Any], context: dict[str, Any]) -> dict[str, Any]`:**
Route by `task["type"]`:
```python
handlers = {
    "requirements_extraction": self._handle_requirements_extraction,
    "gap_analysis": self._handle_gap_analysis,
    "user_story_generation": self._handle_user_story_generation,
    "process_documentation": self._handle_process_documentation,
}
```
Unknown type returns `{"error": f"Unknown task type: {task_type}", "confidence": "low", "partial": True}`.

Add a code comment on the unknown-type return explaining the design choice:
```python
# Intentionally fail-open: return error dict rather than raise ValueError
# to keep the sales workflow unblocked. SA/PM agents raise ValueError for
# unknown types, but BA is called from the sales flow where an exception
# would halt the conversation. This divergence is deliberate.
```

**Handler 1: `_handle_requirements_extraction`**
- Extract `conversation_text` and optional `deal_context` from task
- Call `build_requirements_extraction_prompt(conversation_text, deal_context)`
- Single LLM call with `BA_SYSTEM_PROMPT` as system, prompt as user. Temperature 0.3 for JSON reliability.
- Parse response JSON into `list[ExtractedRequirement]` using Pydantic
- Return `BAResult(task_type="requirements_extraction", requirements=requirements, confidence=...)`.model_dump()
- Fail-open: on any exception, log error and return `{"task_type": "requirements_extraction", "error": str(e), "confidence": "low", "partial": True}`

**Handler 2: `_handle_gap_analysis`**
- Extract `conversation_text` from task, plus optional `existing_requirements`
- If no existing_requirements, first run requirements extraction internally (reuse handler 1 logic as a helper)
- Query Qdrant for product capability chunks: use `_rag_pipeline` with content_type="product" filter if available; if rag_pipeline is None, use empty list and log warning
- Call `build_gap_analysis_prompt(requirements_dicts, capability_chunks)`
- Single LLM call, temperature 0.3
- Parse into `GapAnalysisResult` (includes gaps + contradictions in same struct)
- **SA Escalation (LOCKED DECISION from CONTEXT.md):** After parsing GapAnalysisResult, check if `result.requires_sa_escalation is True`. If so:
  1. Lazy-import the SA dispatch mechanism inside this block (same pattern as `dispatch_technical_question` in Sales Agent -- import inside function body to avoid circular deps):
     ```python
     if result.requires_sa_escalation:
         try:
             # Lazy import to avoid circular dependency
             from src.app.agents.solution_architect.schemas import SAHandoffRequest

             # Build escalation payload with the critical gap descriptions
             escalation_gaps = [
                 g for g in result.gaps if g.recommended_action != "descope_it"
             ]
             gap_descriptions = "; ".join(
                 f"{g.requirement_id}: {g.gap_description}" for g in escalation_gaps
             )

             sa_request = SAHandoffRequest(
                 question=f"BA gap escalation: {gap_descriptions}",
                 deal_id=task.get("deal_id", ""),
                 tenant_id=context.get("tenant_id", ""),
             )

             escalation_dispatched = True
             self._log.info(
                 "gap_analysis.sa_escalation_dispatched",
                 deal_id=task.get("deal_id", ""),
                 gap_count=len(escalation_gaps),
             )
         except Exception as esc_err:
             escalation_dispatched = False
             self._log.warning(
                 "gap_analysis.sa_escalation_failed",
                 error=str(esc_err),
             )
     else:
         escalation_dispatched = False
     ```
  2. Include `escalation_dispatched` flag in the returned dict alongside the BAResult fields.
  NOTE: Check the SA agent's existing schemas to confirm the correct import path and field names for SAHandoffRequest. If SAHandoffRequest doesn't exist, use whatever handoff schema the SA agent accepts (e.g., a plain dict with question/deal_id/tenant_id fields). The key behavior is: construct the escalation payload and signal that escalation was dispatched.
- Return `BAResult(task_type="gap_analysis", requirements=result.requirements, gap_analysis=result, confidence=...)`.model_dump() merged with `{"escalation_dispatched": escalation_dispatched}` if applicable
- Fail-open pattern

**Handler 3: `_handle_user_story_generation`**
- Extract `existing_requirements` from task (list of requirement dicts)
- If empty, extract from `conversation_text` first (same internal helper)
- Call `build_user_story_generation_prompt(requirements_dicts)`
- Single LLM call, temperature 0.4 (slightly higher for creative story writing)
- Parse into `list[UserStory]`
- Return `BAResult(task_type="user_story_generation", user_stories=stories, confidence=...)`.model_dump()
- Fail-open pattern

**Handler 4: `_handle_process_documentation`**
- Extract `conversation_text` and optional `process_context` from task
- Call `build_process_documentation_prompt(conversation_text, process_context)`
- Single LLM call, temperature 0.3
- Parse into `ProcessDocumentation`
- Return `BAResult(task_type="process_documentation", process_documentation=doc, confidence=...)`.model_dump()
- Fail-open pattern

**Helper: `_extract_json_from_response(self, text: str) -> str`**
Same pattern as SA agent: strip markdown code fences, find JSON array or object. Use `re.search(r'[\[{]', text)` to find start, then parse.

**Helper: `_get_product_capabilities(self, tenant_id: str, query: str) -> list[str]`**
Async method that queries rag_pipeline for product content_type chunks. If rag_pipeline is None, return empty list. Wraps in try/except for fail-open.

**LLM call pattern** (same as SA):
```python
response = await self._llm_service.generate(
    messages=[
        {"role": "system", "content": BA_SYSTEM_PROMPT},
        {"role": "user", "content": prompt},
    ],
    temperature=0.3,
)
raw_text = response.content if hasattr(response, 'content') else str(response)
```

Use `from __future__ import annotations`, `import json`, `import re`, `from typing import Any`, `import structlog`. Import all needed schemas and prompt builders.
  </action>
  <verify>
Run: `cd "/Users/RAZER/Documents/projects/sales army" && python -c "
from src.app.agents.business_analyst.agent import BusinessAnalystAgent
from src.app.agents.base import AgentRegistration
print('BusinessAnalystAgent imports OK')
# Verify it's a BaseAgent subclass
from src.app.agents.base import BaseAgent
assert issubclass(BusinessAnalystAgent, BaseAgent), 'Not a BaseAgent subclass'
print('BaseAgent subclass verified')
"` -- must succeed.

Run: `cd "/Users/RAZER/Documents/projects/sales army" && grep -n 'requires_sa_escalation' src/app/agents/business_analyst/agent.py` -- must find the escalation check in _handle_gap_analysis.

Run: `cd "/Users/RAZER/Documents/projects/sales army" && grep -n 'Intentionally fail-open' src/app/agents/business_analyst/agent.py` -- must find the design comment on the unknown-type error path.
  </verify>
  <done>
BusinessAnalystAgent class exists as BaseAgent subclass with 4 handler methods, task router, JSON extraction helper, and product capabilities helper. All handlers follow fail-open pattern. Gap analysis handler dispatches SA escalation when requires_sa_escalation is True (locked CONTEXT.md decision). Unknown-type error path has explanatory code comment documenting the intentional divergence from SA/PM agents.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create capabilities declaration and full package init</name>
  <files>
    src/app/agents/business_analyst/capabilities.py
    src/app/agents/business_analyst/__init__.py
  </files>
  <action>
**capabilities.py** -- Follow SA capabilities.py pattern exactly:

Define `BA_CAPABILITIES: list[AgentCapability]` with 4 entries:
1. `extract_requirements` -- "Extract structured requirements from conversations, categorizing by type (functional/non-functional/constraint), MoSCoW priority, and stakeholder domain"
   - output_schema: `BAResult`
2. `analyze_gaps` -- "Compare stated requirements against product capabilities, identify coverage gaps with recommended actions, and detect requirement contradictions"
   - output_schema: `GapAnalysisResult`
3. `generate_user_stories` -- "Convert business requirements into agile user stories with acceptance criteria, story points, and dual-grouping by epic and stakeholder domain"
   - output_schema: `BAResult`
4. `document_process` -- "Produce process documentation from workflow conversations showing current state, future state, and delta"
   - output_schema: `ProcessDocumentation`

Define `create_ba_registration() -> AgentRegistration`:
- agent_id: "business_analyst"
- name: "Business Analyst"
- description: "Requirements engineering agent that extracts requirements, performs gap analysis, generates user stories, and produces process documentation from sales conversations"
- capabilities: BA_CAPABILITIES
- backup_agent_id: None
- tags: ["requirements", "analysis", "user-stories", "process-docs", "gap-analysis"]
- max_concurrent_tasks: 3

**__init__.py** -- Expand to include full exports (agent + capabilities + schemas):
```python
"""Business Analyst Agent for requirements gathering and analysis.

Exports:
    BusinessAnalystAgent: Core business analyst agent class.
    BA_CAPABILITIES: List of 4 typed capabilities.
    create_ba_registration: Factory for AgentRegistration.
    [all schema exports from plan 01]
"""
from src.app.agents.business_analyst.agent import BusinessAnalystAgent
from src.app.agents.business_analyst.capabilities import (
    BA_CAPABILITIES,
    create_ba_registration,
)
from src.app.agents.business_analyst.schemas import (
    BAHandoffRequest,
    BAHandoffResponse,
    BAResult,
    BATask,
    CapabilityGap,
    ExtractedRequirement,
    GapAnalysisResult,
    ProcessDocumentation,
    RequirementContradiction,
    UserStory,
)

__all__ = [
    "BA_CAPABILITIES",
    "BAHandoffRequest",
    "BAHandoffResponse",
    "BAResult",
    "BATask",
    "BusinessAnalystAgent",
    "CapabilityGap",
    "ExtractedRequirement",
    "GapAnalysisResult",
    "ProcessDocumentation",
    "RequirementContradiction",
    "UserStory",
    "create_ba_registration",
]
```
  </action>
  <verify>
Run: `cd "/Users/RAZER/Documents/projects/sales army" && python -c "
from src.app.agents.business_analyst import (
    BusinessAnalystAgent,
    BA_CAPABILITIES,
    create_ba_registration,
    BATask,
    BAResult,
    ExtractedRequirement,
    UserStory,
    GapAnalysisResult,
)
reg = create_ba_registration()
assert reg.agent_id == 'business_analyst'
assert len(BA_CAPABILITIES) == 4
print(f'BA registration: {reg.agent_id}, {len(BA_CAPABILITIES)} capabilities')
print('Full package init OK')
"` -- must succeed.
  </verify>
  <done>
BA_CAPABILITIES declares 4 capabilities. create_ba_registration produces AgentRegistration with agent_id="business_analyst". __init__.py exports all schemas, agent class, capabilities, and registration factory.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from src.app.agents.business_analyst import BusinessAnalystAgent, create_ba_registration; r = create_ba_registration(); print(r.agent_id, len(r.capabilities))"` -- prints "business_analyst 4"
2. `python -c "from src.app.agents.business_analyst.agent import BusinessAnalystAgent; print(BusinessAnalystAgent.__mro__)"` -- shows BaseAgent in MRO
3. `grep -n 'requires_sa_escalation' src/app/agents/business_analyst/agent.py` -- escalation logic present
4. `grep -n 'Intentionally fail-open' src/app/agents/business_analyst/agent.py` -- design comment present
5. Existing tests still pass: `cd "/Users/RAZER/Documents/projects/sales army" && python -m pytest tests/ -x -q --timeout=30 2>&1 | tail -5`
</verification>

<success_criteria>
- BusinessAnalystAgent extends BaseAgent with 4 handler methods
- Task router dispatches by task["type"] to correct handler
- All handlers follow fail-open pattern (return error dict, never raise)
- Gap analysis handler escalates to SA agent when requires_sa_escalation is True (lazy import, fail-tolerant)
- Unknown-type error path has explanatory code comment documenting intentional divergence from SA/PM
- Capabilities declared for all 4 task types
- Package init exports everything
- Existing tests unbroken
</success_criteria>

<output>
After completion, create `.planning/phases/12-business-analyst-agent/12-02-SUMMARY.md`
</output>
