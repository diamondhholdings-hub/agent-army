# Phase 4.1: Agent Learning & Performance Feedback - Context

**Gathered:** 2026-02-11
**Status:** Ready for planning

<domain>
## Phase Boundary

A learning and feedback system that captures outcomes from agent interactions, collects human judgments on agent actions, calibrates confidence predictions against actual results, surfaces performance analytics to stakeholders, and extracts coaching patterns for sales teams -- enabling the Sales Agent to continuously improve and provide insights to human sales teams.

This phase builds on Phase 4's Sales Agent Core, adding the learning infrastructure that makes the agent smarter over time.

</domain>

<decisions>
## Implementation Decisions

### Outcome Signal Detection
- **Track multiple outcome types**: Customer engagement (replied, opened, clicked), deal progression (stage advancement, new opportunities created), and meeting outcomes (scheduled, attended, positive feedback)
- **Hybrid timing approach**: Layer three signal types:
  - Immediate signals (24h window): email opened, replied, link clicked
  - Time-windowed signals: 7 days for engagement outcomes, 30 days for deal progression
  - Event-based signals: recorded when definitive events occur (deal closed, meeting happened, explicit customer action)
- **Outcome-specific scoring scales**: Different granularity per outcome type (e.g., email engagement might be binary success/failure, deal progression might be 5-level, meeting outcomes 3-level)
- **Hybrid detection**: Automatic for clear signals (email bounced = negative, deal moved to next stage = positive), human labeling required for ambiguous situations

### Feedback Collection Interface
- **Dual interface**: Both inline reactions (Slack/Gmail) for quick feedback + dedicated review dashboard for detailed feedback
- **Context-dependent feedback targets**:
  - Individual messages get quick inline reactions
  - Agent decisions (escalation, stage changes, next actions) get explicit feedback prompts
  - Full conversation threads get retrospective reviews
- **Rating + optional free text**: Quick rating (thumbs up/down or 3-5 level scale) required, optional text comments for details when human wants to elaborate
- **Hybrid workflow**: Real-time prompts for critical actions (escalations, stage changes), on-demand feedback for routine actions (humans can provide feedback anytime but aren't prompted unless critical)

### Confidence Calibration
- **Per-action-type calibration**: Separate calibration curves for email confidence, meeting confidence, escalation confidence, stage progression confidence (recognizes that agent might be well-calibrated for one action type but not another)
- **Continuous updates**: Every new outcome updates calibration in real-time (not batch or periodic)
- **Statistical method**: Claude's discretion on detection approach (likely calibration curves plotting predicted confidence vs actual success rate, or proper scoring rules like Brier score depending on data volume)
- **Auto-adjust behavior**: When miscalibration detected, automatically adjust both confidence scores AND agent behavior (escalation thresholds, action selection) -- agent becomes more/less cautious based on calibration

### Analytics Presentation
- **Role-appropriate views for all audiences**:
  - Sales reps: Their individual agent's performance, response rates, escalation history, deal impact
  - Sales managers: Team-level trends, aggregate patterns, coaching opportunities, comparative performance
  - Executives/founders: Strategic insights, ROI metrics, agent effectiveness vs human baseline, investment decisions
- **Layered format**:
  - Dashboard for ad-hoc exploration (web UI with interactive charts)
  - Reports for routine updates (emailed or Slack summaries)
  - Alerts for urgent attention (threshold-based notifications for anomalies)
- **Mixed timing**: Real-time dashboards (always live for ad-hoc queries) + periodic reports (likely daily for managers, weekly for executives)
- **Comprehensive metric categories**:
  - Performance: Outcome signals, response rates, deal progression impact, customer engagement trends
  - Quality: Human feedback scores, confidence calibration accuracy, escalation appropriateness
  - Efficiency: Cost per interaction, escalation rate, time saved vs human baseline, ROI calculations

### Claude's Discretion
- Exact statistical method for calibration (calibration curves vs Brier score vs log-loss)
- Dashboard UI design and chart types
- Report formatting and delivery channels
- Alert threshold values (when to notify about anomalies)
- Specific rating scale implementations (3-level vs 5-level per target type)

</decisions>

<specifics>
## Specific Ideas

No specific product references or examples provided -- open to standard approaches for learning systems and analytics dashboards.

Key design principles from discussion:
- Feedback should be low-friction (inline reactions) but allow richness when needed (dashboard reviews)
- Calibration should be automatic and actionable (not just monitoring)
- Analytics should meet different stakeholders where they are (not one-size-fits-all dashboard)
- Outcome tracking should capture both immediate signals and long-term impacts (layered approach)

</specifics>

<deferred>
## Deferred Ideas

None -- discussion stayed within phase scope.

</deferred>

---

*Phase: 04.1-agent-learning-performance-feedback*
*Context gathered: 2026-02-11*
