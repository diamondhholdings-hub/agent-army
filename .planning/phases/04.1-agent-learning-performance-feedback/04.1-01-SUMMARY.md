---
phase: 04.1-agent-learning-performance-feedback
plan: 01
subsystem: database, learning
tags: [sqlalchemy, pydantic, alembic, outcome-tracking, calibration, feedback, rls, tenant-isolation]

# Dependency graph
requires:
  - phase: 04-sales-agent-core
    provides: ConversationStateModel, TenantBase, session_factory pattern, DealStage enum
provides:
  - OutcomeRecordModel, FeedbackEntryModel, CalibrationBinModel SQLAlchemy models
  - Pydantic schemas for outcomes, feedback, calibration, analytics API
  - OutcomeTracker service for recording and resolving agent action outcomes
  - Alembic migration with RLS policies for all three tables
  - InMemoryOutcomeTracker test double for downstream test usage
affects: [04.1-02-feedback-collection, 04.1-03-calibration-engine, 04.1-04-analytics, 04.1-05-coaching-patterns]

# Tech tracking
tech-stack:
  added: []
  patterns:
    - "OutcomeTracker session_factory pattern (same as ConversationStateRepository)"
    - "Time-windowed signal detection with configurable window durations per outcome type"
    - "SELECT FOR UPDATE SKIP LOCKED for race condition prevention in outcome resolution"
    - "InMemoryOutcomeTracker test double pattern for unit testing without database"
    - "Per-action-type calibration bins (10 bins per action type per tenant)"

key-files:
  created:
    - src/app/learning/__init__.py
    - src/app/learning/models.py
    - src/app/learning/schemas.py
    - src/app/learning/outcomes.py
    - alembic/versions/add_learning_outcome_feedback_tables.py
    - tests/test_learning_outcomes.py
  modified: []

key-decisions:
  - "OutcomeTracker uses session_factory callable pattern matching ConversationStateRepository for consistent async DB access"
  - "Time windows: 24h email engagement, 168h meeting/escalation, 720h deal progression (from CONTEXT.md locked decisions)"
  - "Deal progression scoring: 0.2 per stage advanced, capped at 1.0"
  - "Immediate signal detection via interaction_count comparison (reply = positive)"
  - "Bulk expire via single UPDATE statement for performance"
  - "CalibrationBin with unique constraint on (tenant_id, action_type, bin_index) for exactly 10 bins per action type"
  - "FeedbackEntry supports dual rating: -1/0/1 for inline, 1-5 for dashboard (single rating field)"

patterns-established:
  - "Learning module pattern: src/app/learning/ as new domain module with models, schemas, service"
  - "InMemory test double for OutcomeTracker: stores in dict, mirrors service interface"
  - "Outcome signal detection: background-compatible methods (check_immediate_signals, check_deal_progression_signals, expire_overdue_outcomes)"

# Metrics
duration: 5min
completed: 2026-02-12
---

# Phase 4.1 Plan 01: Outcome Tracking Data Foundation Summary

**Three tenant-scoped SQLAlchemy models (OutcomeRecord, FeedbackEntry, CalibrationBin), Pydantic schemas for all learning domain types, OutcomeTracker service with time-windowed signal detection, and 29 passing tests**

## Performance

- **Duration:** 5 min
- **Started:** 2026-02-12T04:50:59Z
- **Completed:** 2026-02-12T04:56:39Z
- **Tasks:** 2
- **Files created:** 6

## Accomplishments
- Three SQLAlchemy models with TenantBase, composite indexes, and RLS policies for tenant isolation
- Comprehensive Pydantic schemas covering enums, core types, window configs, calibration curves, and API request/response
- OutcomeTracker service with record, resolve, query, expire, and two signal detection methods
- Alembic migration creating all three tables with RLS policies and indexes
- 29 new tests, full suite at 425/425 passing (29 new + 396 existing)

## Task Commits

Each task was committed atomically:

1. **Task 1: Create learning module with SQLAlchemy models, Pydantic schemas, and migration** - `42e9f6f` (feat)
2. **Task 2: Create OutcomeTracker service with signal detection and tests** - `5a5fd8b` (feat)

## Files Created/Modified
- `src/app/learning/__init__.py` - Learning module init with docstring
- `src/app/learning/models.py` - OutcomeRecordModel, FeedbackEntryModel, CalibrationBinModel with TenantBase
- `src/app/learning/schemas.py` - Pydantic schemas: enums, core types, window config, calibration, API request/response
- `src/app/learning/outcomes.py` - OutcomeTracker service with signal detection and race condition protection
- `alembic/versions/add_learning_outcome_feedback_tables.py` - Migration for 3 tables with RLS and indexes
- `tests/test_learning_outcomes.py` - 29 tests with InMemoryOutcomeTracker test double

## Decisions Made
- OutcomeTracker uses session_factory callable pattern matching ConversationStateRepository for consistent async DB access
- Time windows configured per CONTEXT.md: 24h (email), 168h (meeting/escalation), 720h (deal progression)
- Deal progression scoring at 0.2 per stage advanced (max 1.0) provides graduated positive signals
- Immediate signal detection uses interaction_count_at_creation metadata for reply detection
- Bulk expiry via single UPDATE statement (not per-row) for O(1) database operations
- CalibrationBin unique constraint ensures exactly one bin per (tenant, action_type, bin_index)
- FeedbackEntry uses single rating field supporting both inline (-1/0/1) and dashboard (1-5) scale

## Deviations from Plan

### Auto-fixed Issues

**1. [Rule 1 - Bug] Fixed floating point comparison in multi-stage progression test**
- **Found during:** Task 2 (test execution)
- **Issue:** `3 * 0.2` produces `0.6000000000000001` in Python, causing strict equality assertion to fail
- **Fix:** Changed to `pytest.approx(0.6)` for float comparison
- **Files modified:** tests/test_learning_outcomes.py
- **Verification:** All 29 tests pass
- **Committed in:** 5a5fd8b (Task 2 commit)

---

**Total deviations:** 1 auto-fixed (1 bug fix)
**Impact on plan:** Trivial float precision fix. No scope creep.

## Issues Encountered
None beyond the float comparison fix above.

## User Setup Required
None - no external service configuration required.

## Next Phase Readiness
- OutcomeRecordModel, FeedbackEntryModel, CalibrationBinModel ready for downstream plans
- OutcomeTracker service ready for integration with SalesAgent execute() hooks
- InMemoryOutcomeTracker available for downstream plan tests
- Pydantic schemas ready for API endpoint development (plan 03)
- CalibrationBin model ready for CalibrationEngine (plan 02)
- No blockers for plan 02 (feedback collection) or plan 03 (calibration engine)

---
*Phase: 04.1-agent-learning-performance-feedback*
*Completed: 2026-02-12*
