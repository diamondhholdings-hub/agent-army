---
phase: 02-agent-orchestration
plan: 04
type: execute
wave: 1
depends_on: []
files_modified:
  - src/app/context/__init__.py
  - src/app/context/session.py
  - src/app/context/memory.py
  - src/app/context/working.py
  - src/app/context/manager.py
  - tests/test_context.py
  - alembic/versions/add_pgvector_and_memory_table.py
autonomous: true

must_haves:
  truths:
    - "Session state persists across conversation turns via PostgreSQL checkpointer and is retrievable by thread_id"
    - "Long-term memory facts are stored with embeddings and retrievable via semantic similarity search"
    - "Working context compiles from session history + relevant memories + task data within a token budget"
    - "Context is tenant-scoped -- one tenant's memories are never visible to another tenant"
  artifacts:
    - path: "src/app/context/session.py"
      provides: "SessionStore wrapping LangGraph AsyncPostgresSaver"
      exports: ["SessionStore"]
    - path: "src/app/context/memory.py"
      provides: "LongTermMemory with pgvector semantic search"
      exports: ["LongTermMemory", "MemoryEntry"]
    - path: "src/app/context/working.py"
      provides: "WorkingContextCompiler with token budget enforcement"
      exports: ["WorkingContextCompiler"]
    - path: "src/app/context/manager.py"
      provides: "ContextManager orchestrating all three tiers"
      exports: ["ContextManager"]
    - path: "tests/test_context.py"
      provides: "Unit tests for session, memory, working context, and manager"
      min_lines: 80
  key_links:
    - from: "src/app/context/session.py"
      to: "langgraph-checkpoint-postgres"
      via: "AsyncPostgresSaver for session persistence"
      pattern: "AsyncPostgresSaver|checkpointer"
    - from: "src/app/context/memory.py"
      to: "pgvector"
      via: "Vector similarity search for memory retrieval"
      pattern: "pgvector|embedding|cosine"
    - from: "src/app/context/working.py"
      to: "tiktoken"
      via: "Token counting for budget enforcement"
      pattern: "tiktoken|num_tokens|token_budget"
    - from: "src/app/context/manager.py"
      to: "all three context tiers"
      via: "orchestrates session + memory + working"
      pattern: "SessionStore|LongTermMemory|WorkingContextCompiler"
---

<objective>
Build the three-tier context management system: session state (PostgreSQL checkpointer), long-term memory (pgvector semantic search), and working context (compiled per-invocation with token budget).

Purpose: PLT-06 requires three-tier context management following the Google ADK pattern. LOCKED DECISIONS: session persistence is explicit-clear-only (no time-based expiration), long-term memory is searchable knowledge base with permanent record, working context scope/size is Claude's discretion. The research recommends: 15% system prompt, 35% session history, 35% retrieved context, 15% task + response buffer.

Output: Complete context/ package with SessionStore (LangGraph checkpointer), LongTermMemory (pgvector), WorkingContextCompiler (tiktoken budget), and ContextManager (orchestrator).
</objective>

<execution_context>
@/Users/RAZER/.claude/get-shit-done/workflows/execute-plan.md
@/Users/RAZER/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-agent-orchestration/02-CONTEXT.md
@.planning/phases/02-agent-orchestration/02-RESEARCH.md
@src/app/core/database.py
@src/app/core/tenant.py
@src/app/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create SessionStore and LongTermMemory</name>
  <files>src/app/context/__init__.py, src/app/context/session.py, src/app/context/memory.py, alembic/versions/add_pgvector_and_memory_table.py</files>
  <action>
1. Create src/app/context/__init__.py with exports for SessionStore, LongTermMemory, MemoryEntry, WorkingContextCompiler, ContextManager.

2. Create src/app/context/session.py with SessionStore class:
   - Wraps LangGraph's AsyncPostgresSaver for session state persistence.
   - __init__(self, database_url: str) -- stores the database URL for creating checkpointer
   - async setup(self) -> None -- creates AsyncPostgresSaver from conn_string, calls setup() to create tables
   - self._checkpointer: AsyncPostgresSaver (initialized in setup)
   - @property checkpointer -> AsyncPostgresSaver (for passing to LangGraph graph.compile(checkpointer=...))
   - async get_session_messages(self, thread_id: str, limit: int = 50) -> list[dict] -- retrieves recent messages from checkpointer state for a thread. Uses checkpointer.aget({"configurable": {"thread_id": thread_id}}) to get the latest checkpoint, extracts messages from channel_values.
   - async clear_session(self, thread_id: str) -> None -- (LOCKED DECISION: explicit clear only) Clears session state for a thread. Uses checkpointer internal API or writes empty state.
   - Note: The AsyncPostgresSaver requires a synchronous database URL format (postgresql://, not postgresql+asyncpg://). Store both formats or derive sync URL from async URL by replacing the scheme.

3. Create src/app/context/memory.py:

   MemoryEntry Pydantic model:
   - memory_id: str (default uuid4)
   - tenant_id: str
   - agent_id: str (which agent stored this memory)
   - content: str (the factual content)
   - metadata: dict[str, Any] = {} (e.g., {"source": "crm", "deal_id": "123", "customer": "Acme"})
   - embedding: list[float] | None = None (populated during store)
   - created_at: datetime (default utcnow)
   - updated_at: datetime (default utcnow)

   LongTermMemory class:
   - __init__(self, database_url: str, embedding_model: str = "text-embedding-3-small")
   - async setup(self) -> None -- ensures pgvector extension exists ("CREATE EXTENSION IF NOT EXISTS vector"), creates memories table in shared schema if not exists:
     CREATE TABLE IF NOT EXISTS shared.agent_memories (
       id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
       tenant_id TEXT NOT NULL,
       agent_id TEXT NOT NULL,
       content TEXT NOT NULL,
       metadata JSONB DEFAULT '{}',
       embedding vector(1536),
       created_at TIMESTAMPTZ DEFAULT now(),
       updated_at TIMESTAMPTZ DEFAULT now()
     );
     CREATE INDEX IF NOT EXISTS idx_memories_tenant ON shared.agent_memories(tenant_id);
     CREATE INDEX IF NOT EXISTS idx_memories_embedding ON shared.agent_memories USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);
   - async store(self, entry: MemoryEntry) -> str -- generates embedding via LiteLLM (litellm.aembedding(model=self._embedding_model, input=[entry.content])), stores in shared.agent_memories with tenant_id, returns memory_id
   - async search(self, tenant_id: str, query: str, limit: int = 10, agent_id: str | None = None) -> list[MemoryEntry] -- generates query embedding, performs cosine similarity search filtered by tenant_id (and optionally agent_id), returns top-k results ordered by similarity
   - async delete(self, memory_id: str, tenant_id: str) -> bool -- deletes memory, validates tenant_id matches (prevents cross-tenant deletion)
   - async list_by_tenant(self, tenant_id: str, limit: int = 50) -> list[MemoryEntry] -- lists memories for a tenant ordered by recency

   Note: Use raw SQL via asyncpg for vector operations since SQLAlchemy pgvector integration adds complexity. Use the existing get_engine() for connection management. Tenant isolation is enforced by WHERE tenant_id = $1 in every query.

4. Create an Alembic migration (or a setup script -- prefer setup() method over migration for flexibility):
   The LongTermMemory.setup() method handles table creation, so no separate Alembic migration is strictly needed. But if the project uses Alembic migrations for all schema changes, create one:
   - alembic/versions/add_pgvector_and_memory_table.py
   - upgrade(): CREATE EXTENSION IF NOT EXISTS vector; CREATE TABLE shared.agent_memories...
   - downgrade(): DROP TABLE shared.agent_memories; (don't drop extension)
   - Use branch_labels=("shared",) to match existing Alembic pattern from Phase 1
  </action>
  <verify>
Run: `python -c "from src.app.context.session import SessionStore; from src.app.context.memory import LongTermMemory, MemoryEntry; print('Context imports OK')"` succeeds.
Run: `python -c "from src.app.context.memory import MemoryEntry; m = MemoryEntry(tenant_id='t1', agent_id='a1', content='Customer budget is 50k'); print(f'Memory: {m.content}')"` succeeds.
  </verify>
  <done>SessionStore wraps AsyncPostgresSaver for session persistence with explicit-clear-only lifetime. LongTermMemory uses pgvector for tenant-scoped semantic search with embedding generation via LiteLLM.</done>
</task>

<task type="auto">
  <name>Task 2: Build WorkingContextCompiler and ContextManager</name>
  <files>src/app/context/working.py, src/app/context/manager.py, tests/test_context.py</files>
  <action>
1. Create src/app/context/working.py with WorkingContextCompiler class:
   - TOKEN_BUDGETS: dict mapping model tier to total budget:
     - "fast": 8_000 tokens (Haiku-class models)
     - "reasoning": 32_000 tokens (Sonnet/GPT-4o-class models)
   - BUDGET_ALLOCATION: dict defining percentage split:
     - "system_prompt": 0.15 (15%)
     - "session_history": 0.35 (35%)
     - "relevant_context": 0.35 (35%)
     - "task_and_buffer": 0.15 (15%)
   - __init__(self, model_tier: str = "reasoning") -- sets budget based on tier
   - _count_tokens(self, text: str) -> int -- uses tiktoken with cl100k_base encoding (works for both Claude and GPT models as approximation)
   - _truncate_to_budget(self, text: str, max_tokens: int) -> str -- truncates text to fit within token budget, keeping most recent content (for session history) or highest-relevance content (for memories)
   - async compile(self, system_prompt: str, session_messages: list[dict], relevant_memories: list[str], task: dict) -> dict
     - Calculates token budget for each section
     - Truncates system_prompt if exceeds 15% budget (unlikely but defensive)
     - Truncates session_messages from oldest first (keep most recent) to fit 35%
     - Truncates relevant_memories from least relevant first to fit 35%
     - Formats task data within remaining 15%
     - Returns: {"system_prompt": str, "messages": list[dict], "context": str, "task": dict, "token_usage": {"total": int, "system": int, "session": int, "memory": int, "task": int}}
   - Log token usage per section with structlog for monitoring context pressure

2. Create src/app/context/manager.py with ContextManager class:
   - __init__(self, session_store: SessionStore, memory: LongTermMemory, compiler: WorkingContextCompiler)
   - async compile_working_context(self, tenant_id: str, thread_id: str, task: dict, system_prompt: str, model_tier: str = "reasoning") -> dict
     - Step 1: Get session messages via session_store.get_session_messages(thread_id)
     - Step 2: Search long-term memory via memory.search(tenant_id, task.get("description", ""), limit=10)
     - Step 3: Compile working context via compiler.compile(system_prompt, session_messages, [m.content for m in memories], task)
     - Returns the compiled working context dict
   - async store_memory(self, tenant_id: str, agent_id: str, content: str, metadata: dict | None = None) -> str
     - Creates MemoryEntry and stores via memory.store()
     - Returns memory_id
   - async search_memory(self, tenant_id: str, query: str, limit: int = 10) -> list[MemoryEntry]
     - Delegates to memory.search()
   - @property session -> SessionStore (expose for LangGraph checkpointer access)

3. Create tests/test_context.py with:
   - test_memory_entry_creation: MemoryEntry validates fields
   - test_token_counting: WorkingContextCompiler._count_tokens returns reasonable count for known text
   - test_truncate_to_budget: Text exceeding budget is truncated
   - test_compile_within_budget: Compiled context total tokens <= budget
   - test_compile_preserves_recent_messages: Most recent session messages survive truncation
   - test_budget_allocation: Each section stays within its allocated percentage (with small tolerance)
   - test_context_manager_compile: Mock session_store and memory, verify compile_working_context calls both and returns compiled result
   - test_context_manager_store_memory: Mock memory.store, verify MemoryEntry is created correctly
   - At least 8 test cases. Mock database and Redis for unit tests (no integration DB needed).
  </action>
  <verify>
Run: `python -m pytest tests/test_context.py -v` -- all tests pass.
Run: `python -c "from src.app.context import WorkingContextCompiler; wc = WorkingContextCompiler('reasoning'); print(f'Budget: {wc.TOKEN_BUDGETS[\"reasoning\"]} tokens')"` succeeds.
  </verify>
  <done>WorkingContextCompiler enforces token budgets per model tier with priority-based truncation (recent session > relevant memory > task). ContextManager orchestrates all three tiers into a single compile_working_context call. All tests pass.</done>
</task>

</tasks>

<verification>
1. All classes import cleanly: `from src.app.context import SessionStore, LongTermMemory, MemoryEntry, WorkingContextCompiler, ContextManager`
2. SessionStore wraps AsyncPostgresSaver with explicit-clear-only lifetime
3. LongTermMemory queries are always filtered by tenant_id
4. WorkingContextCompiler stays within token budget for both "fast" (8k) and "reasoning" (32k) tiers
5. ContextManager.compile_working_context pulls from session + memory + task
6. All tests in tests/test_context.py pass
</verification>

<success_criteria>
- Session state persists via LangGraph PostgreSQL checkpointer with explicit-clear-only lifetime
- Long-term memory uses pgvector for semantic similarity search, scoped by tenant_id
- Working context compiles within token budget (15% system, 35% session, 35% memory, 15% task)
- Token counting uses tiktoken for accuracy
- ContextManager orchestrates all three tiers in a single call
- All 8+ tests pass covering token counting, truncation, budget allocation, and manager orchestration
</success_criteria>

<output>
After completion, create `.planning/phases/02-agent-orchestration/02-04-SUMMARY.md`
</output>
