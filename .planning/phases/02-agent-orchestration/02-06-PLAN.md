---
phase: 02-agent-orchestration
plan: 06
type: execute
wave: 4
depends_on: ["02-01", "02-05"]
files_modified:
  - src/app/observability/__init__.py
  - src/app/observability/tracer.py
  - src/app/observability/cost.py
  - src/app/config.py
  - src/app/main.py
  - src/app/core/monitoring.py
  - tests/test_observability.py
  - tests/test_phase2_integration.py
autonomous: true

must_haves:
  truths:
    - "Every LLM call is traced with tenant_id, agent_id, and session_id metadata via Langfuse"
    - "Per-tenant per-agent cost is trackable and queryable from Langfuse dashboard or API"
    - "All Phase 2 modules are wired into the running FastAPI application via main.py"
    - "Agent-specific Prometheus metrics (agent invocations, handoff validations) extend Phase 1 monitoring"
  artifacts:
    - path: "src/app/observability/tracer.py"
      provides: "Langfuse tracing wrapper with agent-scoped trace creation"
      exports: ["AgentTracer", "init_langfuse"]
    - path: "src/app/observability/cost.py"
      provides: "Per-tenant per-agent cost aggregation from Langfuse data"
      exports: ["CostTracker"]
    - path: "src/app/config.py"
      provides: "Extended settings with Langfuse configuration"
      contains: "LANGFUSE_PUBLIC_KEY"
    - path: "src/app/main.py"
      provides: "Updated lifespan and app factory with Phase 2 module initialization"
      contains: "SessionStore|LongTermMemory|AgentRegistry"
    - path: "src/app/core/monitoring.py"
      provides: "Extended Prometheus metrics for agent operations"
      contains: "agent_invocations_total|handoff_validations_total"
    - path: "tests/test_observability.py"
      provides: "Unit tests for tracing and cost tracking"
      min_lines: 40
    - path: "tests/test_phase2_integration.py"
      provides: "Integration tests validating Phase 2 success criteria"
      min_lines: 60
  key_links:
    - from: "src/app/observability/tracer.py"
      to: "langfuse"
      via: "Langfuse @observe decorator and propagate_attributes"
      pattern: "langfuse|observe|propagate_attributes"
    - from: "src/app/observability/tracer.py"
      to: "litellm"
      via: "success_callback=['langfuse'] for automatic LLM tracing"
      pattern: "success_callback|langfuse"
    - from: "src/app/main.py"
      to: "src/app/context/session.py"
      via: "SessionStore initialization in lifespan"
      pattern: "SessionStore|setup"
    - from: "src/app/main.py"
      to: "src/app/context/memory.py"
      via: "LongTermMemory initialization in lifespan"
      pattern: "LongTermMemory|setup"
---

<objective>
Build the observability infrastructure (Langfuse tracing + cost tracking + Prometheus metrics), wire all Phase 2 modules into the running application, and validate with integration tests.

Purpose: PLT-08 requires observability infrastructure for debugging agent decisions. PLT-09 requires per-tenant per-agent cost tracking. This final plan adds the instrumentation layer, extends Phase 1 monitoring with agent-specific metrics, wires all Phase 2 modules into main.py lifespan and dependency injection, and runs integration tests against all 5 success criteria.

Output: Complete observability/ package, extended config.py and monitoring.py, updated main.py with Phase 2 initialization, and integration tests validating the full orchestration pipeline.
</objective>

<execution_context>
@/Users/RAZER/.claude/get-shit-done/workflows/execute-plan.md
@/Users/RAZER/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-agent-orchestration/02-CONTEXT.md
@.planning/phases/02-agent-orchestration/02-RESEARCH.md
@.planning/phases/02-agent-orchestration/02-01-SUMMARY.md
@.planning/phases/02-agent-orchestration/02-05-SUMMARY.md
@src/app/config.py
@src/app/main.py
@src/app/core/monitoring.py
@src/app/services/llm.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Build Langfuse tracing, cost tracking, and agent metrics</name>
  <files>src/app/observability/__init__.py, src/app/observability/tracer.py, src/app/observability/cost.py, src/app/config.py, src/app/core/monitoring.py</files>
  <action>
1. Create src/app/observability/__init__.py with exports for AgentTracer, CostTracker, init_langfuse.

2. Create src/app/observability/tracer.py with:

   init_langfuse() function:
   - Imports litellm and sets: litellm.success_callback = ["langfuse"], litellm.failure_callback = ["langfuse"]
   - Sets LANGFUSE_* environment variables from settings if not already set
   - Logs initialization status with structlog
   - If Langfuse keys not configured, logs warning and skips (graceful degradation)

   AgentTracer class:
   - __init__(self, settings: Settings) -- stores settings, initializes Langfuse client if configured
   - trace_agent_execution(self, agent_id: str, tenant_id: str, session_id: str | None = None) -> context manager
     Uses langfuse.propagate_attributes to set:
     - user_id = tenant_id (maps to Langfuse user for cost grouping)
     - session_id = session_id or thread_id
     - tags = [f"agent:{agent_id}", f"tenant:{tenant_id}"]
     - metadata = {"tenant_id": tenant_id, "agent_id": agent_id}
     All LiteLLM calls within the context are automatically traced via the callback.
   - trace_handoff(self, source_agent: str, target_agent: str, tenant_id: str, valid: bool) -> None
     Creates a Langfuse span/event for the handoff validation result. Useful for debugging handoff rejections.
   - If Langfuse is not configured, all methods are no-ops (no-op context manager, no-op trace methods)

3. Create src/app/observability/cost.py with CostTracker class:
   - __init__(self, settings: Settings) -- stores settings
   - async get_tenant_costs(self, tenant_id: str, period_days: int = 30) -> dict
     Queries Langfuse API (if available) for cost data grouped by agent for a tenant.
     Uses langfuse client's get_observations or traces endpoint filtered by user_id=tenant_id.
     Returns: {"tenant_id": tenant_id, "period_days": period_days, "agents": {"agent_id": {"total_cost": float, "total_tokens": int, "invocation_count": int}}, "total_cost": float}
   - async get_agent_costs(self, agent_id: str, period_days: int = 30) -> dict
     Queries cost data for a specific agent across all tenants.
     Returns: {"agent_id": agent_id, "period_days": period_days, "tenants": {"tenant_id": {"total_cost": float, "total_tokens": int}}, "total_cost": float}
   - If Langfuse not configured, returns empty/zero cost dicts with a "source": "unavailable" flag.

4. Extend src/app/config.py Settings class with:
   - LANGFUSE_PUBLIC_KEY: str = "" (Langfuse public key)
   - LANGFUSE_SECRET_KEY: str = "" (Langfuse secret key)
   - LANGFUSE_HOST: str = "https://cloud.langfuse.com" (default to cloud, override for self-hosted)

5. Extend src/app/core/monitoring.py with agent-specific Prometheus metrics:
   - agent_invocations_total = Counter("agent_invocations_total", "Total agent invocations", ["agent_id", "tenant_id", "status"])
   - agent_invocation_duration_seconds = Histogram("agent_invocation_duration_seconds", "Agent invocation duration", ["agent_id", "tenant_id"])
   - handoff_validations_total = Counter("handoff_validations_total", "Total handoff validations", ["source_agent", "target_agent", "strictness", "result"])
   - supervisor_tasks_total = Counter("supervisor_tasks_total", "Total supervisor tasks", ["tenant_id", "decomposed", "status"])
   - context_compilation_duration_seconds = Histogram("context_compilation_duration_seconds", "Context compilation duration", ["tenant_id", "model_tier"])
   - Add async context manager: track_agent_invocation(agent_id, tenant_id) -- similar to track_llm_call but for agent invocations
  </action>
  <verify>
Run: `python -c "from src.app.observability import AgentTracer, CostTracker, init_langfuse; from src.app.config import get_settings; print('Observability imports OK')"` succeeds.
Run: `python -c "from src.app.core.monitoring import agent_invocations_total, handoff_validations_total; print('Agent metrics OK')"` succeeds.
Run: `python -c "from src.app.config import Settings; s = Settings(); assert hasattr(s, 'LANGFUSE_PUBLIC_KEY'); print('Config extended OK')"` succeeds.
  </verify>
  <done>Langfuse tracing automatically captures all LLM calls with tenant/agent metadata. Cost tracking provides per-tenant per-agent cost queries. Prometheus metrics extended with agent invocation and handoff validation counters.</done>
</task>

<task type="auto">
  <name>Task 2: Wire Phase 2 into main.py and write integration tests</name>
  <files>src/app/main.py, tests/test_observability.py, tests/test_phase2_integration.py</files>
  <action>
1. Update src/app/main.py:
   - Import Phase 2 modules in the lifespan function (lazy to avoid circular imports):
     - from src.app.context.session import SessionStore
     - from src.app.context.memory import LongTermMemory
     - from src.app.agents.registry import get_agent_registry
     - from src.app.observability.tracer import init_langfuse
   - In lifespan startup (after existing init_db and before yield):
     - Initialize Langfuse: init_langfuse() (if keys configured)
     - Initialize SessionStore: create instance, call setup(), store in app.state
     - Initialize LongTermMemory: create instance, call setup(), store in app.state
     - Initialize AgentRegistry: get_agent_registry(), store in app.state
     - Log "Phase 2 orchestration modules initialized" with structlog
   - In lifespan shutdown (after existing close_db and close_redis):
     - No special cleanup needed (Langfuse flushes automatically, registry is in-memory)
   - Do NOT break existing Phase 1 functionality. All new initialization is additive.
   - Handle initialization failures gracefully: if pgvector extension not available, log warning and continue (LongTermMemory will be unavailable). If Langfuse keys missing, log info and continue.

2. Create tests/test_observability.py with:
   - test_init_langfuse_with_keys: Mock litellm, verify success_callback set
   - test_init_langfuse_without_keys: Verify graceful skip when no keys configured
   - test_agent_tracer_noop_without_langfuse: AgentTracer methods are no-ops when Langfuse not configured
   - test_cost_tracker_unavailable: CostTracker returns zero costs when Langfuse not configured
   - test_agent_metrics_increment: agent_invocations_total increments correctly
   - At least 5 test cases

3. Create tests/test_phase2_integration.py with integration tests that validate the 5 success criteria:

   SC1: test_supervisor_task_routing
   - Create a mock agent (subclass BaseAgent with execute that returns canned response)
   - Register it in AgentRegistry
   - Create a HybridRouter with a rule matching the test task
   - Create SupervisorOrchestrator with mocked context and handoffs
   - Call execute_task, verify it routes to the correct agent and returns result

   SC2: test_event_bus_tenant_isolation
   - Create TenantEventBus for tenant_a and tenant_b (use real or mock Redis)
   - Publish event on tenant_a's stream
   - Verify tenant_b cannot see tenant_a's events (different stream keys)
   - Verify events carry source_agent_id and call_chain

   SC3: test_handoff_validation_rejects_malformed
   - Create HandoffPayload with missing source attribution
   - Verify HandoffProtocol rejects it with specific reasons
   - Create valid HandoffPayload with ungrounded data
   - Verify STRICT validation catches it (mock LLM semantic check)

   SC4: test_context_three_tiers
   - Mock SessionStore.get_session_messages returning conversation history
   - Mock LongTermMemory.search returning relevant memories
   - Call WorkingContextCompiler.compile, verify:
     a. Session history is included (most recent messages)
     b. Relevant memories are included
     c. Total tokens within budget
   - Verify ContextManager.compile_working_context orchestrates all three

   SC5: test_observability_tracing
   - Verify AgentTracer.trace_agent_execution sets correct Langfuse metadata (mock Langfuse)
   - Verify agent Prometheus metrics increment on agent invocation
   - Verify handoff validation metrics increment on validation

   At least 5 integration tests, one per success criterion.
  </action>
  <verify>
Run: `python -m pytest tests/test_observability.py -v` -- all tests pass.
Run: `python -m pytest tests/test_phase2_integration.py -v` -- all tests pass.
Run: `python -c "from src.app.main import create_app; app = create_app(); print('App creates OK')"` succeeds (app creation should not fail even without Langfuse/pgvector).
Run: `python -m pytest tests/ -v --tb=short` -- ALL tests pass (Phase 1 + Phase 2).
  </verify>
  <done>All Phase 2 modules wired into FastAPI app lifecycle. Integration tests validate all 5 success criteria: supervisor routing, tenant-isolated events, handoff validation, three-tier context, and observability tracing. No Phase 1 regressions.</done>
</task>

</tasks>

<verification>
1. `from src.app.observability import AgentTracer, CostTracker, init_langfuse` imports cleanly
2. Settings has LANGFUSE_PUBLIC_KEY, LANGFUSE_SECRET_KEY, LANGFUSE_HOST
3. main.py initializes Phase 2 modules in lifespan without breaking Phase 1
4. Agent Prometheus metrics (agent_invocations_total, handoff_validations_total) are registered
5. All tests pass: tests/test_observability.py, tests/test_phase2_integration.py
6. Full test suite passes: `python -m pytest tests/ -v` (no Phase 1 regressions)
7. App starts without Langfuse keys configured (graceful degradation)
</verification>

<success_criteria>
- Langfuse traces every LLM call with tenant_id, agent_id, session_id metadata
- Cost tracking returns per-tenant per-agent cost data (or graceful "unavailable" when Langfuse not configured)
- Agent Prometheus metrics track invocations, durations, and handoff validations
- All Phase 2 modules initialize in main.py lifespan without breaking Phase 1
- Integration tests validate all 5 Phase 2 success criteria
- Full test suite (Phase 1 + Phase 2) passes with no regressions
</success_criteria>

<output>
After completion, create `.planning/phases/02-agent-orchestration/02-06-SUMMARY.md`
</output>
