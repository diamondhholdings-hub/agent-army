---
phase: 14-customer-success-agent
plan: 06
type: execute
wave: 4
depends_on: ["14-03", "14-04"]
files_modified:
  - tests/test_csm_handlers.py
  - tests/test_csm_prompt_builders.py
  - tests/test_csm_notion_adapter.py
autonomous: true

must_haves:
  truths:
    - "health_scan handler uses CSMHealthScorer (no LLM call) and returns health_scores list"
    - "generate_qbr handler calls llm_service.completion() and notion_csm.create_qbr_page()"
    - "check_expansion handler dispatches to sales_agent.execute() with handle_expansion_opportunity type"
    - "Unknown task type raises ValueError (not fail-open dict)"
    - "Each prompt builder returns str containing its expected output schema fields"
    - "NotionCSMAdapter mock tests: get_account returns dict with id and account_id keys"
    - "NotionCSMAdapter mock tests: create_qbr_page called with QBRContent instance"
  artifacts:
    - path: "tests/test_csm_handlers.py"
      provides: "Agent handler routing and behavior tests"
      contains: "class TestCSMHandlers"
    - path: "tests/test_csm_prompt_builders.py"
      provides: "Prompt builder output validation tests"
      contains: "class TestCSMPromptBuilders"
    - path: "tests/test_csm_notion_adapter.py"
      provides: "NotionCSMAdapter mock tests"
      contains: "class TestNotionCSMAdapter"
  key_links:
    - from: "tests/test_csm_handlers.py"
      to: "src/app/agents/customer_success/agent.py"
      via: "CustomerSuccessAgent.execute() direct call"
      pattern: "agent.execute"
    - from: "tests/test_csm_notion_adapter.py"
      to: "src/app/agents/customer_success/notion_adapter.py"
      via: "mock AsyncClient injected"
      pattern: "NotionCSMAdapter.*mock"
---

<objective>
Write tests for the CSM agent handlers, prompt builders, and Notion adapter. These tests prove the handler routing, LLM call patterns, and Notion CRUD work correctly.

Purpose: Validates that health_scan is pure Python (no LLM), generate_qbr calls LLM, check_expansion dispatches to Sales Agent, and Notion adapter correctly structures page creation calls.
Output: 3 test files covering handlers, prompt builders, and Notion adapter with mocked dependencies.
</objective>

<execution_context>
@/Users/RAZER/.claude/get-shit-done/workflows/execute-plan.md
@/Users/RAZER/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md
@.planning/phases/14-customer-success-agent/14-03-SUMMARY.md
@.planning/phases/14-customer-success-agent/14-04-SUMMARY.md
@src/app/agents/customer_success/agent.py
@src/app/agents/customer_success/prompt_builders.py
@src/app/agents/customer_success/notion_adapter.py
@src/app/agents/customer_success/schemas.py
@tests/test_tam_handoff.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Write CSM handler tests and prompt builder tests</name>
  <files>
    tests/test_csm_handlers.py
    tests/test_csm_prompt_builders.py
  </files>
  <action>
Create tests/test_csm_handlers.py following project test conventions (pytest, AsyncMock, same structure as existing test files in tests/).

**TestCSMHandlers class (async tests):**

Setup: Create CustomerSuccessAgent with mocked dependencies:
```python
@pytest.fixture
def mock_llm():
    llm = AsyncMock()
    llm.completion.return_value = {"content": '{"churn_narrative": "test", "expansion_signals": [], "recommended_actions": []}'}
    return llm

@pytest.fixture
def mock_notion():
    n = AsyncMock()
    n.get_account.return_value = {"id": "page-1", "account_id": "acct-1", "name": "Test Co"}
    n.query_all_accounts.return_value = [{"id": "page-1", "account_id": "acct-1", "name": "Test Co", "feature_adoption_rate": 0.7, "usage_trend": "stable", "invoice_payment_status": "current"}]
    n.create_qbr_page.return_value = "qbr-page-id-123"
    n.create_expansion_record.return_value = "exp-page-id-456"
    return n

@pytest.fixture
def mock_sales_agent():
    sa = AsyncMock()
    sa.execute.return_value = {"task_type": "handle_expansion_opportunity", "draft_id": "draft-123", "confidence": "high"}
    return sa
```

Tests:

1. **test_unknown_task_type_raises_value_error** — execute({type: "unknown"}) raises ValueError
2. **test_health_scan_uses_health_scorer_not_llm** — Mock both llm AND health_scorer; run health_scan; assert llm.completion.not_called() and health_scorer.score.called (use real CSMHealthScorer if simpler)
3. **test_health_scan_fail_open_when_scorer_missing** — CustomerSuccessAgent(health_scorer=None); execute health_scan; returns dict with "error" key, not raises
4. **test_generate_qbr_calls_llm_and_creates_notion_page** — Mock LLM response with valid QBR JSON; run generate_qbr; assert mock_notion.create_qbr_page.called
5. **test_check_expansion_dispatches_to_sales_agent** — Mock LLM with expansion opportunity JSON response; run check_expansion; assert mock_sales_agent.execute.called with task containing handle_expansion_opportunity
6. **test_check_expansion_skips_dispatch_when_sales_agent_none** — Same but sales_agent=None; run check_expansion; no AttributeError raised (fail-open)
7. **test_track_feature_adoption_returns_adoption_rate** — Mock LLM with adoption report JSON; run track_feature_adoption; assert result has adoption_rate key
8. **test_all_handlers_fail_open** — For each of generate_qbr, check_expansion, track_feature_adoption: make LLM raise Exception; result should be dict with error key, not raise

---

Create tests/test_csm_prompt_builders.py:

**TestCSMPromptBuilders class (sync tests):**

1. **test_csm_system_prompt_not_empty** — CSM_SYSTEM_PROMPT is str with len > 50
2. **test_build_health_score_prompt_returns_string** — build_health_score_prompt({}, {}) returns str
3. **test_build_health_score_prompt_contains_schema_hint** — result contains "json" or "schema" (case-insensitive)
4. **test_build_churn_narrative_prompt_includes_narrative_key** — result contains "narrative"
5. **test_build_qbr_prompt_includes_all_four_sections** — result contains "health_summary" and "roi" and "adoption" and "expansion"
6. **test_build_expansion_prompt_includes_opportunity_type** — result contains "opportunity_type"
7. **test_build_feature_adoption_prompt_includes_recommendations** — result contains "recommendations"

Run: pytest tests/test_csm_handlers.py tests/test_csm_prompt_builders.py -v
  </action>
  <verify>
cd /Users/RAZER/Documents/projects/sales\ army && python -m pytest tests/test_csm_handlers.py tests/test_csm_prompt_builders.py -v 2>&1 | tail -20
  </verify>
  <done>All handler and prompt builder tests pass. test_health_scan_uses_health_scorer_not_llm confirms LLM not called for health scoring. test_check_expansion_dispatches_to_sales_agent confirms bidirectional handoff fires.</done>
</task>

<task type="auto">
  <name>Task 2: Write NotionCSMAdapter mock tests</name>
  <files>
    tests/test_csm_notion_adapter.py
  </files>
  <action>
Create tests/test_csm_notion_adapter.py. Use mock AsyncClient (same pattern as test_technical_account_manager.py TestNotionTAMAdapterMethods class at line 830).

**TestNotionCSMAdapter class (async tests):**

Setup:
```python
@pytest.fixture
def mock_notion_client():
    client = AsyncMock()
    # Mock databases.query response
    client.databases.query.return_value = {
        "results": [
            {
                "id": "page-uuid-123",
                "properties": {
                    "Account ID": {"rich_text": [{"text": {"content": "acct-001"}}]},
                    "Name": {"title": [{"text": {"content": "Test Corp"}}]},
                    "CSM Health Score": {"number": 75},
                    "CSM Health RAG": {"select": {"name": "GREEN"}},
                }
            }
        ]
    }
    # Mock pages.create response
    client.pages.create.return_value = {"id": "new-page-uuid-456"}
    # Mock pages.update response
    client.pages.update.return_value = {"id": "page-uuid-123"}
    # Mock blocks.children.append response
    client.blocks.children.append.return_value = {"results": []}
    return client
```

Tests:

1. **test_get_account_returns_both_id_and_account_id** — get_account("acct-001") returns dict with both "id" key and "account_id" key
2. **test_get_account_returns_empty_dict_when_not_found** — Mock empty results; get_account("nonexistent") returns {}
3. **test_query_all_accounts_returns_list** — query_all_accounts() returns list of dicts
4. **test_update_health_score_calls_pages_update** — update_health_score("page-123", 75.0, "GREEN"); assert client.pages.update.called with page_id="page-123"
5. **test_create_qbr_page_uses_database_parent** — create_qbr_page(qbr_instance, "Test Corp"); assert client.pages.create called; check call_args contains "database_id" (not "page_id") for parent
6. **test_create_expansion_record_uses_expansion_database** — create_expansion_record(expansion_instance); assert client.pages.create called
7. **test_render_qbr_blocks_produces_structured_blocks** — render_qbr_blocks(qbr) returns list with at least 4 elements (one per section)

Run: pytest tests/test_csm_notion_adapter.py -v
  </action>
  <verify>
cd /Users/RAZER/Documents/projects/sales\ army && python -m pytest tests/test_csm_notion_adapter.py -v 2>&1 | tail -20
  </verify>
  <done>All 7 Notion adapter tests pass. test_get_account_returns_both_id_and_account_id confirms dual-key contract. test_create_qbr_page_uses_database_parent confirms parent type is database (not page).</done>
</task>

</tasks>

<verification>
cd /Users/RAZER/Documents/projects/sales\ army && python -m pytest tests/test_csm_handlers.py tests/test_csm_prompt_builders.py tests/test_csm_notion_adapter.py -v 2>&1 | tail -10
</verification>

<success_criteria>
- test_csm_handlers.py: 8 tests pass including ValueError for unknown type and sales_agent dispatch
- test_csm_prompt_builders.py: 7 tests pass including schema hint in prompt outputs
- test_csm_notion_adapter.py: 7 tests pass including dual-key get_account and database_id parent for QBR
- Total: 22 tests passing across 3 test files
</success_criteria>

<output>
After completion, create `.planning/phases/14-customer-success-agent/14-06-SUMMARY.md`
</output>
