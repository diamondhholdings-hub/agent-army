---
phase: 14-customer-success-agent
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/app/agents/customer_success/__init__.py
  - src/app/agents/customer_success/schemas.py
  - src/app/agents/customer_success/prompt_builders.py
  - src/app/config.py
autonomous: true

must_haves:
  truths:
    - "CSMHealthSignals Pydantic model accepts all 13 signal fields (feature_adoption_rate, usage_trend, login_frequency_days, days_since_last_interaction, stakeholder_engagement, nps_score, invoice_payment_status, days_to_renewal, seats_utilization_rate, open_ticket_count, avg_ticket_sentiment, escalation_count_90_days, tam_health_rag)"
    - "CSMHealthScore model auto-computes should_alert via model_validator — returns True when rag is RED"
    - "CSMHandoffRequest validates task_type Literal for health_scan, generate_qbr, check_expansion, track_feature_adoption"
    - "ExpansionOpportunity, QBRContent, and FeatureAdoptionReport models exist with correct field types"
    - "5 prompt builders return non-empty str with embedded JSON schema"
    - "config.py has NOTION_CSM_HEALTH_DATABASE_ID, NOTION_CSM_QBR_DATABASE_ID, NOTION_CSM_EXPANSION_DATABASE_ID fields"
  artifacts:
    - path: "src/app/agents/customer_success/__init__.py"
      provides: "Module init with CustomerSuccessAgent export"
    - path: "src/app/agents/customer_success/schemas.py"
      provides: "All CSM Pydantic models"
      contains: "class CSMHealthSignals"
    - path: "src/app/agents/customer_success/prompt_builders.py"
      provides: "5 prompt builder functions"
      contains: "build_health_score_prompt"
    - path: "src/app/config.py"
      provides: "3 new Notion DB IDs"
      contains: "NOTION_CSM_HEALTH_DATABASE_ID"
  key_links:
    - from: "src/app/agents/customer_success/schemas.py"
      to: "CSMHealthScore.should_alert"
      via: "model_validator(mode='after')"
      pattern: "@model_validator"
    - from: "src/app/agents/customer_success/prompt_builders.py"
      to: "CSMHealthSignals schema"
      via: "model_json_schema() embedded in prompt"
      pattern: "model_json_schema"
---

<objective>
Create the CSM module foundation: Pydantic schemas for all CSM domain types, 5 prompt builder functions, and 3 new config fields. This is the type foundation every other CSM plan depends on.

Purpose: All subsequent CSM plans (health scorer, agent, handlers, tests) import from schemas.py. Getting the types right first prevents cascading refactors.
Output: src/app/agents/customer_success/ package with schemas.py, prompt_builders.py, __init__.py; config.py updated with 3 Notion DB IDs.
</objective>

<execution_context>
@/Users/RAZER/.claude/get-shit-done/workflows/execute-plan.md
@/Users/RAZER/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/14-customer-success-agent/14-CONTEXT.md
@.planning/phases/14-customer-success-agent/14-RESEARCH.md
@src/app/agents/technical_account_manager/schemas.py
@src/app/agents/technical_account_manager/prompts.py
@src/app/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create CSM schemas module with all Pydantic models</name>
  <files>
    src/app/agents/customer_success/__init__.py
    src/app/agents/customer_success/schemas.py
  </files>
  <action>
Create src/app/agents/customer_success/__init__.py — export CustomerSuccessAgent (as a forward-compatible stub; actual class added in Plan 03).

Create src/app/agents/customer_success/schemas.py with these models (mirror TAM schemas.py structure and docstring pattern):

**CSMHealthSignals(BaseModel):**
- feature_adoption_rate: float = Field(ge=0.0, le=1.0)
- usage_trend: Literal["growing", "stable", "declining", "inactive"]
- login_frequency_days: Optional[int] = None  # None = not tracked
- days_since_last_interaction: Optional[int] = None
- stakeholder_engagement: Literal["high", "medium", "low"]
- nps_score: Optional[int] = Field(default=None, ge=0, le=10)
- invoice_payment_status: Literal["current", "overdue_30", "overdue_60", "overdue_90_plus"]
- days_to_renewal: Optional[int] = None  # None = no renewal date set
- seats_utilization_rate: float = Field(ge=0.0, le=2.0)  # >1.0 = overused (upsell signal)
- open_ticket_count: int = Field(ge=0, default=0)
- avg_ticket_sentiment: Literal["positive", "neutral", "negative", "critical"] = "neutral"
- escalation_count_90_days: int = Field(ge=0, default=0)
- tam_health_rag: Optional[Literal["GREEN", "AMBER", "RED"]] = None

**CSMHealthScore(BaseModel):**
- account_id: str
- score: float = Field(ge=0.0, le=100.0)
- rag: Literal["GREEN", "AMBER", "RED"]
- should_alert: bool = False  # auto-computed by model_validator
- churn_risk_level: Literal["low", "medium", "high", "critical"]
- churn_triggered_by: Optional[Literal["contract_proximity", "behavioral", "both"]] = None
- signal_breakdown: dict[str, float] = Field(default_factory=dict)  # per-signal contribution
- computed_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
- Add @model_validator(mode="after") _compute_alert_flag: should_alert = (self.rag == "RED") or (self.churn_risk_level in ("high", "critical"))

**ChurnRiskResult(BaseModel):**
- account_id: str
- churn_risk_level: Literal["low", "medium", "high", "critical"]
- churn_triggered_by: Optional[Literal["contract_proximity", "behavioral", "both"]] = None
- churn_narrative: str = ""  # LLM-generated explanation
- days_to_renewal: Optional[int] = None
- health_rag: Literal["GREEN", "AMBER", "RED"]
- created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

**ExpansionOpportunity(BaseModel):**
- account_id: str
- opportunity_type: Literal["seats", "module", "integration"]
- evidence: str  # usage pattern that triggered it
- estimated_arr_impact: Optional[float] = None
- recommended_talk_track: str
- confidence: Literal["low", "medium", "high"] = "medium"
- created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

**QBRContent(BaseModel):**
- account_id: str
- period: str  # e.g., "Q1 2026"
- health_summary: str
- roi_metrics: dict[str, Any] = Field(default_factory=dict)
- feature_adoption_scorecard: dict[str, Any] = Field(default_factory=dict)
- expansion_next_steps: list[str] = Field(default_factory=list)
- generated_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
- trigger: Literal["quarterly", "contract_proximity"]

**FeatureAdoptionReport(BaseModel):**
- account_id: str
- features_used: list[str] = Field(default_factory=list)
- adoption_rate: float = Field(ge=0.0, le=1.0)
- underutilized_features: list[str] = Field(default_factory=list)
- recommendations: list[str] = Field(default_factory=list)
- benchmark_comparison: Optional[dict[str, float]] = None
- generated_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

**CSMHandoffRequest(BaseModel):**
- task_type: Literal["health_scan", "generate_qbr", "check_expansion", "track_feature_adoption"]
- account_id: str
- tenant_id: str
- context: dict = Field(default_factory=dict)
- priority: Literal["normal", "high", "urgent"] = "normal"

**CSMAlertResult(BaseModel):**  # mirrors TAM EscalationNotificationResult
- account_id: str
- channels: dict[str, bool] = Field(default_factory=dict)
- draft_id: Optional[str] = None
- alerts_sent: int = 0

Add __all__ listing all 8 models. Use `from __future__ import annotations` at top. Mirror TAM docstring quality.
  </action>
  <verify>
python -c "from src.app.agents.customer_success.schemas import CSMHealthSignals, CSMHealthScore, ChurnRiskResult, ExpansionOpportunity, QBRContent, FeatureAdoptionReport, CSMHandoffRequest, CSMAlertResult; s = CSMHealthScore(account_id='test', score=25.0, rag='RED', churn_risk_level='high'); print(s.should_alert)"
  </verify>
  <done>Import succeeds, CSMHealthScore with rag='RED' returns should_alert=True from model_validator. All 8 models importable.</done>
</task>

<task type="auto">
  <name>Task 2: Create CSM prompt builders and add config fields</name>
  <files>
    src/app/agents/customer_success/prompt_builders.py
    src/app/config.py
  </files>
  <action>
Create src/app/agents/customer_success/prompt_builders.py with 5 builder functions. Mirror TAM prompts.py structure — each builder returns a str with embedded JSON schema in the user message. Use model_json_schema() for output format specification.

**CSM_SYSTEM_PROMPT:** "You are an expert Customer Success Manager AI assistant. Your role is to analyze account health data, identify churn risk, surface expansion opportunities, prepare QBR materials, and track feature adoption. You work from Notion account data (Notion-first approach). All recommendations result in Gmail drafts for rep review — you never send emails autonomously. Respond with JSON matching the schema provided."

**build_health_score_prompt(signals: dict, account_data: dict) -> str:**
Returns prompt asking LLM to produce churn narrative and expansion signals. Include CSMHealthSignals schema in prompt. Note: health score computation itself is deterministic (CSMHealthScorer), but LLM generates the "why this account is at risk" narrative. Output schema: {"churn_narrative": str, "expansion_signals": list[str], "recommended_actions": list[str]}

**build_churn_narrative_prompt(health_score: dict, account_data: dict) -> str:**
Returns prompt asking for detailed churn risk narrative explanation for the rep. Output schema: {"narrative": str, "risk_factors": list[str], "retention_recommendations": list[str]}

**build_qbr_prompt(account_data: dict, health_history: dict, period: str) -> str:**
Returns prompt asking for QBR content generation across all 4 sections. Output schema mirrors QBRContent fields: {"health_summary": str, "roi_metrics": dict, "feature_adoption_scorecard": dict, "expansion_next_steps": list[str]}

**build_expansion_prompt(account_data: dict, usage_signals: dict) -> str:**
Returns prompt asking for expansion opportunity identification. Output schema: {"opportunities": list[{"opportunity_type": str, "evidence": str, "estimated_arr_impact": float|null, "recommended_talk_track": str, "confidence": str}]}

**build_feature_adoption_prompt(account_data: dict, feature_usage: dict) -> str:**
Returns prompt for feature adoption analysis and recommendations. Output schema mirrors FeatureAdoptionReport fields: {"features_used": list[str], "underutilized_features": list[str], "recommendations": list[str], "adoption_rate": float}

Add to src/app/config.py (find the Settings class, add after existing NOTION_DATABASE_ID field):
```python
NOTION_CSM_HEALTH_DATABASE_ID: str = Field(default="", description="Notion DB for CSM account health records")
NOTION_CSM_QBR_DATABASE_ID: str = Field(default="", description="Notion DB for CSM QBR pages")
NOTION_CSM_EXPANSION_DATABASE_ID: str = Field(default="", description="Notion DB for CSM expansion opportunities")
```
  </action>
  <verify>
python -c "from src.app.agents.customer_success.prompt_builders import CSM_SYSTEM_PROMPT, build_health_score_prompt, build_churn_narrative_prompt, build_qbr_prompt, build_expansion_prompt, build_feature_adoption_prompt; p = build_health_score_prompt({}, {}); assert len(p) > 50; print('OK')"
python -c "from src.app.config import Settings; s = Settings(); print(s.NOTION_CSM_HEALTH_DATABASE_ID, s.NOTION_CSM_QBR_DATABASE_ID, s.NOTION_CSM_EXPANSION_DATABASE_ID)"
  </verify>
  <done>All 5 prompt builder functions return non-empty strings. config.py Settings instance has all 3 NOTION_CSM_* fields (defaulting to empty string).</done>
</task>

</tasks>

<verification>
Run: python -c "from src.app.agents.customer_success.schemas import *; from src.app.agents.customer_success.prompt_builders import *; from src.app.config import Settings; s = Settings(); assert hasattr(s, 'NOTION_CSM_QBR_DATABASE_ID'); print('Plan 14-01 verification PASSED')"
</verification>

<success_criteria>
- src/app/agents/customer_success/ package exists with __init__.py, schemas.py, prompt_builders.py
- 8 Pydantic models importable from schemas.py
- CSMHealthScore model_validator auto-computes should_alert=True when rag='RED'
- 5 prompt builder functions importable from prompt_builders.py
- config.py Settings has NOTION_CSM_HEALTH_DATABASE_ID, NOTION_CSM_QBR_DATABASE_ID, NOTION_CSM_EXPANSION_DATABASE_ID
</success_criteria>

<output>
After completion, create `.planning/phases/14-customer-success-agent/14-01-SUMMARY.md`
</output>
