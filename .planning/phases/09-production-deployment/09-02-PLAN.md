---
phase: 09-production-deployment
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - .github/workflows/deploy.yml
  - scripts/verify_production.py
autonomous: true

must_haves:
  truths:
    - "GitHub Actions deploy workflow has a production job that deploys to Cloud Run with all secrets as env_vars"
    - "Production deploy uses google-github-actions/auth@v3 and deploy-cloudrun@v3 with --allow-unauthenticated"
    - "deploy.yml does NOT reference GCP Secret Manager for the production job"
    - "A smoke test script can verify SC1 (webapp) and SC2 (health endpoint) given URLs as CLI args"
    - "Smoke test runs as post-deploy step in the GitHub Actions production job"
  artifacts:
    - path: ".github/workflows/deploy.yml"
      provides: "Production deployment job with GitHub Actions secrets as env_vars"
      contains: "deploy-production"
    - path: "scripts/verify_production.py"
      provides: "Automated SC1 + SC2 verification"
      contains: "check_webapp"
  key_links:
    - from: ".github/workflows/deploy.yml"
      to: "scripts/verify_production.py"
      via: "post-deploy step runs verify_production.py"
      pattern: "verify_production"
    - from: ".github/workflows/deploy.yml"
      to: "Dockerfile"
      via: "gcloud builds submit builds the Docker image"
      pattern: "gcloud builds submit"
---

<objective>
Create the production CI/CD pipeline and automated verification script. Update the GitHub Actions deploy workflow to add a production job that injects all secrets as env_vars (not Secret Manager), and create a standalone smoke test script for SC1/SC2 verification.

Purpose: Without a production deploy job, there is no way to deploy to production. Without the verification script, SC1 and SC2 cannot be automated. This plan creates the deployment mechanism and verification tooling.

Output: Updated deploy.yml with production job, new verify_production.py smoke test script.
</objective>

<execution_context>
@/Users/RAZER/.claude/get-shit-done/workflows/execute-plan.md
@/Users/RAZER/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/09-production-deployment/09-RESEARCH.md

@.github/workflows/deploy.yml
@Dockerfile
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update deploy.yml with production deployment job</name>
  <files>.github/workflows/deploy.yml</files>
  <action>
Update the existing `.github/workflows/deploy.yml` to:

1. **Keep the existing staging job intact** -- do not modify the staging job's functionality beyond updating action versions.

2. **Update action versions** for the staging job:
   - `google-github-actions/auth@v2` to `google-github-actions/auth@v3`
   - `google-github-actions/deploy-cloudrun@v2` to `google-github-actions/deploy-cloudrun@v3`

3. **Add a new `deploy-production` job** after the staging job with these characteristics:
   - `runs-on: ubuntu-latest`
   - `permissions: contents: read, id-token: write`
   - `needs: [deploy-staging]` (production deploys after staging succeeds)
   - Triggered on push to main (same as existing)

   Steps:
   a. `actions/checkout@v4`
   b. `google-github-actions/auth@v3` with Workload Identity Federation using same secrets as staging
   c. `google-github-actions/setup-gcloud@v2`
   d. Skip Docker build (reuse image from staging job which already pushed to gcr.io)
   e. Deploy to Cloud Run with ALL secrets as `env_vars` (NOT `secrets:` block). Use the complete list from the research -- approximately 25 env vars including:
      - ENVIRONMENT=production
      - DATABASE_URL, REDIS_URL, JWT_SECRET_KEY from PROD_ prefixed secrets
      - ANTHROPIC_API_KEY, OPENAI_API_KEY
      - GOOGLE_SERVICE_ACCOUNT_JSON_B64, GOOGLE_DELEGATED_USER_EMAIL
      - NOTION_TOKEN, NOTION_DATABASE_ID
      - KNOWLEDGE_QDRANT_URL, KNOWLEDGE_QDRANT_API_KEY, KNOWLEDGE_OPENAI_API_KEY
      - RECALL_AI_API_KEY, DEEPGRAM_API_KEY
      - ELEVENLABS_API_KEY, ELEVENLABS_VOICE_ID
      - HEYGEN_API_KEY, HEYGEN_AVATAR_ID
      - MEETING_BOT_WEBAPP_URL
      - LANGFUSE_PUBLIC_KEY, LANGFUSE_SECRET_KEY
      - SENTRY_DSN, CORS_ALLOWED_ORIGINS
      - COMPANY_NAME=Skyvera, MEETING_BOT_NAME=Sales Agent

   Use `env_vars_update_strategy: overwrite` and include flags:
      --min-instances=0, --max-instances=10, --memory=1Gi, --cpu=1, --timeout=300, --concurrency=80, --allow-unauthenticated

   f. Post-deploy smoke test step that installs httpx and runs verify_production.py with the webapp URL from secrets and the backend URL from the deploy step output.

**CRITICAL:** The production job must NOT use the `secrets:` block (GCP Secret Manager references). All secrets come from GitHub Actions secrets injected via `env_vars`.
  </action>
  <verify>
Validate deploy.yml is well-formed YAML and contains required elements:
- "deploy-production" job exists
- "deploy-cloudrun@v3" action referenced
- "--allow-unauthenticated" flag present
- "NOTION_TOKEN" in env_vars
- "GOOGLE_SERVICE_ACCOUNT_JSON_B64" in env_vars
- "verify_production" referenced in a post-deploy step
  </verify>
  <done>
deploy.yml has a `deploy-production` job that: uses auth@v3 and deploy-cloudrun@v3, passes all secrets as env_vars (no Secret Manager), includes --allow-unauthenticated flag, and runs the smoke test script as a post-deploy step. Staging job still works unchanged.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create production smoke test script</name>
  <files>scripts/verify_production.py</files>
  <action>
Create `scripts/verify_production.py` -- a standalone script that verifies SC1 (webapp) and SC2 (health endpoint) programmatically.

**Requirements:**
- Accept `--webapp-url` and `--backend-url` as CLI arguments (using argparse)
- Both arguments required
- Use `httpx` for HTTP requests (already in project dependencies)
- Timeout: 15 seconds per request
- Follow redirects for webapp check

**SC1 check (webapp):**
Verify the webapp URL returns HTTP 200 and serves content. Return a tuple of (passed: bool, detail: str).

**SC2 check (health endpoint):**
Verify /health/ready returns HTTP 200 with status "ready". If degraded, return which checks failed. Return a tuple of (passed: bool, detail: str).

**Output format:**
Print a formatted table showing each check name, status (PASS/FAIL), and detail.

**Exit code:** 0 if all pass, 1 if any fail.

**Add shebang:** `#!/usr/bin/env python3` at top.

**Important:** Do NOT hardcode any URLs. Always use CLI arguments. The script should work in both CI (GitHub Actions) and local developer usage.
  </action>
  <verify>
Run: `cd "/Users/RAZER/Documents/projects/sales army" && python scripts/verify_production.py --help`
Expected: Help text showing --webapp-url and --backend-url arguments.
  </verify>
  <done>
`scripts/verify_production.py` exists, accepts --webapp-url and --backend-url CLI args, checks SC1 (webapp 200 response) and SC2 (health endpoint all-green), prints formatted results, and exits with code 0 (all pass) or 1 (any fail).
  </done>
</task>

</tasks>

<verification>
1. deploy.yml is valid YAML with both staging and production jobs
2. Production job uses env_vars (not secrets: block) for all credentials
3. Production job includes --allow-unauthenticated flag
4. verify_production.py runs with --help without error
5. verify_production.py exits 1 when given invalid URLs (expected behavior)
</verification>

<success_criteria>
- deploy.yml has deploy-production job with all secrets as env_vars from GitHub Actions
- deploy.yml production job uses @v3 actions and --allow-unauthenticated
- verify_production.py is a standalone CLI tool accepting --webapp-url and --backend-url
- Smoke test runs as post-deploy step in GitHub Actions
- No GCP Secret Manager references in the production job
</success_criteria>

<output>
After completion, create `.planning/phases/09-production-deployment/09-02-SUMMARY.md`
</output>
