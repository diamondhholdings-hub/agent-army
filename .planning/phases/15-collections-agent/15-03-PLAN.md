---
phase: 15-collections-agent
plan: 03
type: execute
wave: 3
depends_on: ["15-01", "15-02"]
files_modified:
  - src/app/agents/collections/prompt_builders.py
  - src/app/agents/collections/handlers.py
autonomous: true

must_haves:
  truths:
    - "Five prompt builders exist — one per task type — each returning str with embedded JSON schema for structured LLM output"
    - "Five handlers exist matching the 5 task types in CollectionsHandoffRequest.request_type"
    - "All handlers follow fail-open semantics: LLM errors return partial result dict, not 500"
    - "generate_collection_message handler calls compute_tone_modifier and selects stage-appropriate system prompt"
    - "surface_payment_plan handler produces both a Notion page (via adapter) and a Gmail draft (via gmail_service)"
    - "payment_risk_assessment handler calls PaymentRiskScorer.score() for deterministic base, then LLM for narrative enrichment"
  artifacts:
    - path: "src/app/agents/collections/prompt_builders.py"
      provides: "5 prompt builders + COLLECTIONS_SYSTEM_PROMPT"
      exports: ["COLLECTIONS_SYSTEM_PROMPT", "build_ar_report_prompt", "build_risk_narrative_prompt", "build_collection_message_prompt", "build_escalation_check_prompt", "build_payment_plan_prompt"]
      min_lines: 120
    - path: "src/app/agents/collections/handlers.py"
      provides: "5 handler functions called by CollectionsAgent"
      exports: ["handle_ar_aging_report", "handle_payment_risk_assessment", "handle_generate_collection_message", "handle_run_escalation_check", "handle_surface_payment_plan"]
      min_lines: 200
  key_links:
    - from: "src/app/agents/collections/handlers.py"
      to: "src/app/agents/collections/scorer.py"
      via: "PaymentRiskScorer.score() called in handle_payment_risk_assessment"
      pattern: "PaymentRiskScorer.*score"
    - from: "src/app/agents/collections/handlers.py"
      to: "src/app/agents/collections/prompt_builders.py"
      via: "build_* functions called per task type"
      pattern: "build_.*_prompt"
    - from: "src/app/agents/collections/handlers.py"
      to: "src/app/agents/collections/scorer.py"
      via: "compute_tone_modifier called in handle_generate_collection_message"
      pattern: "compute_tone_modifier"
---

<objective>
Build the 5 LLM prompt builders and 5 task handlers for the Collections Agent. Prompts define the LLM output shape; handlers orchestrate the full task lifecycle (score → prompt → LLM → persist → draft).

Purpose: Handlers are the core logic layer between the agent supervisor and external services. Each handler implements one collections capability. Fail-open semantics keep the workflow unblocked under LLM errors.
Output: `src/app/agents/collections/prompt_builders.py` and `src/app/agents/collections/handlers.py`.
</objective>

<execution_context>
@/Users/RAZER/.claude/get-shit-done/workflows/execute-plan.md
@/Users/RAZER/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md

@src/app/agents/collections/schemas.py
@src/app/agents/collections/scorer.py
@src/app/agents/customer_success/prompt_builders.py
@src/app/agents/customer_success/agent.py
@.planning/phases/15-collections-agent/15-01-SUMMARY.md
@.planning/phases/15-collections-agent/15-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create prompt builders for all 5 collections task types</name>
  <files>src/app/agents/collections/prompt_builders.py</files>
  <action>
Create `src/app/agents/collections/prompt_builders.py` following the CSM prompt builder pattern exactly — each builder returns `str` with embedded JSON schema (use `json.dumps(ModelClass.model_json_schema(), indent=2)` for structured output shapes).

Module structure:
```python
"""Prompt builders for the Collections Agent — 5 task-specific builders."""
from __future__ import annotations
import json
from src.app.agents.collections.schemas import (
    ARAgingReport, PaymentRiskResult, CollectionMessageStage, PaymentPlanOptions
)

COLLECTIONS_SYSTEM_PROMPT = """You are a Collections Agent for an enterprise SaaS company..."""
```

**COLLECTIONS_SYSTEM_PROMPT**: You are a collections specialist for an enterprise SaaS company. Your role is to help recover outstanding payments while preserving customer relationships. You analyze AR aging, predict payment risk, generate appropriately calibrated collection messages, evaluate escalation readiness, and structure payment plan options. All communications are DRAFT ONLY — you never send emails autonomously. Human reps review and approve all outreach before sending.

**build_ar_report_prompt(account_id: str, raw_invoices: list[dict]) -> str**:
Builds prompt to analyze raw invoice data and compute AR aging buckets. Embeds ARAgingReport.model_json_schema(). Instructs LLM to compute bucket totals, identify oldest invoice, and return structured ARAgingReport JSON.

**build_risk_narrative_prompt(account_id: str, score_result: dict, account_context: dict) -> str**:
Builds prompt to generate a 2-3 sentence risk narrative enriching the deterministic score. Embeds schema: `{"narrative": str, "key_risk_factors": list[str], "recommended_action": str}`. Instructs LLM to explain what is driving the risk score in human-readable terms for the rep.

**build_collection_message_prompt(account_id: str, stage: int, ar_report: dict, tone_modifier: float, account_context: dict) -> str**:
Builds prompt to generate a collection email for the specific stage. Includes stage persona:
- Stage 1 (friendly nudge): tone=soft, assumes oversight/admin error, relationship-preserving
- Stage 2 (soft reminder): polite urgency, references invoice specifics
- Stage 3 (firm notice): professional, clear consequences stated, tone shifts
- Stage 4 (final warning): explicit escalation timeline, final chance before human intervention
- Stage 5: not used for message gen (human handoff — no automated messages)
tone_modifier float is passed as context: 1.0=baseline, <1.0=softer (high ARR/tenure), >1.0=more urgent (chronic late payer). Message MUST reference oldest_invoice_number and total_outstanding_usd from ar_report.
Embeds schema: `{"subject": str, "body": str, "key_references": {"invoice_number": str, "balance_usd": float}}`.

**build_escalation_check_prompt(account_id: str, escalation_state: dict, ar_report: dict, risk_result: dict) -> str**:
Builds prompt to evaluate whether escalation is warranted given current state and AR data. Returns structured recommendation. Embeds schema: `{"should_advance": bool, "recommended_stage": int, "rationale": str, "stage5_immediate": bool}`. Note: handler does NOT use LLM for escalation logic — this prompt is used only when stage5 handoff notification content needs to be generated.

**build_payment_plan_prompt(account_id: str, ar_report: dict, account_context: dict) -> str**:
Builds prompt to generate 3 payment plan options (installment_schedule, partial_payment, pay_or_suspend). Must include account ARR and relationship tenure in context. Embeds PaymentPlanOptions.model_json_schema(). Instructs LLM to propose realistic installment dates, amounts, and rationale.

Export `__all__` listing all 5 builders + COLLECTIONS_SYSTEM_PROMPT.
  </action>
  <verify>
Run: `cd /Users/RAZER/Documents/projects/sales\ army && python -c "from src.app.agents.collections.prompt_builders import COLLECTIONS_SYSTEM_PROMPT, build_ar_report_prompt, build_risk_narrative_prompt, build_collection_message_prompt, build_escalation_check_prompt, build_payment_plan_prompt; p = build_collection_message_prompt('acct1', 2, {'total_outstanding_usd': 5000, 'oldest_invoice_number': 'INV-001'}, 0.9, {}); assert 'INV-001' in p or 'oldest_invoice' in p; print('prompt builders OK')"`
  </verify>
  <done>All 5 prompt builders importable, return non-empty strings, include embedded JSON schema, COLLECTIONS_SYSTEM_PROMPT defined.</done>
</task>

<task type="auto">
  <name>Task 2: Create 5 task handlers with fail-open semantics</name>
  <files>src/app/agents/collections/handlers.py</files>
  <action>
Create `src/app/agents/collections/handlers.py` following the CSM agent.py handler pattern. Each handler is an async function accepting `(task: dict, llm_service, notion_collections, gmail_service, scorer, **kwargs)`.

**General pattern** (same as CSM/TAM handlers):
- All handlers are `async def`
- LLM calls use `await llm_service.completion(...)` with temperature 0.3-0.4
- On ANY exception: return `{"error": str(exc), "confidence": "low", "partial": True}`
- Parse LLM JSON output with `json.loads()` wrapped in try/except
- Use `re.search(r'\{.*\}', response, re.DOTALL)` to extract JSON from LLM response if needed (same pattern as CSM)

**handle_ar_aging_report(task, llm_service, notion_collections, gmail_service, scorer, **kwargs) -> dict**:
1. Extract account_id from task
2. If notion_collections: call `await notion_collections.get_ar_aging(account_id)` to get raw invoices
3. If no invoices found, return `{"account_id": account_id, "total_outstanding_usd": 0.0, "buckets": [], "message": "No outstanding invoices"}`
4. Build prompt with build_ar_report_prompt, call LLM
5. Parse response into ARAgingReport dict
6. Return ARAgingReport dict

**handle_payment_risk_assessment(task, llm_service, notion_collections, gmail_service, scorer, **kwargs) -> dict**:
1. Extract account_id, build PaymentRiskSignals from task data (days_overdue, payment_history_streak, total_outstanding_balance_usd, days_to_renewal, arr_usd, tenure_years)
2. Call `scorer.score(signals)` for deterministic base score → PaymentRiskResult
3. Build narrative prompt with build_risk_narrative_prompt, call LLM
4. Parse narrative, set result.narrative = narrative_text
5. Return PaymentRiskResult model_dump()

**handle_generate_collection_message(task, llm_service, notion_collections, gmail_service, scorer, **kwargs) -> dict**:
1. Extract account_id, stage (1-4 only — stage 5 is human handoff, no message), ar_report data, account_context
2. Compute tone_modifier via `compute_tone_modifier(days_overdue, arr_usd, payment_streak, tenure_years)` (import from scorer)
3. Build prompt with build_collection_message_prompt(account_id, stage, ar_report, tone_modifier, account_context)
4. Call LLM, parse subject + body
5. If gmail_service: create draft via `await gmail_service.create_draft(...)` — subject, body; store draft_id
6. If notion_collections: call `await notion_collections.log_collection_event(account_id, "message_generated", {...})`
7. Return CollectionMessageStage model_dump()

**handle_run_escalation_check(task, llm_service, notion_collections, gmail_service, scorer, **kwargs) -> dict**:
1. Extract account_id
2. Get escalation_state from notion_collections (or use task-provided state)
3. Get AR aging data
4. Get risk result (or recompute)
5. Apply DETERMINISTIC escalation logic (NOT LLM) using STAGE_TIME_FLOORS:
   - If current_stage == 5: already at human handoff, skip
   - If payment_received_at is set: reset to stage 0, return reset result
   - Check time_floor_met: `(now - stage_entered_at).days >= STAGE_TIME_FLOORS.get(current_stage, 999)`
   - Check non_response: `messages_unanswered >= 1`
   - If BOTH: advance stage (current_stage + 1)
   - If advancing to stage 5: set stage5_notified=False (trigger notification)
   - If new stage == 5 AND not stage5_notified: generate BOTH rep notification draft AND finance team draft via gmail_service.create_draft(); set stage5_notified=True
6. Update escalation_state in notion_collections
7. Return CollectionsAlertResult model_dump()

**handle_surface_payment_plan(task, llm_service, notion_collections, gmail_service, scorer, **kwargs) -> dict**:
1. Extract account_id, ar_report, account_context
2. Build payment plan prompt, call LLM
3. Parse PaymentPlanOptions from LLM response
4. If notion_collections: create payment plan page via `await notion_collections.create_payment_plan_page(account_id, options_dict)` → store page_id
5. If gmail_service: create draft summarizing options for rep review → store draft_id
6. Return PaymentPlanOptions model_dump()

Export `__all__` = ["handle_ar_aging_report", "handle_payment_risk_assessment", "handle_generate_collection_message", "handle_run_escalation_check", "handle_surface_payment_plan"]

Import `STAGE_TIME_FLOORS` from scorer module. Import `compute_tone_modifier` from scorer module. Use lazy imports where needed to avoid circular deps (same pattern as other agents).
  </action>
  <verify>
Run: `cd /Users/RAZER/Documents/projects/sales\ army && python -c "from src.app.agents.collections.handlers import handle_ar_aging_report, handle_payment_risk_assessment, handle_generate_collection_message, handle_run_escalation_check, handle_surface_payment_plan; import asyncio; result = asyncio.run(handle_ar_aging_report({'account_id': 'test'}, None, None, None, None)); assert 'account_id' in result or 'error' in result or 'message' in result; print('handlers importable and callable')"`
  </verify>
  <done>All 5 handlers importable, callable with None services, return dict with either valid data or {"error", "confidence", "partial"} fail-open response. compute_tone_modifier imported from scorer. STAGE_TIME_FLOORS imported from scorer.</done>
</task>

</tasks>

<verification>
1. `python -c "from src.app.agents.collections import prompt_builders, handlers; print('imports OK')"` — no import errors
2. `python -c "from src.app.agents.collections.handlers import handle_run_escalation_check; import inspect; assert inspect.iscoroutinefunction(handle_run_escalation_check)"` — all handlers are async
3. Grep for `create_draft` in handlers.py — both message generation and stage 5 handoff use gmail_service.create_draft(), never send_email
4. Grep for `FINANCE_TEAM_EMAIL\|finance.*email\|finance.*notify` in handlers.py — stage 5 human handoff notifies finance team
</verification>

<success_criteria>
- 5 prompt builders in prompt_builders.py, all returning str, COLLECTIONS_SYSTEM_PROMPT defined
- 5 handlers in handlers.py, all async, all fail-open
- Escalation logic is DETERMINISTIC in handle_run_escalation_check (no LLM for stage advancement decisions)
- Stage 5 triggers Gmail drafts to both rep AND finance team
- All communications via create_draft(), never send_email()
- STAGE_TIME_FLOORS exported from scorer.py and imported in handlers.py
</success_criteria>

<output>
After completion, create `.planning/phases/15-collections-agent/15-03-SUMMARY.md`
</output>
